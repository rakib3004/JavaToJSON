{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "13hLT2nok7Fjr06kadZ7MQpN-7NA9rDUW",
      "authorship_tag": "ABX9TyMssse+EZO33Xb2OmiGxQGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakib3004/SPL3/blob/main/CodeScrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Software System Reconstruction with LLMs\n",
        "Author: Md. Rakib Trofder  \n",
        "Supervisor:Denys Poshyvanyk                                      \n",
        "Mentor:Daniel Rodriguez-Cardenas\n"
      ],
      "metadata": {
        "id": "xucgboZiT9Tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Github to JSON"
      ],
      "metadata": {
        "id": "J_dUKBNwJG4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "\n",
        "# Replace with your GitHub username, repository name, and personal access token\n",
        "username = \"rakib3004\"\n",
        "repository = \"refactoring-workshop\"\n",
        "\n",
        "# Set the GitHub API base URL\n",
        "api_base_url = \"https://api.github.com\"\n",
        "\n",
        "# Define the target directory where you want to save the JSON files\n",
        "target_directory = \"/content/drive/MyDrive/SPL3/WilliamMerry/JSON/hadoop\"\n",
        "\n",
        "# Create the target directory if it doesn't exist\n",
        "if not os.path.exists(target_directory):\n",
        "    os.makedirs(target_directory)\n",
        "\n",
        "# Fetch the repository contents\n",
        "repository_url = f\"https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred?ref=trunk\"\n",
        "response = requests.get(repository_url)\n",
        "if response.status_code == 200:\n",
        "    repository_contents = response.json()\n",
        "    # Iterate through the repository contents\n",
        "\n",
        "    for item in repository_contents:\n",
        "        print(item)\n",
        "        if item[\"type\"] == \"file\" and item[\"name\"].endswith(\".java\"):\n",
        "            # Fetch the content of the Java file\n",
        "            content_url = item[\"download_url\"]\n",
        "            java_code = requests.get(content_url).text\n",
        "            print(item[\"name\"])\n",
        "            print(java_code)\n",
        "            class_info = None\n",
        "            methods_info = []\n",
        "            imports_info = []\n",
        "\n",
        "            lines = java_code.split(\"\\n\")\n",
        "            is_in_method = False\n",
        "\n",
        "            for line in lines:\n",
        "                if line.strip().startswith(\"package \"):\n",
        "                    package_name = line.split(\" \")[1][:-1]  # Extract package name\n",
        "                elif line.strip().startswith(\"import \"):\n",
        "                    import_statement = line.strip()[7:-1]  # Extract import statement\n",
        "                    imports_info.append(import_statement)\n",
        "                elif line.strip().startswith(\"public class \"):\n",
        "                    class_name = line.split(\" \")[3].split(\"{\")[0]\n",
        "                    class_info = {\n",
        "                        \"name\": class_name,\n",
        "                        \"methods\": []\n",
        "                    }\n",
        "                elif line.strip().startswith(\"public\") and line.strip().endswith(\") {\"):\n",
        "                    method_signature = line.split(\"(\")[0].split(\" \")[2:]\n",
        "                    method_name = method_signature[-1]\n",
        "                    method_args = method_signature[:-1]\n",
        "                    is_in_method = True\n",
        "                    method_info = {\n",
        "                        \"name\": method_name,\n",
        "                        \"args\": method_args,\n",
        "                        \"body\": []\n",
        "                    }\n",
        "                elif is_in_method and line.strip() != \"}\":\n",
        "                    method_info[\"body\"].append(line.strip())\n",
        "                elif is_in_method and line.strip() == \"}\":\n",
        "                    is_in_method = False\n",
        "                    class_info[\"methods\"].append(method_info)\n",
        "                    methods_info.append(method_info)\n",
        "\n",
        "            # Convert class, method, and import information to JSON-like structure\n",
        "            json_structure = {\n",
        "                \"package\": package_name,\n",
        "                \"imports\": imports_info,\n",
        "                \"classes\": [class_info],\n",
        "                \"methods\": methods_info\n",
        "            }\n",
        "\n",
        "            # Convert the JSON-like structure to a JSON string\n",
        "            json_string = json_structure\n",
        "\n",
        "\n",
        "            json_structure = {\n",
        "                \"java_filename\": item[\"name\"],\n",
        "                \"java_code\": java_code\n",
        "            }\n",
        "\n",
        "            # Save the JSON file in the target directory\n",
        "            json_filename = os.path.join(target_directory, item[\"name\"] + \".json\")\n",
        "            with open(json_filename, \"w\") as json_file:\n",
        "                json.dump(json_string, json_file, indent=4)\n",
        "\n",
        "    print(\"Java files converted and saved as JSON in the target directory.\")\n",
        "else:\n",
        "    print(\"Failed to fetch repository contents. Check your GitHub credentials or repository name.\")\n"
      ],
      "metadata": {
        "id": "31L-xFHEJMHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae59057-5f80-4ba6-eb53-e7ab8825fee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'LocalContainerLauncher.java', 'path': 'hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java', 'sha': '4c245136efb41f1add3411677914f481d13295a8', 'size': 27121, 'url': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java?ref=trunk', 'html_url': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java', 'git_url': 'https://api.github.com/repos/apache/hadoop/git/blobs/4c245136efb41f1add3411677914f481d13295a8', 'download_url': 'https://raw.githubusercontent.com/apache/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java?ref=trunk', 'git': 'https://api.github.com/repos/apache/hadoop/git/blobs/4c245136efb41f1add3411677914f481d13295a8', 'html': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java'}}\n",
            "LocalContainerLauncher.java\n",
            "/**\n",
            "* Licensed to the Apache Software Foundation (ASF) under one\n",
            "* or more contributor license agreements.  See the NOTICE file\n",
            "* distributed with this work for additional information\n",
            "* regarding copyright ownership.  The ASF licenses this file\n",
            "* to you under the Apache License, Version 2.0 (the\n",
            "* \"License\"); you may not use this file except in compliance\n",
            "* with the License.  You may obtain a copy of the License at\n",
            "*\n",
            "*     http://www.apache.org/licenses/LICENSE-2.0\n",
            "*\n",
            "* Unless required by applicable law or agreed to in writing, software\n",
            "* distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "* See the License for the specific language governing permissions and\n",
            "* limitations under the License.\n",
            "*/\n",
            "\n",
            "package org.apache.hadoop.mapred;\n",
            "\n",
            "import java.io.File;\n",
            "import java.io.IOException;\n",
            "import java.lang.management.ManagementFactory;\n",
            "import java.lang.management.RuntimeMXBean;\n",
            "import java.lang.management.ThreadInfo;\n",
            "import java.lang.management.ThreadMXBean;\n",
            "import java.util.HashMap;\n",
            "import java.util.HashSet;\n",
            "import java.util.Map;\n",
            "import java.util.Set;\n",
            "import java.util.Collections;\n",
            "import java.util.concurrent.BlockingQueue;\n",
            "import java.util.concurrent.ConcurrentHashMap;\n",
            "import java.util.concurrent.ExecutorService;\n",
            "import java.util.concurrent.Future;\n",
            "import java.util.concurrent.LinkedBlockingQueue;\n",
            "\n",
            "import org.apache.hadoop.classification.VisibleForTesting;\n",
            "\n",
            "import org.apache.hadoop.fs.FSError;\n",
            "import org.apache.hadoop.fs.FileContext;\n",
            "import org.apache.hadoop.fs.FileStatus;\n",
            "import org.apache.hadoop.fs.FileSystem;\n",
            "import org.apache.hadoop.fs.Path;\n",
            "import org.apache.hadoop.fs.UnsupportedFileSystemException;\n",
            "import org.apache.hadoop.mapreduce.JobContext;\n",
            "import org.apache.hadoop.mapreduce.JobCounter;\n",
            "import org.apache.hadoop.mapreduce.MRConfig;\n",
            "import org.apache.hadoop.mapreduce.TaskID;\n",
            "import org.apache.hadoop.mapreduce.TypeConverter;\n",
            "import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId;\n",
            "import org.apache.hadoop.mapreduce.v2.api.records.TaskType;\n",
            "import org.apache.hadoop.mapreduce.v2.app.AppContext;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.Job;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.event.JobCounterUpdateEvent;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptContainerLaunchedEvent;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEvent;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType;\n",
            "import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher;\n",
            "import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherEvent;\n",
            "import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerRemoteLaunchEvent;\n",
            "import org.apache.hadoop.service.AbstractService;\n",
            "import org.apache.hadoop.util.ExitUtil;\n",
            "import org.apache.hadoop.util.ShutdownHookManager;\n",
            "import org.apache.hadoop.util.StringUtils;\n",
            "import org.apache.hadoop.util.concurrent.HadoopExecutors;\n",
            "import org.apache.hadoop.yarn.api.ApplicationConstants.Environment;\n",
            "import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;\n",
            "\n",
            "import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ThreadFactoryBuilder;\n",
            "import org.slf4j.Logger;\n",
            "import org.slf4j.LoggerFactory;\n",
            "\n",
            "/**\n",
            " * Runs the container task locally in a thread.\n",
            " * Since all (sub)tasks share the same local directory, they must be executed\n",
            " * sequentially in order to avoid creating/deleting the same files/dirs.\n",
            " */\n",
            "public class LocalContainerLauncher extends AbstractService implements\n",
            "    ContainerLauncher {\n",
            "\n",
            "  private static final File curDir = new File(\".\");\n",
            "  private static final Logger LOG =\n",
            "      LoggerFactory.getLogger(LocalContainerLauncher.class);\n",
            "\n",
            "  private FileContext curFC = null;\n",
            "  private Set<File> localizedFiles = new HashSet<File>();\n",
            "  private final AppContext context;\n",
            "  private final TaskUmbilicalProtocol umbilical;\n",
            "  private final ClassLoader jobClassLoader;\n",
            "  private ExecutorService taskRunner;\n",
            "  private Thread eventHandler;\n",
            "  private byte[] encryptedSpillKey = new byte[] {0};\n",
            "  private BlockingQueue<ContainerLauncherEvent> eventQueue =\n",
            "      new LinkedBlockingQueue<ContainerLauncherEvent>();\n",
            "\n",
            "  public LocalContainerLauncher(AppContext context,\n",
            "                                TaskUmbilicalProtocol umbilical) {\n",
            "    this(context, umbilical, null);\n",
            "  }\n",
            "\n",
            "  public LocalContainerLauncher(AppContext context,\n",
            "                                TaskUmbilicalProtocol umbilical,\n",
            "                                ClassLoader jobClassLoader) {\n",
            "    super(LocalContainerLauncher.class.getName());\n",
            "    this.context = context;\n",
            "    this.umbilical = umbilical;\n",
            "        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n",
            "        // (TODO/FIXME:  pointless to use RPC to talk to self; should create\n",
            "        // LocalTaskAttemptListener or similar:  implement umbilical protocol\n",
            "        // but skip RPC stuff)\n",
            "    this.jobClassLoader = jobClassLoader;\n",
            "\n",
            "    try {\n",
            "      curFC = FileContext.getFileContext(curDir.toURI());\n",
            "    } catch (UnsupportedFileSystemException ufse) {\n",
            "      LOG.error(\"Local filesystem \" + curDir.toURI().toString()\n",
            "                + \" is unsupported?? (should never happen)\");\n",
            "    }\n",
            "\n",
            "    // Save list of files/dirs that are supposed to be present so can delete\n",
            "    // any extras created by one task before starting subsequent task.  Note\n",
            "    // that there's no protection against deleted or renamed localization;\n",
            "    // users who do that get what they deserve (and will have to disable\n",
            "    // uberization in order to run correctly).\n",
            "    File[] curLocalFiles = curDir.listFiles();\n",
            "    if (curLocalFiles != null) {\n",
            "      HashSet<File> lf = new HashSet<File>(curLocalFiles.length);\n",
            "      for (int j = 0; j < curLocalFiles.length; ++j) {\n",
            "        lf.add(curLocalFiles[j]);\n",
            "      }\n",
            "      localizedFiles = Collections.unmodifiableSet(lf);\n",
            "    }\n",
            "\n",
            "    // Relocalization note/future FIXME (per chrisdo, 20110315):  At moment,\n",
            "    // full localization info is in AppSubmissionContext passed from client to\n",
            "    // RM and then to NM for AM-container launch:  no difference between AM-\n",
            "    // localization and MapTask- or ReduceTask-localization, so can assume all\n",
            "    // OK.  Longer-term, will need to override uber-AM container-localization\n",
            "    // request (\"needed resources\") with union of regular-AM-resources + task-\n",
            "    // resources (and, if maps and reduces ever differ, then union of all three\n",
            "    // types), OR will need localizer service/API that uber-AM can request\n",
            "    // after running (e.g., \"localizeForTask()\" or \"localizeForMapTask()\").\n",
            "  }\n",
            "\n",
            "  public void serviceStart() throws Exception {\n",
            "    // create a single thread for serial execution of tasks\n",
            "    // make it a daemon thread so that the process can exit even if the task is\n",
            "    // not interruptible\n",
            "    taskRunner =\n",
            "        HadoopExecutors.newSingleThreadExecutor(new ThreadFactoryBuilder().\n",
            "            setDaemon(true).setNameFormat(\"uber-SubtaskRunner\").build());\n",
            "    // create and start an event handling thread\n",
            "    eventHandler = new Thread(new EventHandler(), \"uber-EventHandler\");\n",
            "    // if the job classloader is specified, set it onto the event handler as the\n",
            "    // thread context classloader so that it can be used by the event handler\n",
            "    // as well as the subtask runner threads\n",
            "    if (jobClassLoader != null) {\n",
            "      LOG.info(\"Setting \" + jobClassLoader +\n",
            "          \" as the context classloader of thread \" + eventHandler.getName());\n",
            "      eventHandler.setContextClassLoader(jobClassLoader);\n",
            "    } else {\n",
            "      // note the current TCCL\n",
            "      LOG.info(\"Context classloader of thread \" + eventHandler.getName() +\n",
            "          \": \" + eventHandler.getContextClassLoader());\n",
            "    }\n",
            "    eventHandler.start();\n",
            "    super.serviceStart();\n",
            "  }\n",
            "\n",
            "  public void serviceStop() throws Exception {\n",
            "    if (eventHandler != null) {\n",
            "      eventHandler.interrupt();\n",
            "    }\n",
            "    if (taskRunner != null) {\n",
            "      taskRunner.shutdownNow();\n",
            "    }\n",
            "    super.serviceStop();\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void handle(ContainerLauncherEvent event) {\n",
            "    try {\n",
            "      eventQueue.put(event);\n",
            "    } catch (InterruptedException e) {\n",
            "      throw new YarnRuntimeException(e);  // FIXME? YarnRuntimeException is \"for runtime exceptions only\"\n",
            "    }\n",
            "  }\n",
            "\n",
            "  public void setEncryptedSpillKey(byte[] encryptedSpillKey) {\n",
            "    if (encryptedSpillKey != null) {\n",
            "      this.encryptedSpillKey = encryptedSpillKey;\n",
            "    }\n",
            "  }\n",
            "\n",
            "  /*\n",
            "   * Uber-AM lifecycle/ordering (\"normal\" case):\n",
            "   *\n",
            "   * - [somebody] sends TA_ASSIGNED\n",
            "   *   - handled by ContainerAssignedTransition (TaskAttemptImpl.java)\n",
            "   *     - creates \"remoteTask\" for us == real Task\n",
            "   *     - sends CONTAINER_REMOTE_LAUNCH\n",
            "   *     - TA: UNASSIGNED -> ASSIGNED\n",
            "   * - CONTAINER_REMOTE_LAUNCH handled by LocalContainerLauncher (us)\n",
            "   *   - sucks \"remoteTask\" out of TaskAttemptImpl via getRemoteTask()\n",
            "   *   - sends TA_CONTAINER_LAUNCHED\n",
            "   *     [[ elsewhere...\n",
            "   *       - TA_CONTAINER_LAUNCHED handled by LaunchedContainerTransition\n",
            "   *         - registers \"remoteTask\" with TaskAttemptListener (== umbilical)\n",
            "   *         - NUKES \"remoteTask\"\n",
            "   *         - sends T_ATTEMPT_LAUNCHED (Task: SCHEDULED -> RUNNING)\n",
            "   *         - TA: ASSIGNED -> RUNNING\n",
            "   *     ]]\n",
            "   *   - runs Task (runSubMap() or runSubReduce())\n",
            "   *     - TA can safely send TA_UPDATE since in RUNNING state\n",
            "   */\n",
            "  private class EventHandler implements Runnable {\n",
            "\n",
            "    // doneWithMaps and finishedSubMaps are accessed from only\n",
            "    // one thread. Therefore, no need to make them volatile.\n",
            "    private boolean doneWithMaps = false;\n",
            "    private int finishedSubMaps = 0;\n",
            "\n",
            "    private final Map<TaskAttemptId,Future<?>> futures =\n",
            "        new ConcurrentHashMap<TaskAttemptId,Future<?>>();\n",
            "\n",
            "    EventHandler() {\n",
            "    }\n",
            "\n",
            "    @SuppressWarnings(\"unchecked\")\n",
            "    @Override\n",
            "    public void run() {\n",
            "      ContainerLauncherEvent event = null;\n",
            "\n",
            "      // Collect locations of map outputs to give to reduces\n",
            "      final Map<TaskAttemptID, MapOutputFile> localMapFiles =\n",
            "          new HashMap<TaskAttemptID, MapOutputFile>();\n",
            "      \n",
            "      // _must_ either run subtasks sequentially or accept expense of new JVMs\n",
            "      // (i.e., fork()), else will get weird failures when maps try to create/\n",
            "      // write same dirname or filename:  no chdir() in Java\n",
            "      while (!Thread.currentThread().isInterrupted()) {\n",
            "        try {\n",
            "          event = eventQueue.take();\n",
            "        } catch (InterruptedException e) {  // mostly via T_KILL? JOB_KILL?\n",
            "          LOG.warn(\"Returning, interrupted : \" + e);\n",
            "          break;\n",
            "        }\n",
            "\n",
            "        LOG.info(\"Processing the event \" + event.toString());\n",
            "\n",
            "        if (event.getType() == EventType.CONTAINER_REMOTE_LAUNCH) {\n",
            "\n",
            "          final ContainerRemoteLaunchEvent launchEv =\n",
            "              (ContainerRemoteLaunchEvent)event;\n",
            "          \n",
            "          // execute the task on a separate thread\n",
            "          Future<?> future = taskRunner.submit(new Runnable() {\n",
            "            public void run() {\n",
            "              runTask(launchEv, localMapFiles);\n",
            "            }\n",
            "          });\n",
            "          // remember the current attempt\n",
            "          futures.put(event.getTaskAttemptID(), future);\n",
            "\n",
            "        } else if (event.getType() == EventType.CONTAINER_REMOTE_CLEANUP) {\n",
            "\n",
            "          if (event.getDumpContainerThreads()) {\n",
            "            try {\n",
            "              // Construct full thread dump header\n",
            "              System.out.println(new java.util.Date());\n",
            "              RuntimeMXBean rtBean = ManagementFactory.getRuntimeMXBean();\n",
            "              System.out.println(\"Full thread dump \" + rtBean.getVmName()\n",
            "                  + \" (\" + rtBean.getVmVersion()\n",
            "                  + \" \" + rtBean.getSystemProperties().get(\"java.vm.info\")\n",
            "                  + \"):\\n\");\n",
            "              // Dump threads' states and stacks\n",
            "              ThreadMXBean tmxBean = ManagementFactory.getThreadMXBean();\n",
            "              ThreadInfo[] tInfos = tmxBean.dumpAllThreads(\n",
            "                  tmxBean.isObjectMonitorUsageSupported(),\n",
            "                  tmxBean.isSynchronizerUsageSupported());\n",
            "              for (ThreadInfo ti : tInfos) {\n",
            "                System.out.println(ti.toString());\n",
            "              }\n",
            "            } catch (Throwable t) {\n",
            "              // Failure to dump stack shouldn't cause method failure.\n",
            "              System.out.println(\"Could not create full thread dump: \"\n",
            "                  + t.getMessage());\n",
            "            }\n",
            "          }\n",
            "\n",
            "          // cancel (and interrupt) the current running task associated with the\n",
            "          // event\n",
            "          TaskAttemptId taId = event.getTaskAttemptID();\n",
            "          Future<?> future = futures.remove(taId);\n",
            "          if (future != null) {\n",
            "            LOG.info(\"canceling the task attempt \" + taId);\n",
            "            future.cancel(true);\n",
            "          }\n",
            "\n",
            "          // send \"cleaned\" event to task attempt to move us from\n",
            "          // SUCCESS_CONTAINER_CLEANUP to SUCCEEDED state (or \n",
            "          // {FAIL|KILL}_CONTAINER_CLEANUP to {FAIL|KILL}_TASK_CLEANUP)\n",
            "          context.getEventHandler().handle(\n",
            "              new TaskAttemptEvent(taId,\n",
            "                  TaskAttemptEventType.TA_CONTAINER_CLEANED));\n",
            "        } else if (event.getType() == EventType.CONTAINER_COMPLETED) {\n",
            "          LOG.debug(\"Container completed \" + event.toString());\n",
            "        } else {\n",
            "          LOG.warn(\"Ignoring unexpected event \" + event.toString());\n",
            "        }\n",
            "\n",
            "      }\n",
            "    }\n",
            "\n",
            "    @SuppressWarnings(\"unchecked\")\n",
            "    private void runTask(ContainerRemoteLaunchEvent launchEv,\n",
            "        Map<TaskAttemptID, MapOutputFile> localMapFiles) {\n",
            "      TaskAttemptId attemptID = launchEv.getTaskAttemptID(); \n",
            "\n",
            "      Job job = context.getAllJobs().get(attemptID.getTaskId().getJobId());\n",
            "      int numMapTasks = job.getTotalMaps();\n",
            "      int numReduceTasks = job.getTotalReduces();\n",
            "\n",
            "      // YARN (tracking) Task:\n",
            "      org.apache.hadoop.mapreduce.v2.app.job.Task ytask =\n",
            "          job.getTask(attemptID.getTaskId());\n",
            "      // classic mapred Task:\n",
            "      org.apache.hadoop.mapred.Task remoteTask = launchEv.getRemoteTask();\n",
            "\n",
            "      // after \"launching,\" send launched event to task attempt to move\n",
            "      // state from ASSIGNED to RUNNING (also nukes \"remoteTask\", so must\n",
            "      // do getRemoteTask() call first)\n",
            "      \n",
            "      //There is no port number because we are not really talking to a task\n",
            "      // tracker.  The shuffle is just done through local files.  So the\n",
            "      // port number is set to -1 in this case.\n",
            "      context.getEventHandler().handle(\n",
            "          new TaskAttemptContainerLaunchedEvent(attemptID, -1));\n",
            "\n",
            "      if (numMapTasks == 0) {\n",
            "        doneWithMaps = true;\n",
            "      }\n",
            "\n",
            "      try {\n",
            "        if (remoteTask.isMapOrReduce()) {\n",
            "          JobCounterUpdateEvent jce = new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n",
            "          jce.addCounterUpdate(JobCounter.TOTAL_LAUNCHED_UBERTASKS, 1);\n",
            "          if (remoteTask.isMapTask()) {\n",
            "            jce.addCounterUpdate(JobCounter.NUM_UBER_SUBMAPS, 1);\n",
            "          } else {\n",
            "            jce.addCounterUpdate(JobCounter.NUM_UBER_SUBREDUCES, 1);\n",
            "          }\n",
            "          context.getEventHandler().handle(jce);\n",
            "        }\n",
            "        runSubtask(remoteTask, ytask.getType(), attemptID, numMapTasks,\n",
            "                   (numReduceTasks > 0), localMapFiles);\n",
            "\n",
            "        // In non-uber mode, TA gets TA_CONTAINER_COMPLETED from MRAppMaster\n",
            "        // as part of NM -> RM -> AM notification route.\n",
            "        // In uber mode, given the task run inside the MRAppMaster container,\n",
            "        // we have to simulate the notification.\n",
            "        context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n",
            "            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n",
            "\n",
            "      } catch (RuntimeException re) {\n",
            "        JobCounterUpdateEvent jce = new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n",
            "        jce.addCounterUpdate(JobCounter.NUM_FAILED_UBERTASKS, 1);\n",
            "        context.getEventHandler().handle(jce);\n",
            "        // this is our signal that the subtask failed in some way, so\n",
            "        // simulate a failed JVM/container and send a container-completed\n",
            "        // event to task attempt (i.e., move state machine from RUNNING\n",
            "        // to FAIL_CONTAINER_CLEANUP [and ultimately to FAILED])\n",
            "        context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n",
            "            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n",
            "      } catch (IOException ioe) {\n",
            "        // if umbilical itself barfs (in error-handler of runSubMap()),\n",
            "        // we're pretty much hosed, so do what YarnChild main() does\n",
            "        // (i.e., exit clumsily--but can never happen, so no worries!)\n",
            "        LOG.error(\"oopsie...  this can never happen: \"\n",
            "            + StringUtils.stringifyException(ioe));\n",
            "        ExitUtil.terminate(-1);\n",
            "      } finally {\n",
            "        // remove my future\n",
            "        if (futures.remove(attemptID) != null) {\n",
            "          LOG.info(\"removed attempt \" + attemptID +\n",
            "              \" from the futures to keep track of\");\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "\n",
            "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n",
            "                            final TaskType taskType,\n",
            "                            TaskAttemptId attemptID,\n",
            "                            final int numMapTasks,\n",
            "                            boolean renameOutputs,\n",
            "                            Map<TaskAttemptID, MapOutputFile> localMapFiles)\n",
            "    throws RuntimeException, IOException {\n",
            "      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID =\n",
            "          TypeConverter.fromYarn(attemptID);\n",
            "\n",
            "      try {\n",
            "        JobConf conf = new JobConf(getConfig());\n",
            "        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n",
            "        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n",
            "        conf.setBoolean(JobContext.TASK_ISMAP, (taskType == TaskType.MAP));\n",
            "        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n",
            "        conf.set(JobContext.ID, task.getJobID().toString());\n",
            "\n",
            "        // Use the AM's local dir env to generate the intermediate step \n",
            "        // output files\n",
            "        String[] localSysDirs = StringUtils.getTrimmedStrings(\n",
            "            System.getenv(Environment.LOCAL_DIRS.name()));\n",
            "        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n",
            "        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n",
            "            + conf.get(MRConfig.LOCAL_DIR));\n",
            "\n",
            "        // mark this as an uberized subtask so it can set task counter\n",
            "        // (longer-term/FIXME:  could redefine as job counter and send\n",
            "        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n",
            "        // will need new Job state-machine transition and JobImpl jobCounters\n",
            "        // map to handle)\n",
            "        conf.setBoolean(\"mapreduce.task.uberized\", true);\n",
            "\n",
            "        // Check and handle Encrypted spill key\n",
            "        task.setEncryptedSpillKey(encryptedSpillKey);\n",
            "        YarnChild.setEncryptedSpillKeyIfRequired(task);\n",
            "\n",
            "        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n",
            "        // etc.), or just assume/hope the state machine(s) and uber-AM work\n",
            "        // as expected?\n",
            "        if (taskType == TaskType.MAP) {\n",
            "          if (doneWithMaps) {\n",
            "            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n",
            "                      + attemptID + \"), but should be finished with maps\");\n",
            "            throw new RuntimeException();\n",
            "          }\n",
            "\n",
            "          MapTask map = (MapTask)task;\n",
            "          map.setConf(conf);\n",
            "\n",
            "          map.run(conf, umbilical);\n",
            "\n",
            "          if (renameOutputs) {\n",
            "            MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID,\n",
            "                map.getMapOutputFile());\n",
            "            localMapFiles.put(classicAttemptID, renamed);\n",
            "          }\n",
            "          relocalize();\n",
            "\n",
            "          if (++finishedSubMaps == numMapTasks) {\n",
            "            doneWithMaps = true;\n",
            "          }\n",
            "\n",
            "        } else /* TaskType.REDUCE */ {\n",
            "\n",
            "          if (!doneWithMaps) {\n",
            "            // check if event-queue empty?  whole idea of counting maps vs. \n",
            "            // checking event queue is a tad wacky...but could enforce ordering\n",
            "            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n",
            "            // doesn't send reduce event until maps all done]\n",
            "            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n",
            "                      + attemptID + \"), but not yet finished with maps\");\n",
            "            throw new RuntimeException();\n",
            "          }\n",
            "\n",
            "          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n",
            "          // set framework name to local to make task local\n",
            "          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n",
            "          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n",
            "\n",
            "          ReduceTask reduce = (ReduceTask)task;\n",
            "          reduce.setLocalMapFiles(localMapFiles);\n",
            "          reduce.setConf(conf);          \n",
            "\n",
            "          reduce.run(conf, umbilical);\n",
            "          relocalize();\n",
            "        }\n",
            "\n",
            "      } catch (FSError e) {\n",
            "        LOG.error(\"FSError from child\", e);\n",
            "        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n",
            "        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n",
            "          umbilical.fsError(classicAttemptID, e.getMessage());\n",
            "        }\n",
            "        throw new RuntimeException();\n",
            "\n",
            "      } catch (Exception exception) {\n",
            "        LOG.warn(\"Exception running local (uberized) 'child' : \"\n",
            "            + StringUtils.stringifyException(exception));\n",
            "        try {\n",
            "          if (task != null) {\n",
            "            // do cleanup for the task\n",
            "            task.taskCleanup(umbilical);\n",
            "          }\n",
            "        } catch (Exception e) {\n",
            "          LOG.info(\"Exception cleaning up: \"\n",
            "              + StringUtils.stringifyException(e));\n",
            "        }\n",
            "        // Report back any failures, for diagnostic purposes\n",
            "        umbilical.reportDiagnosticInfo(classicAttemptID, \n",
            "            StringUtils.stringifyException(exception));\n",
            "        throw new RuntimeException();\n",
            "\n",
            "      } catch (Throwable throwable) {\n",
            "        LOG.error(\"Error running local (uberized) 'child' : \"\n",
            "            + StringUtils.stringifyException(throwable));\n",
            "        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n",
            "          Throwable tCause = throwable.getCause();\n",
            "          String cause =\n",
            "              (tCause == null) ? throwable.getMessage() : StringUtils\n",
            "                  .stringifyException(tCause);\n",
            "          umbilical.fatalError(classicAttemptID, cause, false);\n",
            "        }\n",
            "        throw new RuntimeException();\n",
            "      }\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * Also within the local filesystem, we need to restore the initial state\n",
            "     * of the directory as much as possible.  Compare current contents against\n",
            "     * the saved original state and nuke everything that doesn't belong, with\n",
            "     * the exception of the renamed map outputs.\n",
            "     *\n",
            "     * Any jobs that go out of their way to rename or delete things from the\n",
            "     * local directory are considered broken and deserve what they get...\n",
            "     */\n",
            "    private void relocalize() {\n",
            "      File[] curLocalFiles = curDir.listFiles();\n",
            "      if (curLocalFiles != null) {\n",
            "        for (int j = 0; j < curLocalFiles.length; ++j) {\n",
            "          if (!localizedFiles.contains(curLocalFiles[j])) {\n",
            "            // found one that wasn't there before:  delete it\n",
            "            boolean deleted = false;\n",
            "            try {\n",
            "              if (curFC != null) {\n",
            "                // this is recursive, unlike File delete():\n",
            "                deleted =\n",
            "                    curFC.delete(new Path(curLocalFiles[j].getName()), true);\n",
            "              }\n",
            "            } catch (IOException e) {\n",
            "              deleted = false;\n",
            "            }\n",
            "            if (!deleted) {\n",
            "              LOG.warn(\"Unable to delete unexpected local file/dir \"\n",
            "                  + curLocalFiles[j].getName()\n",
            "                  + \": insufficient permissions?\");\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  } // end EventHandler\n",
            "\n",
            "  /**\n",
            "   * Within the _local_ filesystem (not HDFS), all activity takes place within\n",
            "   * a subdir inside one of the LOCAL_DIRS\n",
            "   * (${local.dir}/usercache/$user/appcache/$appId/$contId/),\n",
            "   * and all sub-MapTasks create the same filename (\"file.out\").  Rename that\n",
            "   * to something unique (e.g., \"map_0.out\") to avoid possible collisions.\n",
            "   *\n",
            "   * Longer-term, we'll modify [something] to use TaskAttemptID-based\n",
            "   * filenames instead of \"file.out\". (All of this is entirely internal,\n",
            "   * so there are no particular compatibility issues.)\n",
            "   */\n",
            "  @VisibleForTesting\n",
            "  protected static MapOutputFile renameMapOutputForReduce(JobConf conf,\n",
            "      TaskAttemptId mapId, MapOutputFile subMapOutputFile) throws IOException {\n",
            "    FileSystem localFs = FileSystem.getLocal(conf);\n",
            "    // move map output to reduce input\n",
            "    Path mapOut = subMapOutputFile.getOutputFile();\n",
            "    FileStatus mStatus = localFs.getFileStatus(mapOut);\n",
            "    Path reduceIn = subMapOutputFile.getInputFileForWrite(\n",
            "        TypeConverter.fromYarn(mapId).getTaskID(), mStatus.getLen());\n",
            "    Path mapOutIndex = subMapOutputFile.getOutputIndexFile();\n",
            "    Path reduceInIndex = new Path(reduceIn.toString() + \".index\");\n",
            "    if (LOG.isDebugEnabled()) {\n",
            "      LOG.debug(\"Renaming map output file for task attempt \"\n",
            "          + mapId.toString() + \" from original location \" + mapOut.toString()\n",
            "          + \" to destination \" + reduceIn.toString());\n",
            "    }\n",
            "    if (!localFs.mkdirs(reduceIn.getParent())) {\n",
            "      throw new IOException(\"Mkdirs failed to create \"\n",
            "          + reduceIn.getParent().toString());\n",
            "    }\n",
            "    if (!localFs.rename(mapOut, reduceIn))\n",
            "      throw new IOException(\"Couldn't rename \" + mapOut);\n",
            "    if (!localFs.rename(mapOutIndex, reduceInIndex))\n",
            "      throw new IOException(\"Couldn't rename \" + mapOutIndex);\n",
            "\n",
            "    return new RenamedMapOutputFile(reduceIn);\n",
            "  }\n",
            "\n",
            "  private static class RenamedMapOutputFile extends MapOutputFile {\n",
            "    private Path path;\n",
            "    \n",
            "    public RenamedMapOutputFile(Path path) {\n",
            "      this.path = path;\n",
            "    }\n",
            "    \n",
            "    @Override\n",
            "    public Path getOutputFile() throws IOException {\n",
            "      return path;\n",
            "    }\n",
            "\n",
            "    @Override\n",
            "    public Path getOutputFileForWrite(long size) throws IOException {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public Path getOutputFileForWriteInVolume(Path existing) {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public Path getOutputIndexFile() throws IOException {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public Path getOutputIndexFileForWrite(long size) throws IOException {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public Path getOutputIndexFileForWriteInVolume(Path existing) {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public Path getSpillFile(int spillNumber) throws IOException {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public Path getSpillFileForWrite(int spillNumber, long size)\n",
            "        throws IOException {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public Path getSpillIndexFile(int spillNumber) throws IOException {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public Path getSpillIndexFileForWrite(int spillNumber, long size)\n",
            "        throws IOException {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public Path getInputFile(int mapId) throws IOException {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public Path getInputFileForWrite(TaskID mapId, long size)\n",
            "        throws IOException {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "    @Override\n",
            "    public void removeAll() throws IOException {\n",
            "      throw new UnsupportedOperationException();\n",
            "    }\n",
            "  }\n",
            "\n",
            "}\n",
            "\n",
            "{'name': 'MapReduceChildJVM.java', 'path': 'hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java', 'sha': 'd305f9ff0765529effcde95499860430d8247f30', 'size': 7357, 'url': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java?ref=trunk', 'html_url': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java', 'git_url': 'https://api.github.com/repos/apache/hadoop/git/blobs/d305f9ff0765529effcde95499860430d8247f30', 'download_url': 'https://raw.githubusercontent.com/apache/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java?ref=trunk', 'git': 'https://api.github.com/repos/apache/hadoop/git/blobs/d305f9ff0765529effcde95499860430d8247f30', 'html': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java'}}\n",
            "MapReduceChildJVM.java\n",
            "/**\n",
            "* Licensed to the Apache Software Foundation (ASF) under one\n",
            "* or more contributor license agreements.  See the NOTICE file\n",
            "* distributed with this work for additional information\n",
            "* regarding copyright ownership.  The ASF licenses this file\n",
            "* to you under the Apache License, Version 2.0 (the\n",
            "* \"License\"); you may not use this file except in compliance\n",
            "* with the License.  You may obtain a copy of the License at\n",
            "*\n",
            "*     http://www.apache.org/licenses/LICENSE-2.0\n",
            "*\n",
            "* Unless required by applicable law or agreed to in writing, software\n",
            "* distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "* See the License for the specific language governing permissions and\n",
            "* limitations under the License.\n",
            "*/\n",
            "\n",
            "package org.apache.hadoop.mapred;\n",
            "\n",
            "import java.net.InetSocketAddress;\n",
            "import java.util.List;\n",
            "import java.util.Map;\n",
            "import java.util.Vector;\n",
            "\n",
            "import org.apache.hadoop.fs.Path;\n",
            "import org.apache.hadoop.mapred.TaskLog.LogName;\n",
            "import org.apache.hadoop.mapreduce.MRJobConfig;\n",
            "import org.apache.hadoop.mapreduce.TaskType;\n",
            "import org.apache.hadoop.mapreduce.v2.util.MRApps;\n",
            "import org.apache.hadoop.yarn.api.ApplicationConstants;\n",
            "import org.apache.hadoop.yarn.api.ApplicationConstants.Environment;\n",
            "import org.apache.hadoop.yarn.conf.YarnConfiguration;\n",
            "\n",
            "@SuppressWarnings(\"deprecation\")\n",
            "public class MapReduceChildJVM {\n",
            "\n",
            "  private static String getTaskLogFile(LogName filter) {\n",
            "    return ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR + \n",
            "        filter.toString();\n",
            "  }\n",
            "\n",
            "  private static String getChildEnvProp(JobConf jobConf, boolean isMap) {\n",
            "    if (isMap) {\n",
            "      return JobConf.MAPRED_MAP_TASK_ENV;\n",
            "    }\n",
            "    return JobConf.MAPRED_REDUCE_TASK_ENV;\n",
            "  }\n",
            "\n",
            "  private static String getChildEnvDefaultValue(JobConf jobConf) {\n",
            "    // There is no default value for these - use the fallback value instead.\n",
            "    return jobConf.get(JobConf.MAPRED_TASK_ENV);\n",
            "  }\n",
            "\n",
            "  public static void setVMEnv(Map<String, String> environment,\n",
            "      Task task) {\n",
            "\n",
            "    JobConf conf = task.conf;\n",
            "    boolean isMap = task.isMapTask();\n",
            "\n",
            "    // Remove these before adding the user variables to prevent\n",
            "    // MRApps.setEnvFromInputProperty() from appending to them.\n",
            "    String hadoopRootLoggerKey = \"HADOOP_ROOT_LOGGER\";\n",
            "    String hadoopClientOptsKey = \"HADOOP_CLIENT_OPTS\";\n",
            "    environment.remove(hadoopRootLoggerKey);\n",
            "    environment.remove(hadoopClientOptsKey);\n",
            "\n",
            "    // Add the environment variables passed by the user\n",
            "    MRApps.setEnvFromInputProperty(environment, getChildEnvProp(conf, isMap),\n",
            "        getChildEnvDefaultValue(conf), conf);\n",
            "\n",
            "    // Set HADOOP_ROOT_LOGGER and HADOOP_CLIENTS if the user did not set them.\n",
            "    if (!environment.containsKey(hadoopRootLoggerKey)) {\n",
            "      // Set the value for logging level in the environment.\n",
            "      // This is so that, if the child forks another \"bin/hadoop\" (common in\n",
            "      // streaming) it will have the correct loglevel.\n",
            "      environment.put(hadoopRootLoggerKey,\n",
            "          MRApps.getChildLogLevel(conf, task.isMapTask()) + \",console\");\n",
            "    }\n",
            "    if (!environment.containsKey(hadoopClientOptsKey)) {\n",
            "      // TODO: The following is useful for instance in streaming tasks.\n",
            "      // Should be set in ApplicationMaster's env by the RM.\n",
            "      String hadoopClientOptsValue = System.getenv(hadoopClientOptsKey);\n",
            "      if (hadoopClientOptsValue == null) {\n",
            "        hadoopClientOptsValue = \"\";\n",
            "      } else {\n",
            "        hadoopClientOptsValue = hadoopClientOptsValue + \" \";\n",
            "      }\n",
            "      environment.put(hadoopClientOptsKey, hadoopClientOptsValue);\n",
            "    }\n",
            "\n",
            "    // Add stdout/stderr env\n",
            "    environment.put(\n",
            "        MRJobConfig.STDOUT_LOGFILE_ENV,\n",
            "        getTaskLogFile(TaskLog.LogName.STDOUT)\n",
            "        );\n",
            "    environment.put(\n",
            "        MRJobConfig.STDERR_LOGFILE_ENV,\n",
            "        getTaskLogFile(TaskLog.LogName.STDERR)\n",
            "        );\n",
            "  }\n",
            "\n",
            "  private static String getChildJavaOpts(JobConf jobConf, boolean isMapTask) {\n",
            "    return jobConf.getTaskJavaOpts(isMapTask ? TaskType.MAP : TaskType.REDUCE);\n",
            "  }\n",
            "\n",
            "  public static List<String> getVMCommand(\n",
            "      InetSocketAddress taskAttemptListenerAddr, Task task, \n",
            "      JVMId jvmID) {\n",
            "\n",
            "    TaskAttemptID attemptID = task.getTaskID();\n",
            "    JobConf conf = task.conf;\n",
            "\n",
            "    Vector<String> vargs = new Vector<String>(8);\n",
            "\n",
            "    vargs.add(MRApps.crossPlatformifyMREnv(task.conf, Environment.JAVA_HOME)\n",
            "        + \"/bin/java\");\n",
            "\n",
            "    // Add child (task) java-vm options.\n",
            "    //\n",
            "    // The following symbols if present in mapred.{map|reduce}.child.java.opts \n",
            "    // value are replaced:\n",
            "    // + @taskid@ is interpolated with value of TaskID.\n",
            "    // Other occurrences of @ will not be altered.\n",
            "    //\n",
            "    // Example with multiple arguments and substitutions, showing\n",
            "    // jvm GC logging, and start of a passwordless JVM JMX agent so can\n",
            "    // connect with jconsole and the likes to watch child memory, threads\n",
            "    // and get thread dumps.\n",
            "    //\n",
            "    //  <property>\n",
            "    //    <name>mapred.map.child.java.opts</name>\n",
            "    //    <value>-Xmx 512M -verbose:gc -Xloggc:/tmp/@taskid@.gc \\\n",
            "    //           -Dcom.sun.management.jmxremote.authenticate=false \\\n",
            "    //           -Dcom.sun.management.jmxremote.ssl=false \\\n",
            "    //    </value>\n",
            "    //  </property>\n",
            "    //\n",
            "    //  <property>\n",
            "    //    <name>mapred.reduce.child.java.opts</name>\n",
            "    //    <value>-Xmx 1024M -verbose:gc -Xloggc:/tmp/@taskid@.gc \\\n",
            "    //           -Dcom.sun.management.jmxremote.authenticate=false \\\n",
            "    //           -Dcom.sun.management.jmxremote.ssl=false \\\n",
            "    //    </value>\n",
            "    //  </property>\n",
            "    //\n",
            "    String javaOpts = getChildJavaOpts(conf, task.isMapTask());\n",
            "    javaOpts = javaOpts.replace(\"@taskid@\", attemptID.toString());\n",
            "    String [] javaOptsSplit = javaOpts.split(\" \");\n",
            "    for (int i = 0; i < javaOptsSplit.length; i++) {\n",
            "      vargs.add(javaOptsSplit[i]);\n",
            "    }\n",
            "\n",
            "    Path childTmpDir = new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n",
            "        YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n",
            "    vargs.add(\"-Djava.io.tmpdir=\" + childTmpDir);\n",
            "    MRApps.addLog4jSystemProperties(task, vargs, conf);\n",
            "\n",
            "    if (conf.getProfileEnabled()) {\n",
            "      if (conf.getProfileTaskRange(task.isMapTask()\n",
            "                                   ).isIncluded(task.getPartition())) {\n",
            "        final String profileParams = conf.get(task.isMapTask()\n",
            "            ? MRJobConfig.TASK_MAP_PROFILE_PARAMS\n",
            "            : MRJobConfig.TASK_REDUCE_PROFILE_PARAMS, conf.getProfileParams());\n",
            "        vargs.add(String.format(profileParams,\n",
            "            getTaskLogFile(TaskLog.LogName.PROFILE)));\n",
            "      }\n",
            "    }\n",
            "\n",
            "    // Add main class and its arguments \n",
            "    vargs.add(YarnChild.class.getName());  // main of Child\n",
            "    // pass TaskAttemptListener's address\n",
            "    vargs.add(taskAttemptListenerAddr.getAddress().getHostAddress()); \n",
            "    vargs.add(Integer.toString(taskAttemptListenerAddr.getPort())); \n",
            "    vargs.add(attemptID.toString());                      // pass task identifier\n",
            "\n",
            "    // Finally add the jvmID\n",
            "    vargs.add(String.valueOf(jvmID.getId()));\n",
            "    vargs.add(\"1>\" + getTaskLogFile(TaskLog.LogName.STDOUT));\n",
            "    vargs.add(\"2>\" + getTaskLogFile(TaskLog.LogName.STDERR));\n",
            "\n",
            "    // Final commmand\n",
            "    StringBuilder mergedCommand = new StringBuilder();\n",
            "    for (CharSequence str : vargs) {\n",
            "      mergedCommand.append(str).append(\" \");\n",
            "    }\n",
            "    Vector<String> vargsFinal = new Vector<String>(1);\n",
            "    vargsFinal.add(mergedCommand.toString());\n",
            "    return vargsFinal;\n",
            "  }\n",
            "}\n",
            "\n",
            "{'name': 'MapTaskAttemptImpl.java', 'path': 'hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapTaskAttemptImpl.java', 'sha': 'ab5e7f27989a56214b4b6f89c0ac1aae2bbe4e72', 'size': 2621, 'url': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapTaskAttemptImpl.java?ref=trunk', 'html_url': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapTaskAttemptImpl.java', 'git_url': 'https://api.github.com/repos/apache/hadoop/git/blobs/ab5e7f27989a56214b4b6f89c0ac1aae2bbe4e72', 'download_url': 'https://raw.githubusercontent.com/apache/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapTaskAttemptImpl.java', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapTaskAttemptImpl.java?ref=trunk', 'git': 'https://api.github.com/repos/apache/hadoop/git/blobs/ab5e7f27989a56214b4b6f89c0ac1aae2bbe4e72', 'html': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapTaskAttemptImpl.java'}}\n",
            "MapTaskAttemptImpl.java\n",
            "/**\n",
            "* Licensed to the Apache Software Foundation (ASF) under one\n",
            "* or more contributor license agreements.  See the NOTICE file\n",
            "* distributed with this work for additional information\n",
            "* regarding copyright ownership.  The ASF licenses this file\n",
            "* to you under the Apache License, Version 2.0 (the\n",
            "* \"License\"); you may not use this file except in compliance\n",
            "* with the License.  You may obtain a copy of the License at\n",
            "*\n",
            "*     http://www.apache.org/licenses/LICENSE-2.0\n",
            "*\n",
            "* Unless required by applicable law or agreed to in writing, software\n",
            "* distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "* See the License for the specific language governing permissions and\n",
            "* limitations under the License.\n",
            "*/\n",
            "\n",
            "package org.apache.hadoop.mapred;\n",
            "\n",
            "import org.apache.hadoop.fs.Path;\n",
            "import org.apache.hadoop.mapreduce.MRJobConfig;\n",
            "import org.apache.hadoop.mapreduce.TypeConverter;\n",
            "import org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier;\n",
            "import org.apache.hadoop.mapreduce.split.JobSplit.TaskSplitMetaInfo;\n",
            "import org.apache.hadoop.mapreduce.v2.api.records.TaskId;\n",
            "import org.apache.hadoop.mapreduce.v2.app.AppContext;\n",
            "import org.apache.hadoop.mapreduce.v2.app.TaskAttemptListener;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl;\n",
            "import org.apache.hadoop.security.Credentials;\n",
            "import org.apache.hadoop.security.token.Token;\n",
            "import org.apache.hadoop.yarn.event.EventHandler;\n",
            "import org.apache.hadoop.yarn.util.Clock;\n",
            "\n",
            "@SuppressWarnings(\"rawtypes\")\n",
            "public class MapTaskAttemptImpl extends TaskAttemptImpl {\n",
            "\n",
            "  private final TaskSplitMetaInfo splitInfo;\n",
            "\n",
            "  public MapTaskAttemptImpl(TaskId taskId, int attempt, \n",
            "      EventHandler eventHandler, Path jobFile, \n",
            "      int partition, TaskSplitMetaInfo splitInfo, JobConf conf,\n",
            "      TaskAttemptListener taskAttemptListener, \n",
            "      Token<JobTokenIdentifier> jobToken,\n",
            "      Credentials credentials, Clock clock,\n",
            "      AppContext appContext) {\n",
            "    super(taskId, attempt, eventHandler, \n",
            "        taskAttemptListener, jobFile, partition, conf, splitInfo.getLocations(),\n",
            "        jobToken, credentials, clock, appContext);\n",
            "    this.splitInfo = splitInfo;\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public Task createRemoteTask() {\n",
            "    //job file name is set in TaskAttempt, setting it null here\n",
            "    MapTask mapTask =\n",
            "      new MapTask(\"\", TypeConverter.fromYarn(getID()), partition,\n",
            "          splitInfo.getSplitIndex(), 1); // YARN doesn't have the concept of slots per task, set it as 1.\n",
            "    mapTask.setUser(conf.get(MRJobConfig.USER_NAME));\n",
            "    mapTask.setConf(conf);\n",
            "    return mapTask;\n",
            "  }\n",
            "\n",
            "}\n",
            "\n",
            "{'name': 'ReduceTaskAttemptImpl.java', 'path': 'hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/ReduceTaskAttemptImpl.java', 'sha': 'be5c270cf56365ebd960bd53042aa1935568e108', 'size': 2515, 'url': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/ReduceTaskAttemptImpl.java?ref=trunk', 'html_url': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/ReduceTaskAttemptImpl.java', 'git_url': 'https://api.github.com/repos/apache/hadoop/git/blobs/be5c270cf56365ebd960bd53042aa1935568e108', 'download_url': 'https://raw.githubusercontent.com/apache/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/ReduceTaskAttemptImpl.java', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/ReduceTaskAttemptImpl.java?ref=trunk', 'git': 'https://api.github.com/repos/apache/hadoop/git/blobs/be5c270cf56365ebd960bd53042aa1935568e108', 'html': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/ReduceTaskAttemptImpl.java'}}\n",
            "ReduceTaskAttemptImpl.java\n",
            "/**\n",
            "* Licensed to the Apache Software Foundation (ASF) under one\n",
            "* or more contributor license agreements.  See the NOTICE file\n",
            "* distributed with this work for additional information\n",
            "* regarding copyright ownership.  The ASF licenses this file\n",
            "* to you under the Apache License, Version 2.0 (the\n",
            "* \"License\"); you may not use this file except in compliance\n",
            "* with the License.  You may obtain a copy of the License at\n",
            "*\n",
            "*     http://www.apache.org/licenses/LICENSE-2.0\n",
            "*\n",
            "* Unless required by applicable law or agreed to in writing, software\n",
            "* distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "* See the License for the specific language governing permissions and\n",
            "* limitations under the License.\n",
            "*/\n",
            "\n",
            "package org.apache.hadoop.mapred;\n",
            "\n",
            "import org.apache.hadoop.fs.Path;\n",
            "import org.apache.hadoop.mapreduce.MRJobConfig;\n",
            "import org.apache.hadoop.mapreduce.TypeConverter;\n",
            "import org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier;\n",
            "import org.apache.hadoop.mapreduce.v2.api.records.TaskId;\n",
            "import org.apache.hadoop.mapreduce.v2.app.AppContext;\n",
            "import org.apache.hadoop.mapreduce.v2.app.TaskAttemptListener;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl;\n",
            "import org.apache.hadoop.security.Credentials;\n",
            "import org.apache.hadoop.security.token.Token;\n",
            "import org.apache.hadoop.yarn.event.EventHandler;\n",
            "import org.apache.hadoop.yarn.util.Clock;\n",
            "\n",
            "@SuppressWarnings(\"rawtypes\")\n",
            "public class ReduceTaskAttemptImpl extends TaskAttemptImpl {\n",
            "\n",
            "  private final int numMapTasks;\n",
            "\n",
            "  public ReduceTaskAttemptImpl(TaskId id, int attempt,\n",
            "      EventHandler eventHandler, Path jobFile, int partition,\n",
            "      int numMapTasks, JobConf conf,\n",
            "      TaskAttemptListener taskAttemptListener,\n",
            "      Token<JobTokenIdentifier> jobToken,\n",
            "      Credentials credentials, Clock clock,\n",
            "      AppContext appContext) {\n",
            "    super(id, attempt, eventHandler, taskAttemptListener, jobFile, partition,\n",
            "        conf, new String[] {}, jobToken, credentials, clock,\n",
            "        appContext);\n",
            "    this.numMapTasks = numMapTasks;\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public Task createRemoteTask() {\n",
            "  //job file name is set in TaskAttempt, setting it null here\n",
            "    ReduceTask reduceTask =\n",
            "      new ReduceTask(\"\", TypeConverter.fromYarn(getID()), partition,\n",
            "          numMapTasks, 1); // YARN doesn't have the concept of slots per task, set it as 1.\n",
            "  reduceTask.setUser(conf.get(MRJobConfig.USER_NAME));\n",
            "  reduceTask.setConf(conf);\n",
            "    return reduceTask;\n",
            "  }\n",
            "\n",
            "}\n",
            "\n",
            "{'name': 'TaskAttemptListenerImpl.java', 'path': 'hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java', 'sha': '5dffd735fdafdec6635a3edd35ad30725302a3d6', 'size': 27873, 'url': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java?ref=trunk', 'html_url': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java', 'git_url': 'https://api.github.com/repos/apache/hadoop/git/blobs/5dffd735fdafdec6635a3edd35ad30725302a3d6', 'download_url': 'https://raw.githubusercontent.com/apache/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java?ref=trunk', 'git': 'https://api.github.com/repos/apache/hadoop/git/blobs/5dffd735fdafdec6635a3edd35ad30725302a3d6', 'html': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java'}}\n",
            "TaskAttemptListenerImpl.java\n",
            "/**\n",
            "* Licensed to the Apache Software Foundation (ASF) under one\n",
            "* or more contributor license agreements.  See the NOTICE file\n",
            "* distributed with this work for additional information\n",
            "* regarding copyright ownership.  The ASF licenses this file\n",
            "* to you under the Apache License, Version 2.0 (the\n",
            "* \"License\"); you may not use this file except in compliance\n",
            "* with the License.  You may obtain a copy of the License at\n",
            "*\n",
            "*     http://www.apache.org/licenses/LICENSE-2.0\n",
            "*\n",
            "* Unless required by applicable law or agreed to in writing, software\n",
            "* distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "* See the License for the specific language governing permissions and\n",
            "* limitations under the License.\n",
            "*/\n",
            "\n",
            "package org.apache.hadoop.mapred;\n",
            "\n",
            "import java.io.IOException;\n",
            "import java.net.InetSocketAddress;\n",
            "import java.util.ArrayList;\n",
            "import java.util.Collections;\n",
            "import java.util.List;\n",
            "import java.util.Set;\n",
            "import java.util.concurrent.ConcurrentHashMap;\n",
            "import java.util.concurrent.ConcurrentMap;\n",
            "import java.util.concurrent.atomic.AtomicReference;\n",
            "\n",
            "import org.slf4j.Logger;\n",
            "import org.slf4j.LoggerFactory;\n",
            "\n",
            "import org.apache.hadoop.classification.VisibleForTesting;\n",
            "import org.apache.hadoop.conf.Configuration;\n",
            "import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n",
            "import org.apache.hadoop.ipc.ProtocolSignature;\n",
            "import org.apache.hadoop.ipc.RPC;\n",
            "import org.apache.hadoop.ipc.Server;\n",
            "import org.apache.hadoop.mapred.SortedRanges.Range;\n",
            "import org.apache.hadoop.mapreduce.MRJobConfig;\n",
            "import org.apache.hadoop.mapreduce.TypeConverter;\n",
            "import org.apache.hadoop.mapreduce.checkpoint.TaskCheckpointID;\n",
            "import org.apache.hadoop.mapreduce.security.token.JobTokenSecretManager;\n",
            "import org.apache.hadoop.mapreduce.util.MRJobConfUtil;\n",
            "import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId;\n",
            "import org.apache.hadoop.mapreduce.v2.api.records.TaskId;\n",
            "import org.apache.hadoop.mapreduce.v2.app.AppContext;\n",
            "import org.apache.hadoop.mapreduce.v2.app.TaskAttemptListener;\n",
            "import org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.Job;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.Task;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptDiagnosticsUpdateEvent;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEvent;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptFailEvent;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptStatusUpdateEvent;\n",
            "import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptStatusUpdateEvent.TaskAttemptStatus;\n",
            "import org.apache.hadoop.mapreduce.v2.app.rm.RMHeartbeatHandler;\n",
            "import org.apache.hadoop.mapreduce.v2.app.rm.preemption.AMPreemptionPolicy;\n",
            "import org.apache.hadoop.mapreduce.v2.app.security.authorize.MRAMPolicyProvider;\n",
            "import org.apache.hadoop.net.NetUtils;\n",
            "import org.apache.hadoop.security.authorize.PolicyProvider;\n",
            "import org.apache.hadoop.service.CompositeService;\n",
            "import org.apache.hadoop.util.StringInterner;\n",
            "import org.apache.hadoop.util.Time;\n",
            "import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;\n",
            "\n",
            "/**\n",
            " * This class is responsible for talking to the task umblical.\n",
            " * It also converts all the old data structures\n",
            " * to yarn data structures.\n",
            " * \n",
            " * This class HAS to be in this package to access package private \n",
            " * methods/classes.\n",
            " */\n",
            "public class TaskAttemptListenerImpl extends CompositeService \n",
            "    implements TaskUmbilicalProtocol, TaskAttemptListener {\n",
            "\n",
            "  private static final JvmTask TASK_FOR_INVALID_JVM = new JvmTask(null, true);\n",
            "\n",
            "  private static final Logger LOG =\n",
            "      LoggerFactory.getLogger(TaskAttemptListenerImpl.class);\n",
            "\n",
            "  private AppContext context;\n",
            "  private Server server;\n",
            "  protected TaskHeartbeatHandler taskHeartbeatHandler;\n",
            "  private RMHeartbeatHandler rmHeartbeatHandler;\n",
            "  private long commitWindowMs;\n",
            "  private InetSocketAddress address;\n",
            "  private ConcurrentMap<WrappedJvmID, org.apache.hadoop.mapred.Task>\n",
            "    jvmIDToActiveAttemptMap\n",
            "      = new ConcurrentHashMap<WrappedJvmID, org.apache.hadoop.mapred.Task>();\n",
            "\n",
            "  private ConcurrentMap<TaskAttemptId,\n",
            "      AtomicReference<TaskAttemptStatus>> attemptIdToStatus\n",
            "        = new ConcurrentHashMap<>();\n",
            "\n",
            "  /**\n",
            "   * A Map to keep track of the history of logging each task attempt.\n",
            "   */\n",
            "  private ConcurrentHashMap<TaskAttemptID, TaskProgressLogPair>\n",
            "      taskAttemptLogProgressStamps = new ConcurrentHashMap<>();\n",
            "\n",
            "  private Set<WrappedJvmID> launchedJVMs = Collections\n",
            "      .newSetFromMap(new ConcurrentHashMap<WrappedJvmID, Boolean>());\n",
            "\n",
            "  private JobTokenSecretManager jobTokenSecretManager = null;\n",
            "  private AMPreemptionPolicy preemptionPolicy;\n",
            "  private byte[] encryptedSpillKey;\n",
            "\n",
            "  public TaskAttemptListenerImpl(AppContext context,\n",
            "      JobTokenSecretManager jobTokenSecretManager,\n",
            "      RMHeartbeatHandler rmHeartbeatHandler,\n",
            "      AMPreemptionPolicy preemptionPolicy) {\n",
            "    this(context, jobTokenSecretManager, rmHeartbeatHandler,\n",
            "            preemptionPolicy, null);\n",
            "  }\n",
            "\n",
            "  public TaskAttemptListenerImpl(AppContext context,\n",
            "      JobTokenSecretManager jobTokenSecretManager,\n",
            "      RMHeartbeatHandler rmHeartbeatHandler,\n",
            "      AMPreemptionPolicy preemptionPolicy, byte[] secretShuffleKey) {\n",
            "    super(TaskAttemptListenerImpl.class.getName());\n",
            "    this.context = context;\n",
            "    this.jobTokenSecretManager = jobTokenSecretManager;\n",
            "    this.rmHeartbeatHandler = rmHeartbeatHandler;\n",
            "    this.preemptionPolicy = preemptionPolicy;\n",
            "    this.encryptedSpillKey = secretShuffleKey;\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  protected void serviceInit(Configuration conf) throws Exception {\n",
            "    registerHeartbeatHandler(conf);\n",
            "    commitWindowMs = conf.getLong(MRJobConfig.MR_AM_COMMIT_WINDOW_MS,\n",
            "        MRJobConfig.DEFAULT_MR_AM_COMMIT_WINDOW_MS);\n",
            "    // initialize the delta threshold for logging the task progress.\n",
            "    MRJobConfUtil.setTaskLogProgressDeltaThresholds(conf);\n",
            "    super.serviceInit(conf);\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  protected void serviceStart() throws Exception {\n",
            "    startRpcServer();\n",
            "    super.serviceStart();\n",
            "  }\n",
            "\n",
            "  protected void registerHeartbeatHandler(Configuration conf) {\n",
            "    taskHeartbeatHandler = new TaskHeartbeatHandler(context.getEventHandler(), \n",
            "        context.getClock(), conf.getInt(MRJobConfig.MR_AM_TASK_LISTENER_THREAD_COUNT, \n",
            "            MRJobConfig.DEFAULT_MR_AM_TASK_LISTENER_THREAD_COUNT));\n",
            "    addService(taskHeartbeatHandler);\n",
            "  }\n",
            "\n",
            "  protected void startRpcServer() {\n",
            "    Configuration conf = getConfig();\n",
            "    try {\n",
            "      server = new RPC.Builder(conf).setProtocol(TaskUmbilicalProtocol.class)\n",
            "          .setInstance(this).setBindAddress(\"0.0.0.0\")\n",
            "          .setPortRangeConfig(MRJobConfig.MR_AM_JOB_CLIENT_PORT_RANGE)\n",
            "          .setNumHandlers(\n",
            "          conf.getInt(MRJobConfig.MR_AM_TASK_LISTENER_THREAD_COUNT, \n",
            "          MRJobConfig.DEFAULT_MR_AM_TASK_LISTENER_THREAD_COUNT))\n",
            "          .setVerbose(false).setSecretManager(jobTokenSecretManager).build();\n",
            "\n",
            "      // Enable service authorization?\n",
            "      if (conf.getBoolean(\n",
            "          CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION, \n",
            "          false)) {\n",
            "        refreshServiceAcls(conf, new MRAMPolicyProvider());\n",
            "      }\n",
            "\n",
            "      server.start();\n",
            "      this.address = NetUtils.createSocketAddrForHost(\n",
            "          context.getNMHostname(),\n",
            "          server.getListenerAddress().getPort());\n",
            "    } catch (IOException e) {\n",
            "      throw new YarnRuntimeException(e);\n",
            "    }\n",
            "  }\n",
            "\n",
            "  void refreshServiceAcls(Configuration configuration, \n",
            "      PolicyProvider policyProvider) {\n",
            "    this.server.refreshServiceAcl(configuration, policyProvider);\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  protected void serviceStop() throws Exception {\n",
            "    stopRpcServer();\n",
            "    super.serviceStop();\n",
            "  }\n",
            "\n",
            "  protected void stopRpcServer() {\n",
            "    if (server != null) {\n",
            "      server.stop();\n",
            "    }\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public InetSocketAddress getAddress() {\n",
            "    return address;\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Child checking whether it can commit.\n",
            "   * \n",
            "   * <br>\n",
            "   * Commit is a two-phased protocol. First the attempt informs the\n",
            "   * ApplicationMaster that it is\n",
            "   * {@link #commitPending(TaskAttemptID, TaskStatus)}. Then it repeatedly polls\n",
            "   * the ApplicationMaster whether it {@link #canCommit(TaskAttemptID)} This is\n",
            "   * a legacy from the centralized commit protocol handling by the JobTracker.\n",
            "   */\n",
            "  @Override\n",
            "  public boolean canCommit(TaskAttemptID taskAttemptID) throws IOException {\n",
            "    LOG.info(\"Commit go/no-go request from \" + taskAttemptID.toString());\n",
            "    // An attempt is asking if it can commit its output. This can be decided\n",
            "    // only by the task which is managing the multiple attempts. So redirect the\n",
            "    // request there.\n",
            "    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n",
            "        TypeConverter.toYarn(taskAttemptID);\n",
            "\n",
            "    taskHeartbeatHandler.progressing(attemptID);\n",
            "\n",
            "    // tell task to retry later if AM has not heard from RM within the commit\n",
            "    // window to help avoid double-committing in a split-brain situation\n",
            "    long now = context.getClock().getTime();\n",
            "    if (now - rmHeartbeatHandler.getLastHeartbeatTime() > commitWindowMs) {\n",
            "      return false;\n",
            "    }\n",
            "\n",
            "    Job job = context.getJob(attemptID.getTaskId().getJobId());\n",
            "    Task task = job.getTask(attemptID.getTaskId());\n",
            "    return task.canCommit(attemptID);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * TaskAttempt is reporting that it is in commit_pending and it is waiting for\n",
            "   * the commit Response\n",
            "   * \n",
            "   * <br>\n",
            "   * Commit it a two-phased protocol. First the attempt informs the\n",
            "   * ApplicationMaster that it is\n",
            "   * {@link #commitPending(TaskAttemptID, TaskStatus)}. Then it repeatedly polls\n",
            "   * the ApplicationMaster whether it {@link #canCommit(TaskAttemptID)} This is\n",
            "   * a legacy from the centralized commit protocol handling by the JobTracker.\n",
            "   */\n",
            "  @Override\n",
            "  public void commitPending(TaskAttemptID taskAttemptID, TaskStatus taskStatsu)\n",
            "          throws IOException, InterruptedException {\n",
            "    LOG.info(\"Commit-pending state update from \" + taskAttemptID.toString());\n",
            "    // An attempt is asking if it can commit its output. This can be decided\n",
            "    // only by the task which is managing the multiple attempts. So redirect the\n",
            "    // request there.\n",
            "    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n",
            "        TypeConverter.toYarn(taskAttemptID);\n",
            "\n",
            "    taskHeartbeatHandler.progressing(attemptID);\n",
            "    //Ignorable TaskStatus? - since a task will send a LastStatusUpdate\n",
            "    context.getEventHandler().handle(\n",
            "        new TaskAttemptEvent(attemptID, \n",
            "            TaskAttemptEventType.TA_COMMIT_PENDING));\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void preempted(TaskAttemptID taskAttemptID, TaskStatus taskStatus)\n",
            "          throws IOException, InterruptedException {\n",
            "    LOG.info(\"Preempted state update from \" + taskAttemptID.toString());\n",
            "    // An attempt is telling us that it got preempted.\n",
            "    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n",
            "        TypeConverter.toYarn(taskAttemptID);\n",
            "\n",
            "    preemptionPolicy.reportSuccessfulPreemption(attemptID);\n",
            "    taskHeartbeatHandler.progressing(attemptID);\n",
            "\n",
            "    context.getEventHandler().handle(\n",
            "        new TaskAttemptEvent(attemptID,\n",
            "            TaskAttemptEventType.TA_PREEMPTED));\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void done(TaskAttemptID taskAttemptID) throws IOException {\n",
            "    LOG.info(\"Done acknowledgment from \" + taskAttemptID.toString());\n",
            "\n",
            "    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n",
            "        TypeConverter.toYarn(taskAttemptID);\n",
            "\n",
            "    taskHeartbeatHandler.progressing(attemptID);\n",
            "\n",
            "    context.getEventHandler().handle(\n",
            "        new TaskAttemptEvent(attemptID, TaskAttemptEventType.TA_DONE));\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void fatalError(TaskAttemptID taskAttemptID, String msg, boolean fastFail)\n",
            "      throws IOException {\n",
            "    // This happens only in Child and in the Task.\n",
            "    LOG.error(\"Task: \" + taskAttemptID + \" - exited : \" + msg);\n",
            "    reportDiagnosticInfo(taskAttemptID, \"Error: \" + msg);\n",
            "\n",
            "    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n",
            "        TypeConverter.toYarn(taskAttemptID);\n",
            "\n",
            "    // handling checkpoints\n",
            "    preemptionPolicy.handleFailedContainer(attemptID);\n",
            "\n",
            "    context.getEventHandler().handle(\n",
            "        new TaskAttemptFailEvent(attemptID, fastFail));\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void fsError(TaskAttemptID taskAttemptID, String message)\n",
            "      throws IOException {\n",
            "    // This happens only in Child.\n",
            "    LOG.error(\"Task: \" + taskAttemptID + \" - failed due to FSError: \"\n",
            "        + message);\n",
            "    reportDiagnosticInfo(taskAttemptID, \"FSError: \" + message);\n",
            "\n",
            "    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n",
            "        TypeConverter.toYarn(taskAttemptID);\n",
            "\n",
            "    // handling checkpoints\n",
            "    preemptionPolicy.handleFailedContainer(attemptID);\n",
            "\n",
            "    context.getEventHandler().handle(\n",
            "        new TaskAttemptFailEvent(attemptID));\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void shuffleError(TaskAttemptID taskAttemptID, String message) throws IOException {\n",
            "    // TODO: This isn't really used in any MR code. Ask for removal.    \n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public MapTaskCompletionEventsUpdate getMapCompletionEvents(\n",
            "      JobID jobIdentifier, int startIndex, int maxEvents,\n",
            "      TaskAttemptID taskAttemptID) throws IOException {\n",
            "    LOG.info(\"MapCompletionEvents request from \" + taskAttemptID.toString()\n",
            "        + \". startIndex \" + startIndex + \" maxEvents \" + maxEvents);\n",
            "\n",
            "    // TODO: shouldReset is never used. See TT. Ask for Removal.\n",
            "    boolean shouldReset = false;\n",
            "    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n",
            "      TypeConverter.toYarn(taskAttemptID);\n",
            "    TaskCompletionEvent[] events =\n",
            "        context.getJob(attemptID.getTaskId().getJobId()).getMapAttemptCompletionEvents(\n",
            "            startIndex, maxEvents);\n",
            "\n",
            "    taskHeartbeatHandler.progressing(attemptID);\n",
            "    \n",
            "    return new MapTaskCompletionEventsUpdate(events, shouldReset);\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void reportDiagnosticInfo(TaskAttemptID taskAttemptID, String diagnosticInfo)\n",
            " throws IOException {\n",
            "    diagnosticInfo = StringInterner.weakIntern(diagnosticInfo);\n",
            "    LOG.info(\"Diagnostics report from \" + taskAttemptID.toString() + \": \"\n",
            "        + diagnosticInfo);\n",
            "\n",
            "    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n",
            "      TypeConverter.toYarn(taskAttemptID);\n",
            "    taskHeartbeatHandler.progressing(attemptID);\n",
            "\n",
            "    // This is mainly used for cases where we want to propagate exception traces\n",
            "    // of tasks that fail.\n",
            "\n",
            "    // This call exists as a hadoop mapreduce legacy wherein all changes in\n",
            "    // counters/progress/phase/output-size are reported through statusUpdate()\n",
            "    // call but not diagnosticInformation.\n",
            "    context.getEventHandler().handle(\n",
            "        new TaskAttemptDiagnosticsUpdateEvent(attemptID, diagnosticInfo));\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n",
            "      TaskStatus taskStatus) throws IOException, InterruptedException {\n",
            "\n",
            "    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID =\n",
            "        TypeConverter.toYarn(taskAttemptID);\n",
            "\n",
            "    AMFeedback feedback = new AMFeedback();\n",
            "    feedback.setTaskFound(true);\n",
            "\n",
            "    AtomicReference<TaskAttemptStatus> lastStatusRef =\n",
            "        attemptIdToStatus.get(yarnAttemptID);\n",
            "    if (lastStatusRef == null) {\n",
            "      // The task is not known, but it could be in the process of tearing\n",
            "      // down gracefully or receiving a thread dump signal. Tolerate unknown\n",
            "      // tasks as long as they have unregistered recently.\n",
            "      if (!taskHeartbeatHandler.hasRecentlyUnregistered(yarnAttemptID)) {\n",
            "        LOG.error(\"Status update was called with illegal TaskAttemptId: \"\n",
            "            + yarnAttemptID);\n",
            "        feedback.setTaskFound(false);\n",
            "      }\n",
            "      return feedback;\n",
            "    }\n",
            "\n",
            "    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n",
            "    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n",
            "        && preemptionPolicy.isPreempted(yarnAttemptID)) {\n",
            "      feedback.setPreemption(true);\n",
            "      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n",
            "          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n",
            "    }\n",
            "\n",
            "    if (taskStatus == null) {\n",
            "      //We are using statusUpdate only as a simple ping\n",
            "      if (LOG.isDebugEnabled()) {\n",
            "        LOG.debug(\"Ping from \" + taskAttemptID.toString());\n",
            "      }\n",
            "      // Consider ping from the tasks for liveliness check\n",
            "      if (getConfig().getBoolean(MRJobConfig.MR_TASK_ENABLE_PING_FOR_LIVELINESS_CHECK,\n",
            "          MRJobConfig.DEFAULT_MR_TASK_ENABLE_PING_FOR_LIVELINESS_CHECK)) {\n",
            "        taskHeartbeatHandler.progressing(yarnAttemptID);\n",
            "      }\n",
            "      return feedback;\n",
            "    }\n",
            "\n",
            "    // if we are here there is an actual status update to be processed\n",
            "\n",
            "    taskHeartbeatHandler.progressing(yarnAttemptID);\n",
            "    TaskAttemptStatus taskAttemptStatus =\n",
            "        new TaskAttemptStatus();\n",
            "    taskAttemptStatus.id = yarnAttemptID;\n",
            "    // Task sends the updated progress to the TT.\n",
            "    taskAttemptStatus.progress = taskStatus.getProgress();\n",
            "    // log the new progress\n",
            "    taskAttemptLogProgressStamps.computeIfAbsent(taskAttemptID,\n",
            "        k -> new TaskProgressLogPair(taskAttemptID))\n",
            "        .update(taskStatus.getProgress());\n",
            "    // Task sends the updated state-string to the TT.\n",
            "    taskAttemptStatus.stateString = taskStatus.getStateString();\n",
            "    // Task sends the updated phase to the TT.\n",
            "    taskAttemptStatus.phase = TypeConverter.toYarn(taskStatus.getPhase());\n",
            "    // Counters are updated by the task. Convert counters into new format as\n",
            "    // that is the primary storage format inside the AM to avoid multiple\n",
            "    // conversions and unnecessary heap usage.\n",
            "    taskAttemptStatus.counters = new org.apache.hadoop.mapreduce.Counters(\n",
            "      taskStatus.getCounters());\n",
            "\n",
            "    // Map Finish time set by the task (map only)\n",
            "    if (taskStatus.getIsMap() && taskStatus.getMapFinishTime() != 0) {\n",
            "      taskAttemptStatus.mapFinishTime = taskStatus.getMapFinishTime();\n",
            "    }\n",
            "\n",
            "    // Shuffle Finish time set by the task (reduce only).\n",
            "    if (!taskStatus.getIsMap() && taskStatus.getShuffleFinishTime() != 0) {\n",
            "      taskAttemptStatus.shuffleFinishTime = taskStatus.getShuffleFinishTime();\n",
            "    }\n",
            "\n",
            "    // Sort finish time set by the task (reduce only).\n",
            "    if (!taskStatus.getIsMap() && taskStatus.getSortFinishTime() != 0) {\n",
            "      taskAttemptStatus.sortFinishTime = taskStatus.getSortFinishTime();\n",
            "    }\n",
            "\n",
            "    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n",
            "    //taskAttemptStatus.taskState =  TypeConverter.toYarn(taskStatus.getRunState());\n",
            "    \n",
            "    //set the fetch failures\n",
            "    if (taskStatus.getFetchFailedMaps() != null \n",
            "        && taskStatus.getFetchFailedMaps().size() > 0) {\n",
            "      taskAttemptStatus.fetchFailedMaps = \n",
            "        new ArrayList<org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId>();\n",
            "      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n",
            "        taskAttemptStatus.fetchFailedMaps.add(\n",
            "            TypeConverter.toYarn(failedMapId));\n",
            "      }\n",
            "    }\n",
            "\n",
            " // Task sends the information about the nextRecordRange to the TT\n",
            "    \n",
            "//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n",
            "//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n",
            "//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n",
            "//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n",
            "//    // This was used by TT to do counter updates only once every minute. So this\n",
            "//    // isn't ever changed by the Task itself.\n",
            "//    taskStatus.getIncludeCounters();\n",
            "\n",
            "    coalesceStatusUpdate(yarnAttemptID, taskAttemptStatus, lastStatusRef);\n",
            "\n",
            "    return feedback;\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public long getProtocolVersion(String arg0, long arg1) throws IOException {\n",
            "    return TaskUmbilicalProtocol.versionID;\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void reportNextRecordRange(TaskAttemptID taskAttemptID, Range range)\n",
            "      throws IOException {\n",
            "    // This is used when the feature of skipping records is enabled.\n",
            "\n",
            "    // This call exists as a hadoop mapreduce legacy wherein all changes in\n",
            "    // counters/progress/phase/output-size are reported through statusUpdate()\n",
            "    // call but not the next record range information.\n",
            "    throw new IOException(\"Not yet implemented.\");\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public JvmTask getTask(JvmContext context) throws IOException {\n",
            "\n",
            "    // A rough imitation of code from TaskTracker.\n",
            "\n",
            "    JVMId jvmId = context.jvmId;\n",
            "    LOG.info(\"JVM with ID : \" + jvmId + \" asked for a task\");\n",
            "\n",
            "    JvmTask jvmTask = null;\n",
            "    // TODO: Is it an authorized container to get a task? Otherwise return null.\n",
            "\n",
            "    // TODO: Child.java's firstTaskID isn't really firstTaskID. Ask for update\n",
            "    // to jobId and task-type.\n",
            "\n",
            "    WrappedJvmID wJvmID = new WrappedJvmID(jvmId.getJobId(), jvmId.isMap,\n",
            "        jvmId.getId());\n",
            "\n",
            "    // Try to look up the task. We remove it directly as we don't give\n",
            "    // multiple tasks to a JVM\n",
            "    if (!jvmIDToActiveAttemptMap.containsKey(wJvmID)) {\n",
            "      LOG.info(\"JVM with ID: \" + jvmId + \" is invalid and will be killed.\");\n",
            "      jvmTask = TASK_FOR_INVALID_JVM;\n",
            "    } else {\n",
            "      if (!launchedJVMs.contains(wJvmID)) {\n",
            "        jvmTask = null;\n",
            "        LOG.info(\"JVM with ID: \" + jvmId\n",
            "            + \" asking for task before AM launch registered. Given null task\");\n",
            "      } else {\n",
            "        // remove the task as it is no more needed and free up the memory.\n",
            "        // Also we have already told the JVM to process a task, so it is no\n",
            "        // longer pending, and further request should ask it to exit.\n",
            "        org.apache.hadoop.mapred.Task task =\n",
            "            jvmIDToActiveAttemptMap.remove(wJvmID);\n",
            "        launchedJVMs.remove(wJvmID);\n",
            "        LOG.info(\"JVM with ID: \" + jvmId + \" given task: \" + task.getTaskID());\n",
            "        task.setEncryptedSpillKey(encryptedSpillKey);\n",
            "        jvmTask = new JvmTask(task, false);\n",
            "      }\n",
            "    }\n",
            "    return jvmTask;\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void registerPendingTask(\n",
            "      org.apache.hadoop.mapred.Task task, WrappedJvmID jvmID) {\n",
            "    // Create the mapping so that it is easy to look up\n",
            "    // when the jvm comes back to ask for Task.\n",
            "\n",
            "    // A JVM not present in this map is an illegal task/JVM.\n",
            "    jvmIDToActiveAttemptMap.put(jvmID, task);\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void registerLaunchedTask(\n",
            "      org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID,\n",
            "      WrappedJvmID jvmId) {\n",
            "    // The AM considers the task to be launched (Has asked the NM to launch it)\n",
            "    // The JVM will only be given a task after this registartion.\n",
            "    launchedJVMs.add(jvmId);\n",
            "\n",
            "    taskHeartbeatHandler.register(attemptID);\n",
            "\n",
            "    attemptIdToStatus.put(attemptID, new AtomicReference<>());\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void unregister(\n",
            "      org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID,\n",
            "      WrappedJvmID jvmID) {\n",
            "\n",
            "    // Unregistration also comes from the same TaskAttempt which does the\n",
            "    // registration. Events are ordered at TaskAttempt, so unregistration will\n",
            "    // always come after registration.\n",
            "\n",
            "    // Remove from launchedJVMs before jvmIDToActiveAttemptMap to avoid\n",
            "    // synchronization issue with getTask(). getTask should be checking\n",
            "    // jvmIDToActiveAttemptMap before it checks launchedJVMs.\n",
            " \n",
            "    // remove the mappings if not already removed\n",
            "    launchedJVMs.remove(jvmID);\n",
            "    jvmIDToActiveAttemptMap.remove(jvmID);\n",
            "\n",
            "    //unregister this attempt\n",
            "    taskHeartbeatHandler.unregister(attemptID);\n",
            "\n",
            "    attemptIdToStatus.remove(attemptID);\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public ProtocolSignature getProtocolSignature(String protocol,\n",
            "      long clientVersion, int clientMethodsHash) throws IOException {\n",
            "    return ProtocolSignature.getProtocolSignature(this, \n",
            "        protocol, clientVersion, clientMethodsHash);\n",
            "  }\n",
            "\n",
            "  // task checkpoint bookeeping\n",
            "  @Override\n",
            "  public TaskCheckpointID getCheckpointID(TaskID taskId) {\n",
            "    TaskId tid = TypeConverter.toYarn(taskId);\n",
            "    return preemptionPolicy.getCheckpointID(tid);\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void setCheckpointID(TaskID taskId, TaskCheckpointID cid) {\n",
            "    TaskId tid = TypeConverter.toYarn(taskId);\n",
            "    preemptionPolicy.setCheckpointID(tid, cid);\n",
            "  }\n",
            "\n",
            "  private void coalesceStatusUpdate(TaskAttemptId yarnAttemptID,\n",
            "      TaskAttemptStatus taskAttemptStatus,\n",
            "      AtomicReference<TaskAttemptStatus> lastStatusRef) {\n",
            "    List<TaskAttemptId> fetchFailedMaps = taskAttemptStatus.fetchFailedMaps;\n",
            "    TaskAttemptStatus lastStatus = null;\n",
            "    boolean done = false;\n",
            "    while (!done) {\n",
            "      lastStatus = lastStatusRef.get();\n",
            "      if (lastStatus != null && lastStatus.fetchFailedMaps != null) {\n",
            "        // merge fetchFailedMaps from the previous update\n",
            "        if (taskAttemptStatus.fetchFailedMaps == null) {\n",
            "          taskAttemptStatus.fetchFailedMaps = lastStatus.fetchFailedMaps;\n",
            "        } else {\n",
            "          taskAttemptStatus.fetchFailedMaps =\n",
            "              new ArrayList<>(lastStatus.fetchFailedMaps.size() +\n",
            "                  fetchFailedMaps.size());\n",
            "          taskAttemptStatus.fetchFailedMaps.addAll(\n",
            "              lastStatus.fetchFailedMaps);\n",
            "          taskAttemptStatus.fetchFailedMaps.addAll(\n",
            "              fetchFailedMaps);\n",
            "        }\n",
            "      }\n",
            "\n",
            "      // lastStatusRef may be changed by either the AsyncDispatcher when\n",
            "      // it processes the update, or by another IPC server handler\n",
            "      done = lastStatusRef.compareAndSet(lastStatus, taskAttemptStatus);\n",
            "      if (!done) {\n",
            "        LOG.info(\"TaskAttempt \" + yarnAttemptID +\n",
            "            \": lastStatusRef changed by another thread, retrying...\");\n",
            "        // let's revert taskAttemptStatus.fetchFailedMaps\n",
            "        taskAttemptStatus.fetchFailedMaps = fetchFailedMaps;\n",
            "      }\n",
            "    }\n",
            "\n",
            "    boolean asyncUpdatedNeeded = (lastStatus == null);\n",
            "    if (asyncUpdatedNeeded) {\n",
            "      context.getEventHandler().handle(\n",
            "          new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n",
            "              lastStatusRef));\n",
            "    }\n",
            "  }\n",
            "\n",
            "  @VisibleForTesting\n",
            "  ConcurrentMap<TaskAttemptId,\n",
            "      AtomicReference<TaskAttemptStatus>> getAttemptIdToStatus() {\n",
            "    return attemptIdToStatus;\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Entity to keep track of the taskAttempt, last time it was logged,\n",
            "   * and the\n",
            "   * progress that has been logged.\n",
            "   */\n",
            "  class TaskProgressLogPair {\n",
            "\n",
            "    /**\n",
            "     * The taskAttemptId of that history record.\n",
            "     */\n",
            "    private final TaskAttemptID taskAttemptID;\n",
            "    /**\n",
            "     * Timestamp of last time the progress was logged.\n",
            "     */\n",
            "    private volatile long logTimeStamp;\n",
            "    /**\n",
            "     * Snapshot of the last logged progress.\n",
            "     */\n",
            "    private volatile double prevProgress;\n",
            "\n",
            "    TaskProgressLogPair(final TaskAttemptID attemptID) {\n",
            "      taskAttemptID = attemptID;\n",
            "      prevProgress = 0.0;\n",
            "      logTimeStamp = 0;\n",
            "    }\n",
            "\n",
            "    private void resetLog(final boolean doLog,\n",
            "        final float progress, final double processedProgress,\n",
            "        final long timestamp) {\n",
            "      if (doLog) {\n",
            "        prevProgress = processedProgress;\n",
            "        logTimeStamp = timestamp;\n",
            "        LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n",
            "            + progress);\n",
            "      } else {\n",
            "        if (LOG.isDebugEnabled()) {\n",
            "          LOG.debug(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n",
            "              + progress);\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "\n",
            "    public void update(final float progress) {\n",
            "      final double processedProgress =\n",
            "          MRJobConfUtil.convertTaskProgressToFactor(progress);\n",
            "      final double diffProgress = processedProgress - prevProgress;\n",
            "      final long currentTime = Time.monotonicNow();\n",
            "      boolean result =\n",
            "          (Double.compare(diffProgress,\n",
            "              MRJobConfUtil.getTaskProgressMinDeltaThreshold()) >= 0);\n",
            "      if (!result) {\n",
            "        // check if time has expired.\n",
            "        result = ((currentTime - logTimeStamp)\n",
            "            >= MRJobConfUtil.getTaskProgressWaitDeltaTimeThreshold());\n",
            "      }\n",
            "      // It is helpful to log the progress when it reaches 1.0F.\n",
            "      if (Float.compare(progress, 1.0f) == 0) {\n",
            "        result = true;\n",
            "        taskAttemptLogProgressStamps.remove(taskAttemptID);\n",
            "      }\n",
            "      resetLog(result, progress, processedProgress, currentTime);\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "{'name': 'WrappedJvmID.java', 'path': 'hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedJvmID.java', 'sha': '1f45c40601492001b0a14f4e74b56a1bde9deb73', 'size': 1042, 'url': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedJvmID.java?ref=trunk', 'html_url': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedJvmID.java', 'git_url': 'https://api.github.com/repos/apache/hadoop/git/blobs/1f45c40601492001b0a14f4e74b56a1bde9deb73', 'download_url': 'https://raw.githubusercontent.com/apache/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedJvmID.java', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedJvmID.java?ref=trunk', 'git': 'https://api.github.com/repos/apache/hadoop/git/blobs/1f45c40601492001b0a14f4e74b56a1bde9deb73', 'html': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedJvmID.java'}}\n",
            "WrappedJvmID.java\n",
            "/**\n",
            "* Licensed to the Apache Software Foundation (ASF) under one\n",
            "* or more contributor license agreements.  See the NOTICE file\n",
            "* distributed with this work for additional information\n",
            "* regarding copyright ownership.  The ASF licenses this file\n",
            "* to you under the Apache License, Version 2.0 (the\n",
            "* \"License\"); you may not use this file except in compliance\n",
            "* with the License.  You may obtain a copy of the License at\n",
            "*\n",
            "*     http://www.apache.org/licenses/LICENSE-2.0\n",
            "*\n",
            "* Unless required by applicable law or agreed to in writing, software\n",
            "* distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "* See the License for the specific language governing permissions and\n",
            "* limitations under the License.\n",
            "*/\n",
            "\n",
            "package org.apache.hadoop.mapred;\n",
            "\n",
            "/**\n",
            " * A simple wrapper for increasing the visibility.\n",
            " */\n",
            "public class WrappedJvmID extends JVMId {\n",
            "\n",
            "  public WrappedJvmID(JobID jobID, boolean mapTask, long nextLong) {\n",
            "    super(jobID, mapTask, nextLong);\n",
            "  }\n",
            "\n",
            "}\n",
            "\n",
            "{'name': 'WrappedPeriodicStatsAccumulator.java', 'path': 'hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedPeriodicStatsAccumulator.java', 'sha': 'e55c0ad2641e27ef909e7549ebca161685432157', 'size': 1202, 'url': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedPeriodicStatsAccumulator.java?ref=trunk', 'html_url': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedPeriodicStatsAccumulator.java', 'git_url': 'https://api.github.com/repos/apache/hadoop/git/blobs/e55c0ad2641e27ef909e7549ebca161685432157', 'download_url': 'https://raw.githubusercontent.com/apache/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedPeriodicStatsAccumulator.java', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedPeriodicStatsAccumulator.java?ref=trunk', 'git': 'https://api.github.com/repos/apache/hadoop/git/blobs/e55c0ad2641e27ef909e7549ebca161685432157', 'html': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedPeriodicStatsAccumulator.java'}}\n",
            "WrappedPeriodicStatsAccumulator.java\n",
            "/**\n",
            " * Licensed to the Apache Software Foundation (ASF) under one\n",
            " * or more contributor license agreements.  See the NOTICE file\n",
            " * distributed with this work for additional information\n",
            " * regarding copyright ownership.  The ASF licenses this file\n",
            " * to you under the Apache License, Version 2.0 (the\n",
            " * \"License\"); you may not use this file except in compliance\n",
            " * with the License.  You may obtain a copy of the License at\n",
            " *\n",
            " *     http://www.apache.org/licenses/LICENSE-2.0\n",
            " *\n",
            " * Unless required by applicable law or agreed to in writing, software\n",
            " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            " * See the License for the specific language governing permissions and\n",
            " * limitations under the License.\n",
            " */\n",
            "\n",
            "package org.apache.hadoop.mapred;\n",
            "\n",
            "//Workaround for PeriodicStateAccumulator being package access\n",
            "public class WrappedPeriodicStatsAccumulator {\n",
            "\n",
            "  private PeriodicStatsAccumulator real;\n",
            "\n",
            "  public WrappedPeriodicStatsAccumulator(PeriodicStatsAccumulator real) {\n",
            "    this.real = real;\n",
            "  }\n",
            "  \n",
            "  public void extend(double newProgress, int newValue) {\n",
            "    real.extend(newProgress, newValue);\n",
            "  }\n",
            "}\n",
            "\n",
            "{'name': 'WrappedProgressSplitsBlock.java', 'path': 'hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedProgressSplitsBlock.java', 'sha': 'f79580e65b2b2ca1b135d9f7e519c89b620c426f', 'size': 2558, 'url': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedProgressSplitsBlock.java?ref=trunk', 'html_url': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedProgressSplitsBlock.java', 'git_url': 'https://api.github.com/repos/apache/hadoop/git/blobs/f79580e65b2b2ca1b135d9f7e519c89b620c426f', 'download_url': 'https://raw.githubusercontent.com/apache/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedProgressSplitsBlock.java', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedProgressSplitsBlock.java?ref=trunk', 'git': 'https://api.github.com/repos/apache/hadoop/git/blobs/f79580e65b2b2ca1b135d9f7e519c89b620c426f', 'html': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/WrappedProgressSplitsBlock.java'}}\n",
            "WrappedProgressSplitsBlock.java\n",
            "/**\n",
            " * Licensed to the Apache Software Foundation (ASF) under one\n",
            " * or more contributor license agreements.  See the NOTICE file\n",
            " * distributed with this work for additional information\n",
            " * regarding copyright ownership.  The ASF licenses this file\n",
            " * to you under the Apache License, Version 2.0 (the\n",
            " * \"License\"); you may not use this file except in compliance\n",
            " * with the License.  You may obtain a copy of the License at\n",
            " *\n",
            " *     http://www.apache.org/licenses/LICENSE-2.0\n",
            " *\n",
            " * Unless required by applicable law or agreed to in writing, software\n",
            " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            " * See the License for the specific language governing permissions and\n",
            " * limitations under the License.\n",
            " */\n",
            "\n",
            "package org.apache.hadoop.mapred;\n",
            "\n",
            "// Workaround for ProgressSplitBlock being package access\n",
            "public class WrappedProgressSplitsBlock extends ProgressSplitsBlock {\n",
            "  private WrappedPeriodicStatsAccumulator wrappedProgressWallclockTime;\n",
            "  private WrappedPeriodicStatsAccumulator wrappedProgressCPUTime;\n",
            "  private WrappedPeriodicStatsAccumulator wrappedProgressVirtualMemoryKbytes;\n",
            "  private WrappedPeriodicStatsAccumulator wrappedProgressPhysicalMemoryKbytes;\n",
            "\n",
            "  public WrappedProgressSplitsBlock(int numberSplits) {\n",
            "    super(numberSplits);\n",
            "  }\n",
            "\n",
            "  public int[][] burst() {\n",
            "    return super.burst();\n",
            "  }\n",
            "\n",
            "  public WrappedPeriodicStatsAccumulator getProgressWallclockTime() {\n",
            "    if (wrappedProgressWallclockTime == null) {\n",
            "      wrappedProgressWallclockTime = new WrappedPeriodicStatsAccumulator(\n",
            "          progressWallclockTime);\n",
            "    }\n",
            "    return wrappedProgressWallclockTime;\n",
            "  }\n",
            "\n",
            "  public WrappedPeriodicStatsAccumulator getProgressCPUTime() {\n",
            "    if (wrappedProgressCPUTime == null) {\n",
            "      wrappedProgressCPUTime = new WrappedPeriodicStatsAccumulator(\n",
            "          progressCPUTime);\n",
            "    }\n",
            "    return wrappedProgressCPUTime;\n",
            "  }\n",
            "\n",
            "  public WrappedPeriodicStatsAccumulator getProgressVirtualMemoryKbytes() {\n",
            "    if (wrappedProgressVirtualMemoryKbytes == null) {\n",
            "      wrappedProgressVirtualMemoryKbytes = new WrappedPeriodicStatsAccumulator(\n",
            "          progressVirtualMemoryKbytes);\n",
            "    }\n",
            "    return wrappedProgressVirtualMemoryKbytes;\n",
            "  }\n",
            "\n",
            "  public WrappedPeriodicStatsAccumulator getProgressPhysicalMemoryKbytes() {\n",
            "    if (wrappedProgressPhysicalMemoryKbytes == null) {\n",
            "      wrappedProgressPhysicalMemoryKbytes = new WrappedPeriodicStatsAccumulator(\n",
            "          progressPhysicalMemoryKbytes);\n",
            "    }\n",
            "    return wrappedProgressPhysicalMemoryKbytes;\n",
            "  }\n",
            "}\n",
            "{'name': 'YarnChild.java', 'path': 'hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java', 'sha': 'bbf527ebff53a968ee0e14137d51db092923d816', 'size': 14883, 'url': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java?ref=trunk', 'html_url': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java', 'git_url': 'https://api.github.com/repos/apache/hadoop/git/blobs/bbf527ebff53a968ee0e14137d51db092923d816', 'download_url': 'https://raw.githubusercontent.com/apache/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java?ref=trunk', 'git': 'https://api.github.com/repos/apache/hadoop/git/blobs/bbf527ebff53a968ee0e14137d51db092923d816', 'html': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java'}}\n",
            "YarnChild.java\n",
            "/**\n",
            "* Licensed to the Apache Software Foundation (ASF) under one\n",
            "* or more contributor license agreements.  See the NOTICE file\n",
            "* distributed with this work for additional information\n",
            "* regarding copyright ownership.  The ASF licenses this file\n",
            "* to you under the Apache License, Version 2.0 (the\n",
            "* \"License\"); you may not use this file except in compliance\n",
            "* with the License.  You may obtain a copy of the License at\n",
            "*\n",
            "*     http://www.apache.org/licenses/LICENSE-2.0\n",
            "*\n",
            "* Unless required by applicable law or agreed to in writing, software\n",
            "* distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "* See the License for the specific language governing permissions and\n",
            "* limitations under the License.\n",
            "*/\n",
            "\n",
            "package org.apache.hadoop.mapred;\n",
            "\n",
            "import static java.util.concurrent.TimeUnit.MILLISECONDS;\n",
            "\n",
            "import java.io.IOException;\n",
            "import java.io.OutputStream;\n",
            "import java.net.InetSocketAddress;\n",
            "import java.security.PrivilegedExceptionAction;\n",
            "import java.util.concurrent.ScheduledExecutorService;\n",
            "\n",
            "import org.apache.commons.lang3.exception.ExceptionUtils;\n",
            "import org.apache.hadoop.fs.FSError;\n",
            "import org.apache.hadoop.fs.FileSystem;\n",
            "import org.apache.hadoop.fs.LocalDirAllocator;\n",
            "import org.apache.hadoop.fs.Path;\n",
            "import org.apache.hadoop.fs.ClusterStorageCapacityExceededException;\n",
            "import org.apache.hadoop.fs.permission.FsPermission;\n",
            "import org.apache.hadoop.io.IOUtils;\n",
            "import org.apache.hadoop.ipc.CallerContext;\n",
            "import org.apache.hadoop.ipc.RPC;\n",
            "import org.apache.hadoop.mapreduce.MRConfig;\n",
            "import org.apache.hadoop.mapreduce.MRJobConfig;\n",
            "import org.apache.hadoop.mapreduce.TaskType;\n",
            "import org.apache.hadoop.mapreduce.counters.Limits;\n",
            "import org.apache.hadoop.mapreduce.security.TokenCache;\n",
            "import org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier;\n",
            "import org.apache.hadoop.mapreduce.security.token.JobTokenSecretManager;\n",
            "import org.apache.hadoop.mapreduce.v2.util.MRApps;\n",
            "import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;\n",
            "import org.apache.hadoop.metrics2.source.JvmMetrics;\n",
            "import org.apache.hadoop.net.NetUtils;\n",
            "import org.apache.hadoop.security.Credentials;\n",
            "import org.apache.hadoop.security.SecurityUtil;\n",
            "import org.apache.hadoop.security.UserGroupInformation;\n",
            "import org.apache.hadoop.security.token.Token;\n",
            "import org.apache.hadoop.util.DiskChecker.DiskErrorException;\n",
            "import org.apache.hadoop.util.ShutdownHookManager;\n",
            "import org.apache.hadoop.util.StringUtils;\n",
            "import org.apache.hadoop.yarn.YarnUncaughtExceptionHandler;\n",
            "import org.apache.hadoop.yarn.api.ApplicationConstants;\n",
            "import org.apache.hadoop.yarn.api.ApplicationConstants.Environment;\n",
            "import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;\n",
            "import org.apache.hadoop.yarn.api.records.ContainerId;\n",
            "\n",
            "import org.slf4j.Logger;\n",
            "import org.slf4j.LoggerFactory;\n",
            "\n",
            "import org.apache.hadoop.classification.VisibleForTesting;\n",
            "\n",
            "/**\n",
            " * The main() for MapReduce task processes.\n",
            " */\n",
            "class YarnChild {\n",
            "\n",
            "  private static final Logger LOG = LoggerFactory.getLogger(YarnChild.class);\n",
            "\n",
            "  static volatile TaskAttemptID taskid = null;\n",
            "\n",
            "  public static void main(String[] args) throws Throwable {\n",
            "    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n",
            "    LOG.debug(\"Child starting\");\n",
            "\n",
            "    final JobConf job = new JobConf(MRJobConfig.JOB_CONF_FILE);\n",
            "    // Initing with our JobConf allows us to avoid loading confs twice\n",
            "    Limits.init(job);\n",
            "    UserGroupInformation.setConfiguration(job);\n",
            "    // MAPREDUCE-6565: need to set configuration for SecurityUtil.\n",
            "    SecurityUtil.setConfiguration(job);\n",
            "\n",
            "    String host = args[0];\n",
            "    int port = Integer.parseInt(args[1]);\n",
            "    final InetSocketAddress address =\n",
            "        NetUtils.createSocketAddrForHost(host, port);\n",
            "    final TaskAttemptID firstTaskid = TaskAttemptID.forName(args[2]);\n",
            "    long jvmIdLong = Long.parseLong(args[3]);\n",
            "    JVMId jvmId = new JVMId(firstTaskid.getJobID(),\n",
            "        firstTaskid.getTaskType() == TaskType.MAP, jvmIdLong);\n",
            "    \n",
            "    CallerContext.setCurrent(\n",
            "        new CallerContext.Builder(\"mr_\" + firstTaskid.toString()).build());\n",
            "\n",
            "    // initialize metrics\n",
            "    DefaultMetricsSystem.initialize(\n",
            "        StringUtils.camelize(firstTaskid.getTaskType().name()) +\"Task\");\n",
            "\n",
            "    // Security framework already loaded the tokens into current ugi\n",
            "    Credentials credentials =\n",
            "        UserGroupInformation.getCurrentUser().getCredentials();\n",
            "    LOG.info(\"Executing with tokens: {}\", credentials.getAllTokens());\n",
            "\n",
            "    // Create TaskUmbilicalProtocol as actual task owner.\n",
            "    UserGroupInformation taskOwner =\n",
            "      UserGroupInformation.createRemoteUser(firstTaskid.getJobID().toString());\n",
            "    Token<JobTokenIdentifier> jt = TokenCache.getJobToken(credentials);\n",
            "    SecurityUtil.setTokenService(jt, address);\n",
            "    taskOwner.addToken(jt);\n",
            "    final TaskUmbilicalProtocol umbilical =\n",
            "      taskOwner.doAs(new PrivilegedExceptionAction<TaskUmbilicalProtocol>() {\n",
            "      @Override\n",
            "      public TaskUmbilicalProtocol run() throws Exception {\n",
            "        return (TaskUmbilicalProtocol)RPC.getProxy(TaskUmbilicalProtocol.class,\n",
            "            TaskUmbilicalProtocol.versionID, address, job);\n",
            "      }\n",
            "    });\n",
            "\n",
            "    // report non-pid to application master\n",
            "    JvmContext context = new JvmContext(jvmId, \"-1000\");\n",
            "    LOG.debug(\"PID: \" + System.getenv().get(\"JVM_PID\"));\n",
            "    Task task = null;\n",
            "    UserGroupInformation childUGI = null;\n",
            "    ScheduledExecutorService logSyncer = null;\n",
            "\n",
            "    try {\n",
            "      int idleLoopCount = 0;\n",
            "      JvmTask myTask = null;\n",
            "      // poll for new task\n",
            "      for (int idle = 0; null == myTask; ++idle) {\n",
            "        long sleepTimeMilliSecs = Math.min(idle * 500, 1500);\n",
            "        LOG.info(\"Sleeping for \" + sleepTimeMilliSecs\n",
            "            + \"ms before retrying again. Got null now.\");\n",
            "        MILLISECONDS.sleep(sleepTimeMilliSecs);\n",
            "        myTask = umbilical.getTask(context);\n",
            "      }\n",
            "      if (myTask.shouldDie()) {\n",
            "        return;\n",
            "      }\n",
            "\n",
            "      task = myTask.getTask();\n",
            "      YarnChild.taskid = task.getTaskID();\n",
            "\n",
            "      // Create the job-conf and set credentials\n",
            "      configureTask(job, task, credentials, jt);\n",
            "\n",
            "      // log the system properties\n",
            "      String systemPropsToLog = MRApps.getSystemPropertiesToLog(job);\n",
            "      if (systemPropsToLog != null) {\n",
            "        LOG.info(systemPropsToLog);\n",
            "      }\n",
            "\n",
            "      // Initiate Java VM metrics\n",
            "      JvmMetrics.initSingleton(jvmId.toString(), job.getSessionId());\n",
            "      childUGI = UserGroupInformation.createRemoteUser(System\n",
            "          .getenv(ApplicationConstants.Environment.USER.toString()));\n",
            "      // Add tokens to new user so that it may execute its task correctly.\n",
            "      childUGI.addCredentials(credentials);\n",
            "\n",
            "      // set job classloader if configured before invoking the task\n",
            "      MRApps.setJobClassLoader(job);\n",
            "\n",
            "      logSyncer = TaskLog.createLogSyncer();\n",
            "\n",
            "      // Create a final reference to the task for the doAs block\n",
            "      final Task taskFinal = task;\n",
            "      childUGI.doAs(new PrivilegedExceptionAction<Object>() {\n",
            "        @Override\n",
            "        public Object run() throws Exception {\n",
            "          // use job-specified working directory\n",
            "          setEncryptedSpillKeyIfRequired(taskFinal);\n",
            "          FileSystem.get(job).setWorkingDirectory(job.getWorkingDirectory());\n",
            "          taskFinal.run(job, umbilical); // run the task\n",
            "          return null;\n",
            "        }\n",
            "      });\n",
            "    } catch (FSError e) {\n",
            "      LOG.error(\"FSError from child\", e);\n",
            "      if (!ShutdownHookManager.get().isShutdownInProgress()) {\n",
            "        umbilical.fsError(taskid, e.getMessage());\n",
            "      }\n",
            "    } catch (Exception exception) {\n",
            "      LOG.warn(\"Exception running child : \"\n",
            "          + StringUtils.stringifyException(exception));\n",
            "      try {\n",
            "        if (task != null) {\n",
            "          // do cleanup for the task\n",
            "          if (childUGI == null) { // no need to job into doAs block\n",
            "            task.taskCleanup(umbilical);\n",
            "          } else {\n",
            "            final Task taskFinal = task;\n",
            "            childUGI.doAs(new PrivilegedExceptionAction<Object>() {\n",
            "              @Override\n",
            "              public Object run() throws Exception {\n",
            "                taskFinal.taskCleanup(umbilical);\n",
            "                return null;\n",
            "              }\n",
            "            });\n",
            "          }\n",
            "        }\n",
            "      } catch (Exception e) {\n",
            "        LOG.info(\"Exception cleaning up: \" + StringUtils.stringifyException(e));\n",
            "      }\n",
            "      // Report back any failures, for diagnostic purposes\n",
            "      if (taskid != null) {\n",
            "        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n",
            "          reportError(exception, task, umbilical);\n",
            "        }\n",
            "      }\n",
            "    } catch (Throwable throwable) {\n",
            "      LOG.error(\"Error running child : \"\n",
            "    \t        + StringUtils.stringifyException(throwable));\n",
            "      if (taskid != null) {\n",
            "        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n",
            "          Throwable tCause = throwable.getCause();\n",
            "          String cause =\n",
            "              tCause == null ? throwable.getMessage() : StringUtils\n",
            "                  .stringifyException(tCause);\n",
            "          umbilical.fatalError(taskid, cause, false);\n",
            "        }\n",
            "      }\n",
            "    } finally {\n",
            "      RPC.stopProxy(umbilical);\n",
            "      DefaultMetricsSystem.shutdown();\n",
            "      TaskLog.syncLogsShutdown(logSyncer);\n",
            "    }\n",
            "  }\n",
            "\n",
            "  @VisibleForTesting\n",
            "  static void reportError(Exception exception, Task task,\n",
            "      TaskUmbilicalProtocol umbilical) throws IOException {\n",
            "    boolean fastFailJob = false;\n",
            "    boolean hasClusterStorageCapacityExceededException =\n",
            "        ExceptionUtils.indexOfType(exception,\n",
            "            ClusterStorageCapacityExceededException.class) != -1;\n",
            "    if (hasClusterStorageCapacityExceededException) {\n",
            "      boolean killJobWhenExceedClusterStorageCapacity = task.getConf()\n",
            "          .getBoolean(MRJobConfig.JOB_DFS_STORAGE_CAPACITY_KILL_LIMIT_EXCEED,\n",
            "              MRJobConfig.DEFAULT_JOB_DFS_STORAGE_CAPACITY_KILL_LIMIT_EXCEED);\n",
            "      if (killJobWhenExceedClusterStorageCapacity) {\n",
            "        LOG.error(\n",
            "            \"Fast fail the job because the cluster storage capacity was exceeded.\");\n",
            "        fastFailJob = true;\n",
            "      }\n",
            "    }\n",
            "    umbilical.fatalError(taskid, StringUtils.stringifyException(exception),\n",
            "        fastFailJob);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Utility method to check if the Encrypted Spill Key needs to be set into the\n",
            "   * user credentials of the user running the Map / Reduce Task\n",
            "   * @param task The Map / Reduce task to set the Encrypted Spill information in\n",
            "   * @throws Exception\n",
            "   */\n",
            "  public static void setEncryptedSpillKeyIfRequired(Task task) throws\n",
            "          Exception {\n",
            "    if ((task != null) && (task.getEncryptedSpillKey() != null) && (task\n",
            "            .getEncryptedSpillKey().length > 1)) {\n",
            "      Credentials creds =\n",
            "              UserGroupInformation.getCurrentUser().getCredentials();\n",
            "      TokenCache.setEncryptedSpillKey(task.getEncryptedSpillKey(), creds);\n",
            "      UserGroupInformation.getCurrentUser().addCredentials(creds);\n",
            "    }\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Configure mapred-local dirs. This config is used by the task for finding\n",
            "   * out an output directory.\n",
            "   * @throws IOException \n",
            "   */\n",
            "  private static void configureLocalDirs(Task task, JobConf job) throws IOException {\n",
            "    String[] localSysDirs = StringUtils.getTrimmedStrings(\n",
            "        System.getenv(Environment.LOCAL_DIRS.name()));\n",
            "    job.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n",
            "    LOG.info(MRConfig.LOCAL_DIR + \" for child: \" + job.get(MRConfig.LOCAL_DIR));\n",
            "    LocalDirAllocator lDirAlloc = new LocalDirAllocator(MRConfig.LOCAL_DIR);\n",
            "    Path workDir = null;\n",
            "    // First, try to find the JOB_LOCAL_DIR on this host.\n",
            "    try {\n",
            "      workDir = lDirAlloc.getLocalPathToRead(\"work\", job);\n",
            "    } catch (DiskErrorException e) {\n",
            "      // DiskErrorException means dir not found. If not found, it will\n",
            "      // be created below.\n",
            "    }\n",
            "    if (workDir == null) {\n",
            "      // JOB_LOCAL_DIR doesn't exist on this host -- Create it.\n",
            "      workDir = lDirAlloc.getLocalPathForWrite(\"work\", job);\n",
            "      FileSystem lfs = FileSystem.getLocal(job).getRaw();\n",
            "      boolean madeDir = false;\n",
            "      try {\n",
            "        madeDir = lfs.mkdirs(workDir);\n",
            "      } catch (FileAlreadyExistsException e) {\n",
            "        // Since all tasks will be running in their own JVM, the race condition\n",
            "        // exists where multiple tasks could be trying to create this directory\n",
            "        // at the same time. If this task loses the race, it's okay because\n",
            "        // the directory already exists.\n",
            "        madeDir = true;\n",
            "        workDir = lDirAlloc.getLocalPathToRead(\"work\", job);\n",
            "      }\n",
            "      if (!madeDir) {\n",
            "          throw new IOException(\"Mkdirs failed to create \"\n",
            "              + workDir.toString());\n",
            "      }\n",
            "    }\n",
            "    job.set(MRJobConfig.JOB_LOCAL_DIR,workDir.toString());\n",
            "  }\n",
            "\n",
            "  private static void configureTask(JobConf job, Task task,\n",
            "      Credentials credentials, Token<JobTokenIdentifier> jt) throws IOException {\n",
            "    job.setCredentials(credentials);\n",
            "\n",
            "    ApplicationAttemptId appAttemptId = ContainerId.fromString(\n",
            "        System.getenv(Environment.CONTAINER_ID.name()))\n",
            "        .getApplicationAttemptId();\n",
            "    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n",
            "    // Set it in conf, so as to be able to be used the the OutputCommitter.\n",
            "    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n",
            "        appAttemptId.getAttemptId());\n",
            "\n",
            "    // set tcp nodelay\n",
            "    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n",
            "    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n",
            "        YarnOutputFiles.class, MapOutputFile.class);\n",
            "    // set the jobToken and shuffle secrets into task\n",
            "    task.setJobTokenSecret(\n",
            "        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n",
            "    byte[] shuffleSecret = TokenCache.getShuffleSecretKey(credentials);\n",
            "    if (shuffleSecret == null) {\n",
            "      LOG.warn(\"Shuffle secret missing from task credentials.\"\n",
            "          + \" Using job token secret as shuffle secret.\");\n",
            "      shuffleSecret = jt.getPassword();\n",
            "    }\n",
            "    task.setShuffleSecret(\n",
            "        JobTokenSecretManager.createSecretKey(shuffleSecret));\n",
            "\n",
            "    // setup the child's MRConfig.LOCAL_DIR.\n",
            "    configureLocalDirs(task, job);\n",
            "\n",
            "    // setup the child's attempt directories\n",
            "    // Do the task-type specific localization\n",
            "    task.localizeConfiguration(job);\n",
            "\n",
            "    // Set up the DistributedCache related configs\n",
            "    MRApps.setupDistributedCacheLocal(job);\n",
            "\n",
            "    // Overwrite the localized task jobconf which is linked to in the current\n",
            "    // work-dir.\n",
            "    Path localTaskFile = new Path(MRJobConfig.JOB_CONF_FILE);\n",
            "    writeLocalJobFile(localTaskFile, job);\n",
            "    task.setJobFile(localTaskFile.toString());\n",
            "    task.setConf(job);\n",
            "  }\n",
            "\n",
            "  private static final FsPermission urw_gr =\n",
            "    FsPermission.createImmutable((short) 0640);\n",
            "\n",
            "  /**\n",
            "   * Write the task specific job-configuration file.\n",
            "   * @throws IOException\n",
            "   */\n",
            "  private static void writeLocalJobFile(Path jobFile, JobConf conf)\n",
            "      throws IOException {\n",
            "    FileSystem localFs = FileSystem.getLocal(conf);\n",
            "    localFs.delete(jobFile);\n",
            "    OutputStream out = null;\n",
            "    try {\n",
            "      out = FileSystem.create(localFs, jobFile, urw_gr);\n",
            "      conf.writeXml(out);\n",
            "    } finally {\n",
            "      IOUtils.cleanupWithLogger(LOG, out);\n",
            "    }\n",
            "  }\n",
            "\n",
            "}\n",
            "\n",
            "{'name': 'YarnOutputFiles.java', 'path': 'hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnOutputFiles.java', 'sha': 'ebcb3e70e7bef5033d9a93ddf1f966e45538f386', 'size': 7467, 'url': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnOutputFiles.java?ref=trunk', 'html_url': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnOutputFiles.java', 'git_url': 'https://api.github.com/repos/apache/hadoop/git/blobs/ebcb3e70e7bef5033d9a93ddf1f966e45538f386', 'download_url': 'https://raw.githubusercontent.com/apache/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnOutputFiles.java', 'type': 'file', '_links': {'self': 'https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnOutputFiles.java?ref=trunk', 'git': 'https://api.github.com/repos/apache/hadoop/git/blobs/ebcb3e70e7bef5033d9a93ddf1f966e45538f386', 'html': 'https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnOutputFiles.java'}}\n",
            "YarnOutputFiles.java\n",
            "/**\n",
            "* Licensed to the Apache Software Foundation (ASF) under one\n",
            "* or more contributor license agreements.  See the NOTICE file\n",
            "* distributed with this work for additional information\n",
            "* regarding copyright ownership.  The ASF licenses this file\n",
            "* to you under the Apache License, Version 2.0 (the\n",
            "* \"License\"); you may not use this file except in compliance\n",
            "* with the License.  You may obtain a copy of the License at\n",
            "*\n",
            "*     http://www.apache.org/licenses/LICENSE-2.0\n",
            "*\n",
            "* Unless required by applicable law or agreed to in writing, software\n",
            "* distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "* See the License for the specific language governing permissions and\n",
            "* limitations under the License.\n",
            "*/\n",
            "\n",
            "package org.apache.hadoop.mapred;\n",
            "\n",
            "import java.io.IOException;\n",
            "\n",
            "import org.apache.hadoop.classification.InterfaceAudience;\n",
            "import org.apache.hadoop.classification.InterfaceStability;\n",
            "import org.apache.hadoop.conf.Configuration;\n",
            "import org.apache.hadoop.fs.LocalDirAllocator;\n",
            "import org.apache.hadoop.fs.Path;\n",
            "import org.apache.hadoop.mapreduce.JobContext;\n",
            "import org.apache.hadoop.mapreduce.MRConfig;\n",
            "\n",
            "/**\n",
            " * Manipulate the working area for the transient store for maps and reduces.\n",
            " *\n",
            " * This class is used by map and reduce tasks to identify the directories that\n",
            " * they need to write to/read from for intermediate files. The callers of\n",
            " * these methods are from child space.\n",
            " */\n",
            "@InterfaceAudience.Private\n",
            "@InterfaceStability.Unstable\n",
            "public class YarnOutputFiles extends MapOutputFile {\n",
            "\n",
            "  private JobConf conf;\n",
            "\n",
            "  private static final String JOB_OUTPUT_DIR = \"output\";\n",
            "  private static final String SPILL_FILE_PATTERN = \"%s_spill_%d.out\";\n",
            "  private static final String SPILL_INDEX_FILE_PATTERN = SPILL_FILE_PATTERN\n",
            "      + \".index\";\n",
            "\n",
            "  public YarnOutputFiles() {\n",
            "  }\n",
            "\n",
            "  // assume configured to $localdir/usercache/$user/appcache/$appId\n",
            "  private LocalDirAllocator lDirAlloc = \n",
            "    new LocalDirAllocator(MRConfig.LOCAL_DIR);\n",
            "\n",
            "  private Path getAttemptOutputDir() {\n",
            "    return new Path(JOB_OUTPUT_DIR, conf.get(JobContext.TASK_ATTEMPT_ID));\n",
            "  }\n",
            "  \n",
            "  /**\n",
            "   * Return the path to local map output file created earlier\n",
            "   * \n",
            "   * @return path\n",
            "   * @throws IOException\n",
            "   */\n",
            "  public Path getOutputFile() throws IOException {\n",
            "    Path attemptOutput =\n",
            "      new Path(getAttemptOutputDir(), MAP_OUTPUT_FILENAME_STRING);\n",
            "    return lDirAlloc.getLocalPathToRead(attemptOutput.toString(), conf);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Create a local map output file name.\n",
            "   * \n",
            "   * @param size the size of the file\n",
            "   * @return path\n",
            "   * @throws IOException\n",
            "   */\n",
            "  public Path getOutputFileForWrite(long size) throws IOException {\n",
            "    Path attemptOutput = \n",
            "      new Path(getAttemptOutputDir(), MAP_OUTPUT_FILENAME_STRING);\n",
            "    return lDirAlloc.getLocalPathForWrite(attemptOutput.toString(), size, conf);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Create a local map output file name on the same volume.\n",
            "   */\n",
            "  public Path getOutputFileForWriteInVolume(Path existing) {\n",
            "    Path outputDir = new Path(existing.getParent(), JOB_OUTPUT_DIR);\n",
            "    Path attemptOutputDir = new Path(outputDir,\n",
            "        conf.get(JobContext.TASK_ATTEMPT_ID));\n",
            "    return new Path(attemptOutputDir, MAP_OUTPUT_FILENAME_STRING);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Return the path to a local map output index file created earlier\n",
            "   * \n",
            "   * @return path\n",
            "   * @throws IOException\n",
            "   */\n",
            "  public Path getOutputIndexFile() throws IOException {\n",
            "    Path attemptIndexOutput =\n",
            "      new Path(getAttemptOutputDir(), MAP_OUTPUT_FILENAME_STRING +\n",
            "                                      MAP_OUTPUT_INDEX_SUFFIX_STRING);\n",
            "    return lDirAlloc.getLocalPathToRead(attemptIndexOutput.toString(), conf);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Create a local map output index file name.\n",
            "   * \n",
            "   * @param size the size of the file\n",
            "   * @return path\n",
            "   * @throws IOException\n",
            "   */\n",
            "  public Path getOutputIndexFileForWrite(long size) throws IOException {\n",
            "    Path attemptIndexOutput =\n",
            "      new Path(getAttemptOutputDir(), MAP_OUTPUT_FILENAME_STRING +\n",
            "                                      MAP_OUTPUT_INDEX_SUFFIX_STRING);\n",
            "    return lDirAlloc.getLocalPathForWrite(attemptIndexOutput.toString(),\n",
            "        size, conf);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Create a local map output index file name on the same volume.\n",
            "   */\n",
            "  public Path getOutputIndexFileForWriteInVolume(Path existing) {\n",
            "    Path outputDir = new Path(existing.getParent(), JOB_OUTPUT_DIR);\n",
            "    Path attemptOutputDir = new Path(outputDir,\n",
            "        conf.get(JobContext.TASK_ATTEMPT_ID));\n",
            "    return new Path(attemptOutputDir, MAP_OUTPUT_FILENAME_STRING +\n",
            "                                      MAP_OUTPUT_INDEX_SUFFIX_STRING);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Return a local map spill file created earlier.\n",
            "   * \n",
            "   * @param spillNumber the number\n",
            "   * @return path\n",
            "   * @throws IOException\n",
            "   */\n",
            "  public Path getSpillFile(int spillNumber) throws IOException {\n",
            "    return lDirAlloc.getLocalPathToRead(\n",
            "        String.format(SPILL_FILE_PATTERN,\n",
            "            conf.get(JobContext.TASK_ATTEMPT_ID), spillNumber), conf);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Create a local map spill file name.\n",
            "   * \n",
            "   * @param spillNumber the number\n",
            "   * @param size the size of the file\n",
            "   * @return path\n",
            "   * @throws IOException\n",
            "   */\n",
            "  public Path getSpillFileForWrite(int spillNumber, long size)\n",
            "      throws IOException {\n",
            "    return lDirAlloc.getLocalPathForWrite(\n",
            "        String.format(SPILL_FILE_PATTERN,\n",
            "            conf.get(JobContext.TASK_ATTEMPT_ID), spillNumber), size, conf);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Return a local map spill index file created earlier\n",
            "   * \n",
            "   * @param spillNumber the number\n",
            "   * @return path\n",
            "   * @throws IOException\n",
            "   */\n",
            "  public Path getSpillIndexFile(int spillNumber) throws IOException {\n",
            "    return lDirAlloc.getLocalPathToRead(\n",
            "        String.format(SPILL_INDEX_FILE_PATTERN,\n",
            "            conf.get(JobContext.TASK_ATTEMPT_ID), spillNumber), conf);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Create a local map spill index file name.\n",
            "   * \n",
            "   * @param spillNumber the number\n",
            "   * @param size the size of the file\n",
            "   * @return path\n",
            "   * @throws IOException\n",
            "   */\n",
            "  public Path getSpillIndexFileForWrite(int spillNumber, long size)\n",
            "      throws IOException {\n",
            "    return lDirAlloc.getLocalPathForWrite(\n",
            "        String.format(SPILL_INDEX_FILE_PATTERN,\n",
            "            conf.get(JobContext.TASK_ATTEMPT_ID), spillNumber), size, conf);\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Return a local reduce input file created earlier\n",
            "   * \n",
            "   * @param mapId a map task id\n",
            "   * @return path\n",
            "   * @throws IOException \n",
            "   */\n",
            "  public Path getInputFile(int mapId) throws IOException {\n",
            "    throw new UnsupportedOperationException(\"Incompatible with LocalRunner\");\n",
            "  }\n",
            "\n",
            "  /**\n",
            "   * Create a local reduce input file name.\n",
            "   * \n",
            "   * @param mapId a map task id\n",
            "   * @param size the size of the file\n",
            "   * @return path\n",
            "   * @throws IOException\n",
            "   */\n",
            "  public Path getInputFileForWrite(org.apache.hadoop.mapreduce.TaskID mapId,\n",
            "      long size) throws IOException {\n",
            "    return lDirAlloc.getLocalPathForWrite(String.format(\n",
            "        REDUCE_INPUT_FILE_FORMAT_STRING,\n",
            "        getAttemptOutputDir().toString(), mapId.getId()),\n",
            "        size, conf);\n",
            "  }\n",
            "\n",
            "  /** Removes all of the files related to a task. */\n",
            "  public void removeAll() throws IOException {\n",
            "    throw new UnsupportedOperationException(\"Incompatible with LocalRunner\");\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public void setConf(Configuration conf) {\n",
            "    if (conf instanceof JobConf) {\n",
            "      this.conf = (JobConf) conf;\n",
            "    } else {\n",
            "      this.conf = new JobConf(conf);\n",
            "    }\n",
            "  }\n",
            "\n",
            "  @Override\n",
            "  public Configuration getConf() {\n",
            "    return conf;\n",
            "  }\n",
            "  \n",
            "}\n",
            "\n",
            "Java files converted and saved as JSON in the target directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Github Repository to JSON"
      ],
      "metadata": {
        "id": "vQYfwA75WrOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "\n",
        "\n",
        "# Replace with the username and repository name of the target repository\n",
        "username = \"apache\"\n",
        "repository = \"cloudstack\"\n",
        "\n",
        "# Set the GitHub API base URL\n",
        "api_base_url = \"https://api.github.com\"\n",
        "\n",
        "# Define the target directory where you want to save the JSON files\n",
        "target_directory = \"/content/drive/MyDrive/SPL3/WilliamMerry/JSON/SPL1\"\n",
        "\n",
        "# Function to fetch and convert Java files to JSON\n",
        "def process_repository_contents(contents, current_path=\"\"):\n",
        "    for item in contents:\n",
        "        if item[\"type\"] == \"file\" and item[\"name\"].endswith(\".java\"):\n",
        "            print(item[\"name\"])\n",
        "            # Fetch the content of the Java file\n",
        "            content_url = item[\"download_url\"]\n",
        "            java_code = requests.get(content_url).text\n",
        "\n",
        "            # Create a JSON structure from the Java code\n",
        "            json_structure = {\n",
        "                \"java_filename\": item[\"name\"],\n",
        "                \"java_code\": java_code\n",
        "            }\n",
        "\n",
        "            # Save the JSON file in the target directory\n",
        "            json_filename = os.path.join(target_directory, current_path, item[\"name\"] + \".json\")\n",
        "            with open(json_filename, \"w\") as json_file:\n",
        "                json.dump(json_structure, json_file, indent=4)\n",
        "        elif item[\"type\"] == \"dir\":\n",
        "            # If the item is a directory, fetch its contents and recurse\n",
        "            subdir_url = f\"{api_base_url}/repos/{username}/{repository}/contents/{current_path}/{item['name']}\"\n",
        "            subdir_contents = requests.get(subdir_url).json()\n",
        "            process_repository_contents(subdir_contents, os.path.join(current_path, item[\"name\"]))\n",
        "\n",
        "# Create the target directory if it doesn't exist\n",
        "if not os.path.exists(target_directory):\n",
        "    os.makedirs(target_directory)\n",
        "\n",
        "# Fetch the root of the repository contents\n",
        "repository_url = f\"{api_base_url}/repos/{username}/{repository}/contents\"\n",
        "response = requests.get(repository_url)\n",
        "print(response)\n",
        "if response.status_code == 200:\n",
        "    repository_contents = response.json()\n",
        "    print(repository_contents)\n",
        "    process_repository_contents(repository_contents)\n",
        "    print(\"Java files converted and saved as JSON in the target directory.\")\n",
        "else:\n",
        "    print(\"Failed to fetch repository contents. Check the repository owner and name.\")\n"
      ],
      "metadata": {
        "id": "c5F2E2HTWwgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a96a2c-1274-4e45-e3ef-752bc9ca10c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [403]>\n",
            "Failed to fetch repository contents. Check the repository owner and name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Java Repository to JSON Folder\n"
      ],
      "metadata": {
        "id": "k6TFkriCk9tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import shutil\n",
        "import ast\n",
        "import json\n",
        "\n",
        "username = \"rakib3004\"\n",
        "repository = \"object-oriented-concepts-II\"\n",
        "\n",
        "api_url = f\"https://api.github.com/repos/{username}/{repository}/contents/\"\n",
        "\n",
        "access_token = \"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\"\n",
        "\n",
        "def java_to_json(java_code):\n",
        "    classes_info = []\n",
        "    methods_info = []\n",
        "    imports_info = []\n",
        "    packages_info = []\n",
        "    class_info = None\n",
        "    lines = java_code.split(\"\\n\")\n",
        "    is_in_method = False\n",
        "    package_name=\"\"\n",
        "\n",
        "    for line in lines:\n",
        "        #print(line)\n",
        "        if line.strip().startswith(\"package \"):\n",
        "\n",
        "            package_name = line.split(\" \")[1][:-1]\n",
        "            packages_info.append(package_name)\n",
        "        elif line.strip().startswith(\"import \"):\n",
        "            import_name = line.split(\" \")[1][:-1]\n",
        "            imports_info.append(import_name)\n",
        "        elif line.strip().startswith(\"public class \"):\n",
        "\n",
        "            class_name = line.split(\" \")[2].split(\"{\")[0]\n",
        "            #print('class name', class_name)\n",
        "            class_info = {\n",
        "                \"name\": class_name,\n",
        "                \"methods\": []\n",
        "            }\n",
        "            classes_info.append(class_info)\n",
        "        elif line.strip().startswith(\"public\") and line.strip().endswith(\") {\"):\n",
        "            method_signature = line.split(\"(\")[0].split(\" \")[2:]\n",
        "            method_name = method_signature[-1]\n",
        "            method_args = method_signature[:-1]\n",
        "            #print(\"methods - \", method_signature)\n",
        "            is_in_method = True\n",
        "            method_info = {\n",
        "                \"name\": method_name,\n",
        "            }\n",
        "\n",
        "        elif is_in_method and line.strip() == \"}\":\n",
        "            is_in_method = False\n",
        "            if method_info is not None:\n",
        "              class_info[\"methods\"].append(method_info)\n",
        "              methods_info.append(method_info)\n",
        "\n",
        "\n",
        "\n",
        "    json_structure = {\n",
        "        \"package\": packages_info,\n",
        "        \"imports\": imports_info,\n",
        "        \"classes\": classes_info,\n",
        "\n",
        "    }\n",
        "    return json_structure\n",
        "\n",
        "\n",
        "\n",
        "def java_code_to_json_representation(api_url, destination_directory):\n",
        "    response = requests.get(api_url, headers={\"Authorization\": f\"token {access_token}\"})\n",
        "    print(response)\n",
        "    if response.status_code == 200:\n",
        "        contents = response.json()\n",
        "        for item in contents:\n",
        "          print(item[\"type\"])\n",
        "        for item in contents:\n",
        "            if item[\"type\"] == \"file\":\n",
        "                file_url = item[\"download_url\"]\n",
        "                file_name = item[\"name\"]\n",
        "                base_name, extension = os.path.splitext(file_name)\n",
        "                print(file_name)\n",
        "                if extension == \".java\":\n",
        "                  response = requests.get(file_url)\n",
        "                  if response.status_code == 200:\n",
        "                    content = response.text\n",
        "                    json_content = java_to_json(content)\n",
        "                    new_file_name = base_name + \".json\"\n",
        "                    new_file_path = os.path.join(destination_directory, new_file_name)\n",
        "                    print('[path] -- ', new_file_path)\n",
        "                    print('[json-content] -- ', json_content)\n",
        "                    with open(new_file_path, \"w\") as new_file:\n",
        "                        #new_file.write(json_content)\n",
        "                        json.dump(json_content, new_file, indent=4)\n",
        "            elif item[\"type\"] == \"dir\":\n",
        "                new_dir = os.path.join(destination_directory, item[\"name\"])\n",
        "                os.makedirs(new_dir, exist_ok=True)\n",
        "                java_code_to_json_representation(item[\"url\"], new_dir)\n",
        "\n",
        "os.makedirs(f\"/content/drive/MyDrive/SPL3/WilliamMerry/JSON/{repository}\",exist_ok=True)\n",
        "destination_directory = f\"/content/drive/MyDrive/SPL3/WilliamMerry/JSON/{repository}\"\n",
        "\n",
        "java_code_to_json_representation(api_url, destination_directory)\n"
      ],
      "metadata": {
        "id": "mufMlKy3lOF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Java Code to JSON Code"
      ],
      "metadata": {
        "id": "zRtWZY7sKh_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import shutil\n",
        "import ast\n",
        "import json\n",
        "\n",
        "\n",
        "def java_to_json(java_code):\n",
        "    classes_info = []\n",
        "    methods_info = []\n",
        "    imports_info = []\n",
        "    packages_info = []\n",
        "    class_info = None\n",
        "    lines = java_code.split(\"\\n\")\n",
        "    is_in_method = False\n",
        "    package_name=\"\"\n",
        "\n",
        "    for line in lines:\n",
        "        #print(line)\n",
        "        if line.strip().startswith(\"package \"):\n",
        "\n",
        "            package_name = line.split(\" \")[1][:-1]\n",
        "            packages_info.append(package_name)\n",
        "        elif line.strip().startswith(\"import \"):\n",
        "            import_name = line.split(\" \")[1][:-1]\n",
        "            imports_info.append(import_name)\n",
        "        elif line.strip().startswith(\"public class \"):\n",
        "\n",
        "            class_name = line.split(\" \")[2].split(\"{\")[0]\n",
        "            #print('class name', class_name)\n",
        "            class_info = {\n",
        "                \"name\": class_name,\n",
        "                \"methods\": []\n",
        "            }\n",
        "\n",
        "        elif line.strip().startswith(\"public\") and line.strip().endswith(\") {\"):\n",
        "            method_signature = line.split(\"(\")[0].split(\" \")[2:]\n",
        "            method_name = method_signature[-1]\n",
        "            method_args = method_signature[:-1]\n",
        "            #print(\"methods - \", method_signature)\n",
        "            is_in_method = True\n",
        "            method_info = {\n",
        "                \"name\": method_name,\n",
        "            }\n",
        "\n",
        "        elif is_in_method and line.strip() == \"}\":\n",
        "            is_in_method = False\n",
        "            if method_info is not None:\n",
        "              class_info[\"methods\"].append(method_info)\n",
        "              methods_info.append(method_info)\n",
        "\n",
        "\n",
        "\n",
        "    json_structure = {\n",
        "        \"package\": packages_info,\n",
        "        \"imports\": imports_info,\n",
        "        \"classes\": class_info,\n",
        "\n",
        "    }\n",
        "    return json_structure\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "java_code = '''\n",
        "package LibraryMangementSystem;\n",
        "import FilePackage.DateTimeWriter;\n",
        "import ObjectOriented.PriorityData;\n",
        "import MultiVariableRegression.MedianCalculation;\n",
        "public class Magazine {\n",
        "    String name;\n",
        "    String type;\n",
        "    String publisher;\n",
        "    double price;\n",
        "    String language;\n",
        "\n",
        "    public void addMagazine(){\n",
        "\n",
        "    }\n",
        "    public void removeMagazine(){\n",
        "\n",
        "    }\n",
        "    public void searchMagazine(){\n",
        "\n",
        "    }\n",
        "    public void borrowMagazine(){\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "'''\n",
        "\n",
        "print(json.dumps(java_to_json(java_code), indent=4))\n"
      ],
      "metadata": {
        "id": "2n9tNuNzojHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35556d1f-0930-42af-a535-a2910a7910fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"package\": [\n",
            "        \"LibraryMangementSystem\"\n",
            "    ],\n",
            "    \"imports\": [\n",
            "        \"FilePackage.DateTimeWriter\",\n",
            "        \"ObjectOriented.PriorityData\",\n",
            "        \"MultiVariableRegression.MedianCalculation\"\n",
            "    ],\n",
            "    \"classes\": {\n",
            "        \"name\": \"Magazine\",\n",
            "        \"methods\": []\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pattern Based"
      ],
      "metadata": {
        "id": "5LRX3P1H3o9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "code = \"\"\"\n",
        "\n",
        "public class OutputWriter {\n",
        "    int iterator;\n",
        "\n",
        "public void outputWriterMethods(PriorityData[] priorityData, int numberOfBooks) {\n",
        "       openWriter();\n",
        "       displayWriter();\n",
        "       analytics(documents, colors);\n",
        "    }\n",
        "\n",
        "    public string inputWriterMethods(PriorityData[] priorityData, int bookDetails) {\n",
        "\n",
        "          startWriting();\n",
        "          verifyWriting(callPen);\n",
        "        }\n",
        "\n",
        "public void inputWriterMethods(PriorityData[] priorityData, int bookDetails) {\n",
        "\n",
        "        }\n",
        "\n",
        "        public void timeSchedule(){\n",
        "          searchWBS();\n",
        "          calculateCost(totalResouce, timestamp);\n",
        "          reviewReport(primaryDocument, projectManager);\n",
        "        }\n",
        "}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Define a regular expression pattern to match method declarations and calls\n",
        "method_pattern = r\"(public|private|protected)?\\s+(\\w+)\\s+(\\w+)\\s*\\([^)]*\\)\\s*{\"\n",
        "call_pattern = r\"(\\w+)\\([^)]*\\);\"\n",
        "\n",
        "# Extract method names and calls\n",
        "method_names = re.findall(method_pattern, code)\n",
        "call_names = re.findall(call_pattern, code)\n",
        "\n",
        "# Create a dictionary to store method names and the methods they call\n",
        "method_calls = {}\n",
        "current_method = None\n",
        "\n",
        "for line in code.split('\\n'):\n",
        "    if re.match(method_pattern, line):\n",
        "        access_modifier, return_type, method_name = re.search(method_pattern, line).groups()\n",
        "        current_method = method_name\n",
        "        method_calls[current_method] = set()\n",
        "    elif current_method and re.search(call_pattern, line):\n",
        "        called_method = re.search(call_pattern, line).group(1)\n",
        "        method_calls[current_method].add(called_method)\n",
        "\n",
        "# Print the method names and the methods they call\n",
        "for method, calls in method_calls.items():\n",
        "    print(f\"Method: {method}\")\n",
        "    if calls:\n",
        "        print(f\"Calls: {', '.join(calls)}\")\n",
        "    print()\n",
        "\n",
        "# Output the method names and calls in the desired format\n",
        "output = {\n",
        "    \"classes\": [\n",
        "        {\n",
        "            \"name\": \"OutputWriter\",\n",
        "            \"methods\": [\n",
        "                {\n",
        "                    \"name\": method,\n",
        "                    \"calls\": list(calls)\n",
        "                }\n",
        "                for method, calls in method_calls.items()\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(json.dumps(output, indent=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLeweFaD3rhl",
        "outputId": "2afd1bba-00fc-40be-eafc-afa3a23ec895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"classes\": [\n",
            "        {\n",
            "            \"name\": \"OutputWriter\",\n",
            "            \"methods\": []\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relationships"
      ],
      "metadata": {
        "id": "s5jJ3I-lstTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install javalang"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ9zMNkvszYB",
        "outputId": "b8c227ef-65b3-4c4b-e1ca-11c2066dac82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting javalang\n",
            "  Downloading javalang-0.13.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from javalang) (1.16.0)\n",
            "Installing collected packages: javalang\n",
            "Successfully installed javalang-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHUKHknKWjlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxtKn_8S_L_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "def parse_java_code(java_code):\n",
        "    classes = {}\n",
        "    associations = []\n",
        "\n",
        "    class_pattern = r\"public\\s+class\\s+(\\w+)\"\n",
        "    field_pattern = r\"(\\w+)\\s+(\\w+)\\s*=\\s*new\\s+(\\w+)\\(\\)\"\n",
        "\n",
        "    class_matches = re.findall(class_pattern, java_code)\n",
        "    field_matches = re.findall(field_pattern, java_code)\n",
        "\n",
        "    class_names = [match for match in class_matches]\n",
        "    print(class_names)\n",
        "    for class_name in class_names:\n",
        "        classes[class_name] = {\"name\": class_name, \"relationships\": []}\n",
        "\n",
        "    for match in field_matches:\n",
        "        field_type, field_name, class_type = match\n",
        "        if field_type in class_names:\n",
        "            associations.append({\n",
        "                \"name\": class_name,\n",
        "                \"relationship\": {\n",
        "                    \"with\": class_type,\n",
        "                    \"type\": \"Association\"\n",
        "                }\n",
        "            })\n",
        "\n",
        "    for class_name in class_names:\n",
        "        for association in associations:\n",
        "            if association[\"name\"] == class_name:\n",
        "                classes[class_name][\"relationships\"].append(association[\"relationship\"])\n",
        "    result = {\"classes\": list(classes.values())}\n",
        "    return result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    java_code = \"\"\"\n",
        "    public class BankingSystem {\n",
        "      AccountSystem accountSystem = new AccountSystem();\n",
        "      EmployeeSystem employeeSystem = new EmployeeSystem();\n",
        "      CustomerSystem customerSystem = new CustomerSystem();\n",
        "      LockerSystem lockerSystem = new LockerSystem();\n",
        "    }\n",
        "      public class AccountSystem {\n",
        "      EmployeeSystem employeeSystem = new EmployeeSystem();\n",
        "      CustomerSystem customerSystem = new CustomerSystem();\n",
        "      LockerSystem lockerSystem = new LockerSystem();\n",
        "    }\n",
        "      public class EmployeeSystem {\n",
        "      AccountSystem accountSystem = new AccountSystem();\n",
        "      CustomerSystem customerSystem = new CustomerSystem();\n",
        "      LockerSystem lockerSystem = new LockerSystem();\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    result = parse_java_code(java_code)\n",
        "    json_output = json.dumps(result, indent=2)\n",
        "    print(json_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVk0AbNmWmH_",
        "outputId": "922e8bc3-1671-4cb8-f48e-ec43d3b1ae79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BankingSystem', 'AccountSystem', 'EmployeeSystem']\n",
            "{\n",
            "  \"classes\": [\n",
            "    {\n",
            "      \"name\": \"BankingSystem\",\n",
            "      \"relationships\": []\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"AccountSystem\",\n",
            "      \"relationships\": []\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"EmployeeSystem\",\n",
            "      \"relationships\": [\n",
            "        {\n",
            "          \"with\": \"AccountSystem\",\n",
            "          \"type\": \"Association\"\n",
            "        },\n",
            "        {\n",
            "          \"with\": \"EmployeeSystem\",\n",
            "          \"type\": \"Association\"\n",
            "        },\n",
            "        {\n",
            "          \"with\": \"EmployeeSystem\",\n",
            "          \"type\": \"Association\"\n",
            "        },\n",
            "        {\n",
            "          \"with\": \"AccountSystem\",\n",
            "          \"type\": \"Association\"\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "java_code = \"\"\"\n",
        "public class Employee extends Person implements Employable {\n",
        "    private Company company;\n",
        "\n",
        "    public Employee(String name, Company company) {\n",
        "        super(name);\n",
        "        this.company = company;\n",
        "    }\n",
        "\n",
        "    @Override\n",
        "    public void hire() {\n",
        "        System.out.println(getName() + \" has been hired by \" + company.getCompanyName());\n",
        "    }\n",
        "\n",
        "    public static void main(String[] args) {\n",
        "        Company company = new Company(\"TechCorp\");\n",
        "        Employee employee = new Employee(\"John\", company);\n",
        "        employee.hire();\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Regular expressions to identify class declarations and relationships\n",
        "class_pattern = r\"class\\s+(\\w+)\\s+(extends\\s+(\\w+))?\\s+implements\\s+(\\w+)?\\s*\\{\"\n",
        "relationship_pattern = r\"\\s+(\\w+)\\s+(\\w+);\"\n",
        "\n",
        "classes = []\n",
        "current_class = None\n",
        "ier=0\n",
        "jer=0\n",
        "for line in java_code.split('\\n'):\n",
        "    class_match = re.match(class_pattern, line)\n",
        "    relationship_match = re.match(relationship_pattern, line)\n",
        "    print(class_match,ier)\n",
        "    print(relationship_match,jer)\n",
        "    ier=ier+1\n",
        "    jer=jer+1\n",
        "    if class_match:\n",
        "        current_class = {\n",
        "            \"name\": class_match.group(1),\n",
        "            \"methods\": [],\n",
        "            \"relationship\": []\n",
        "        }\n",
        "        if class_match.group(3):\n",
        "            current_class[\"relationship\"].append({\"name\": class_match.group(3), \"type\": \"Generalization\"})\n",
        "        if class_match.group(4):\n",
        "            current_class[\"relationship\"].append({\"name\": class_match.group(4), \"type\": \"Realization\"})\n",
        "    elif relationship_match:\n",
        "        current_class[\"relationship\"].append({\"name\": relationship_match.group(1), \"type\": \"Association\"})\n",
        "    elif line.strip().startswith(\"public void\"):\n",
        "        method_name = line.split(\"(\")[0].split()[-1]\n",
        "        current_class[\"methods\"].append(method_name)\n",
        "\n",
        "    classes.append(current_class)\n",
        "\n",
        "json_representation = {\"classes\": classes}\n",
        "print(json.dumps(json_representation, indent=2))\n"
      ],
      "metadata": {
        "id": "Kcia6Wkpsxnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "def parse_java_code(java_code):\n",
        "    classes = {}\n",
        "    associations = []\n",
        "\n",
        "    class_pattern = r\"public\\s+class\\s+(\\w+)\\s*{([^}]+)}\"\n",
        "    field_pattern = r\"(\\w+)\\s+(\\w+)\\s*=\\s*new\\s+(\\w+)\\(\\);\"\n",
        "\n",
        "    class_matches = re.findall(class_pattern, java_code, re.DOTALL)\n",
        "\n",
        "    for class_match in class_matches:\n",
        "        class_name, class_body = class_match\n",
        "        classes[class_name] = {\"name\": class_name, \"relationships\": []}\n",
        "\n",
        "        field_matches = re.findall(field_pattern, class_body)\n",
        "        print(class_match)\n",
        "        print(field_matches)\n",
        "\n",
        "\n",
        "        for field_match in field_matches:\n",
        "            field_type, field_name, _ = field_match\n",
        "            if field_type in classes:\n",
        "                associations.append({\n",
        "                    \"name\": class_name,\n",
        "                    \"relationship\": {\n",
        "                        \"with\": field_type,\n",
        "                        \"type\": \"Association\"\n",
        "                    }\n",
        "                })\n",
        "\n",
        "    for association in associations:\n",
        "        classes[association[\"name\"]][\"relationships\"].append(association[\"relationship\"])\n",
        "\n",
        "    result = {\"classes\": list(classes.values())}\n",
        "    return result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    java_code = \"\"\"\n",
        "    public class BankingSystem {\n",
        "        AccountSystem accountSystem = new AccountSystem();\n",
        "        EmployeeSystem employeeSystem = new EmployeeSystem();\n",
        "    }\n",
        "    public class AccountSystem {\n",
        "        EmployeeSystem employeeSystem = new EmployeeSystem();\n",
        "        CustomerSystem customerSystem = new CustomerSystem();\n",
        "    }\n",
        "    public class EmployeeSystem {\n",
        "        CustomerSystem customerSystem = new CustomerSystem();\n",
        "        LockerSystem lockerSystem = new LockerSystem();\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    result = parse_java_code(java_code)\n",
        "    json_output = json.dumps(result, indent=2)\n",
        "    print(json_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ3JS4dL9szm",
        "outputId": "9a08973e-a885-45bf-d887-5f498d144471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('BankingSystem', '\\n        AccountSystem accountSystem = new AccountSystem();\\n        EmployeeSystem employeeSystem = new EmployeeSystem();\\n    ')\n",
            "[('AccountSystem', 'accountSystem', 'AccountSystem'), ('EmployeeSystem', 'employeeSystem', 'EmployeeSystem')]\n",
            "('AccountSystem', '\\n        EmployeeSystem employeeSystem = new EmployeeSystem();\\n        CustomerSystem customerSystem = new CustomerSystem();\\n    ')\n",
            "[('EmployeeSystem', 'employeeSystem', 'EmployeeSystem'), ('CustomerSystem', 'customerSystem', 'CustomerSystem')]\n",
            "('EmployeeSystem', '\\n        CustomerSystem customerSystem = new CustomerSystem();\\n        LockerSystem lockerSystem = new LockerSystem();\\n    ')\n",
            "[('CustomerSystem', 'customerSystem', 'CustomerSystem'), ('LockerSystem', 'lockerSystem', 'LockerSystem')]\n",
            "{\n",
            "  \"classes\": [\n",
            "    {\n",
            "      \"name\": \"BankingSystem\",\n",
            "      \"relationships\": []\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"AccountSystem\",\n",
            "      \"relationships\": []\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"EmployeeSystem\",\n",
            "      \"relationships\": []\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Association, Realization, Generalization"
      ],
      "metadata": {
        "id": "W8R4_kBh5BQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "java_code = \"\"\"\n",
        "package FilePackage;\n",
        "\n",
        "import java.io.BufferedWriter;\n",
        "import java.io.FileWriter;\n",
        "import java.io.IOException;\n",
        "import java.text.SimpleDateFormat;\n",
        "import java.util.Date;\n",
        "\n",
        "public class DateTimeWriter {\n",
        "\n",
        "    int classCounter = 0;\n",
        "\n",
        "    public void dateTimeWriterInitialMethods(String className) {\n",
        "        Date dNow = new Date();\n",
        "        SimpleDateFormat ft = new SimpleDateFormat(\"E dd.MM.yyyy 'at' hh:mm:ss a\");\n",
        "\n",
        "        String FILENAME, string, COUNTER_FILE;\n",
        "        FILENAME = \"history.txt\";\n",
        "        COUNTER_FILE = \"ClassCounter.txt\";\n",
        "\n",
        "        string = className + \"\\t\";\n",
        "        string = string + ft.format(dNow) + \"\\n\";\n",
        "        try {\n",
        "            FileWriter fileWriter = new FileWriter(FILENAME);\n",
        "            fileWriter.write(string);\n",
        "            fileWriter.close();\n",
        "        } catch (IOException e) {\n",
        "            e.printStackTrace();\n",
        "        }\n",
        "\n",
        "        classCounter++;\n",
        "        String noAccessClass = Integer.toString(classCounter);\n",
        "\n",
        "        FileWriter fileWriter1 = null;\n",
        "        try {\n",
        "            fileWriter1 = new FileWriter(COUNTER_FILE);\n",
        "            fileWriter1.write(noAccessClass);\n",
        "            fileWriter1.close();\n",
        "        } catch (IOException e) {\n",
        "            e.printStackTrace();\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public void dateTimeWriterMethods(String className) {\n",
        "        Date dNow = new Date();\n",
        "        SimpleDateFormat ft = new SimpleDateFormat(\"E dd.MM.yyyy 'at' hh:mm:ss a\");\n",
        "\n",
        "        String FILENAME, string;\n",
        "        FILENAME = \"history.txt\";\n",
        "        string = className + \"\\t\";\n",
        "        string = string + ft.format(dNow) + \"\\n\";\n",
        "\n",
        "        BufferedWriter out = null;\n",
        "        try {\n",
        "            out = new BufferedWriter(\n",
        "                    new FileWriter(FILENAME, true));\n",
        "        } catch (IOException e) {\n",
        "            e.printStackTrace();\n",
        "        }\n",
        "        try {\n",
        "            out.write(string);\n",
        "            out.close();\n",
        "        } catch (IOException e) {\n",
        "            e.printStackTrace();\n",
        "        }\n",
        "        /*\n",
        "         * try {\n",
        "         * FileWriter fileWriter=new FileWriter(FILENAME);\n",
        "         * fileWriter.write(string);\n",
        "         * fileWriter.close();\n",
        "         * } catch (IOException e) {\n",
        "         * e.printStackTrace();\n",
        "         * }\n",
        "         */\n",
        "\n",
        "        String COUNTER_FILE = \"ClassCounter.txt\";\n",
        "        classCounter++;\n",
        "        String noAccessClass = Integer.toString(classCounter);\n",
        "\n",
        "        FileWriter fileWriter1 = null;\n",
        "        try {\n",
        "            fileWriter1 = new FileWriter(COUNTER_FILE);\n",
        "            fileWriter1.write(noAccessClass);\n",
        "            fileWriter1.close();\n",
        "        } catch (IOException e) {\n",
        "            e.printStackTrace();\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "class_relationships = []\n",
        "\n",
        "class_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s*{([^}]+)}\"\n",
        "\n",
        "implements_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s+implements\\s+(\\w+)\"\n",
        "extends_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s+extends\\s+(\\w+)\"\n",
        "\n",
        "implements_matches = re.findall(implements_pattern, java_code)\n",
        "for _, implementing_class, implemented_interface in implements_matches:\n",
        "    class_relationships.append({\n",
        "        \"class\": implementing_class,\n",
        "        \"relationship_type\": \"Realization\",\n",
        "        \"with\": implemented_interface\n",
        "    })\n",
        "\n",
        "extends_matches = re.findall(extends_pattern, java_code)\n",
        "for _, extending_class, extended_class in extends_matches:\n",
        "    class_relationships.append({\n",
        "        \"class\": extending_class,\n",
        "        \"relationship_type\": \"Generalization\",\n",
        "        \"with\": extended_class\n",
        "    })\n",
        "\n",
        "\n",
        "classes = {}\n",
        "associations = []\n",
        "\n",
        "class_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s*.*?{([^}]+)}\"\n",
        "class_title_pattern =  r\"(public\\s+)?class\\s+(\\w+)\"\n",
        "field_pattern = r\"(\\w+)\\s+(\\w+)\\s*=\\s*new\\s+(\\w+)\\(\\);\"\n",
        "\n",
        "class_matches = re.findall(class_title_pattern, java_code)\n",
        "class_names = [match[1] for match in class_matches]\n",
        "\n",
        "\n",
        "class_matches = re.findall(class_pattern, java_code, re.DOTALL)\n",
        "for class_match in class_matches:\n",
        "    _, class_name, class_body = class_match\n",
        "\n",
        "    field_matches = re.findall(field_pattern, class_body)\n",
        "    for field_match in field_matches:\n",
        "        field_type, field_name, _ = field_match\n",
        "        class_relationships.append({\n",
        "            \"class\": class_name,\n",
        "            \"relationship_type\": \"Association\",\n",
        "                \"with\": field_type,\n",
        "                      }\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "json_output = json.dumps({\"class_relationships\": class_relationships}, indent=2)\n",
        "\n",
        "print(json_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdyWaMdc_Ouq",
        "outputId": "8ce395d2-f950-49d3-fcff-096da82f8299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"class_relationships\": [\n",
            "    {\n",
            "      \"class\": \"DateTimeWriter\",\n",
            "      \"relationship_type\": \"Association\",\n",
            "      \"with\": \"Date\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enum"
      ],
      "metadata": {
        "id": "wcDpGDK47uKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "java_code = \"\"\"\n",
        "public class EnumExample {\n",
        "    enum Color {\n",
        "        RED, GREEN, BLUE\n",
        "    }\n",
        "}\n",
        "\n",
        "class WeatherReport {\n",
        "    enum WeatherCondition {\n",
        "        SUNNY, CLOUDY, RAINY, SNOWY\n",
        "    }\n",
        "}\n",
        "\n",
        "class CardGame {\n",
        "    enum Suit {\n",
        "        HEARTS, DIAMONDS, CLUBS, SPADES\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Define a regular expression to match enum definitions\n",
        "enum_pattern = r\"enum\\s+(\\w+)\\s*{\\s*([^}]+)}\"\n",
        "\n",
        "# Find all enum matches in the Java code\n",
        "enum_matches = re.findall(enum_pattern, java_code)\n",
        "\n",
        "# Create a list to store enum information\n",
        "enum_info_list = []\n",
        "\n",
        "# Iterate over enum matches and extract information\n",
        "for enum_name, enum_values in enum_matches:\n",
        "    values = [value.strip() for value in enum_values.split(\",\")]\n",
        "    enum_info = {\n",
        "        \"enum_name\": enum_name,\n",
        "        \"enum_values\": values\n",
        "    }\n",
        "    enum_info_list.append(enum_info)\n",
        "\n",
        "# Convert the enum information to JSON\n",
        "json_output = json.dumps({\"enums\": enum_info_list}, indent=2)\n",
        "\n",
        "# Save the JSON to a file\n",
        "with open('enums.json', 'w') as json_file:\n",
        "    json_file.write(json_output)\n",
        "print(json_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl64qxXM7sCl",
        "outputId": "dcc2f5bc-9503-4ba0-d336-a3986450d05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"enums\": [\n",
            "    {\n",
            "      \"enum_name\": \"Color\",\n",
            "      \"enum_values\": [\n",
            "        \"RED\",\n",
            "        \"GREEN\",\n",
            "        \"BLUE\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"enum_name\": \"WeatherCondition\",\n",
            "      \"enum_values\": [\n",
            "        \"SUNNY\",\n",
            "        \"CLOUDY\",\n",
            "        \"RAINY\",\n",
            "        \"SNOWY\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"enum_name\": \"Suit\",\n",
            "      \"enum_values\": [\n",
            "        \"HEARTS\",\n",
            "        \"DIAMONDS\",\n",
            "        \"CLUBS\",\n",
            "        \"SPADES\"\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method\n"
      ],
      "metadata": {
        "id": "ltEZjkpYjd10"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bpXzEwHK8KQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "# Load your Java source code from a file or provide it as a string\n",
        "java_code = \"\"\"\n",
        "public class ClassA {\n",
        "    public void methodA1()  { }\n",
        "    public void methodA2() {  }\n",
        "}\n",
        "\n",
        "class ClassB {\n",
        "      public void methodA2() {  }\n",
        "\n",
        "    public void methodB2() {   }\n",
        "}\n",
        "\n",
        "public class ClassC {\n",
        "      public void methodA2() {}\n",
        "\n",
        "    public void methodC1() {\n",
        "            double summation = 0.0;\n",
        "            int sizeB = list.size();\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Define regular expressions to find class and method declarations\n",
        "class_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s*.*?{([^}]+)}\"\n",
        "\n",
        "method_pattern = r\"(public\\s+)?\\w+\\s+(\\w+)\\s*\\([^)]*\\)\\s*{[^}]*}\"\n",
        "\n",
        "# Find all class matches in the Java code\n",
        "class_matches = re.findall(class_pattern, java_code, re.DOTALL)\n",
        "for class_match in class_matches:\n",
        "    _, class_name, class_body = class_match\n",
        "    print(_,'_',class_name,'class_name',class_body,'class_body')\n",
        "\n",
        "    method_matches = re.findall(method_pattern, class_body)\n",
        "    for method_match in method_matches:\n",
        "        method_name, __ , _ = method_matches\n",
        "        print('--',method_name)\n",
        "\n",
        "\n",
        "class_matches = re.finditer(class_pattern, java_code)\n",
        "\n",
        "# Initialize a dictionary to store class information\n",
        "class_info_dict = {}\n",
        "\n",
        "for match in class_matches:\n",
        "    class_name = match.group(2)\n",
        "    class_info_dict[class_name] = {\"methods\": []}\n",
        "\n",
        "    class_content = match.group(0)\n",
        "\n",
        "    # Find all method matches within the class\n",
        "    method_matches = re.finditer(method_pattern, class_content)\n",
        "    for method_match in method_matches:\n",
        "        method_name = method_match.group(2)\n",
        "        class_info_dict[class_name][\"methods\"].append(method_name)\n",
        "\n",
        "\n",
        "class_matches = re.findall(class_pattern, java_code, re.DOTALL)\n",
        "for class_match in class_matches:\n",
        "    class_name, class_body = class_match\n",
        "\n",
        "    field_matches = re.findall(field_pattern, class_body)\n",
        "    for field_match in field_matches:\n",
        "        field_type, field_name, _ = field_match\n",
        "        class_relationships.append({\n",
        "            \"class\": class_name,\n",
        "            \"relationship_type\": \"Association\",\n",
        "                \"with\": field_type,\n",
        "                      }\n",
        "        )\n",
        "\n",
        "json_output = json.dumps(class_names, indent=2)\n",
        "\n",
        "# Print or save the JSON output\n",
        "print(json_output)\n"
      ],
      "metadata": {
        "id": "B4ELYv9-jg36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "# Define a sample Java code as a string\n",
        "java_code = \"\"\"\n",
        "public class PriceCollection {\n",
        "    public void priceCollectionMLRMethods() {\n",
        "    }\n",
        "\n",
        "    public void priceCollectionAHPMethods() {\n",
        "    }\n",
        "\n",
        "    public void priceCollectionPRAMethods() {\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create a regular expression pattern to match class and method declarations\n",
        "pattern = r'class\\s+(\\w+)\\s*\\{([^}]+)\\}'\n",
        "\n",
        "# Use regular expressions to extract class and method information\n",
        "class_info = []\n",
        "\n",
        "matches = re.finditer(pattern, java_code)\n",
        "for match in matches:\n",
        "    class_name = match.group(1)\n",
        "    methods = re.findall(r'public\\s+\\w+\\s+(\\w+)\\s*\\(', match.group(2))\n",
        "    class_info.append({\"name\": class_name, \"methods\": methods})\n",
        "\n",
        "# Convert the result to JSON\n",
        "result_json = json.dumps(class_info, indent=4)\n",
        "print(result_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUuOuc2iIuRw",
        "outputId": "9ff0ec8b-fb42-42b9-df39-bdd0b4b3507d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"name\": \"PriceCollection\",\n",
            "        \"methods\": [\n",
            "            \"priceCollectionMLRMethods\"\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "# Define a sample Java code as a string\n",
        "java_code = \"\"\"\n",
        "public class PriceCollection {\n",
        "    public void priceCollectionMLRMethods() {\n",
        "    }\n",
        "\n",
        "    public void priceCollectionAHPMethods() {\n",
        "    }\n",
        "\n",
        "    public void priceCollectionPRAMethods() {\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create a regular expression pattern to match class and method declarations\n",
        "pattern = r'class\\s+(\\w+)\\s*\\{([^}]+)\\}'\n",
        "\n",
        "# Use regular expressions to extract class and method information\n",
        "class_info = []\n",
        "\n",
        "matches = re.finditer(pattern, java_code)\n",
        "for match in matches:\n",
        "    class_name = match.group(1)\n",
        "    methods = re.findall(r'public\\s+\\w+\\s+(\\w+)\\s*\\(', match.group(2))\n",
        "    class_info.append({\"class\": {\"name\": class_name, \"methods\": methods}})\n",
        "\n",
        "# Convert the result to JSON\n",
        "result_json = json.dumps(class_info, indent=4)\n",
        "print(result_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1IYmKmKJNMq",
        "outputId": "8c5cc9db-ff48-4711-d1f3-48b41d680b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"class\": {\n",
            "            \"name\": \"PriceCollection\",\n",
            "            \"methods\": [\n",
            "                \"priceCollectionMLRMethods\"\n",
            "            ]\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import javalang\n",
        "\n",
        "# Java code as a string\n",
        "java_code = \"\"\"\n",
        "public class MyClass {\n",
        "    public MyClass() {\n",
        "        // Constructor content here\n",
        "    }\n",
        "\n",
        "    public string news() {\n",
        "        // Method content here\n",
        "    }\n",
        "\n",
        "    public void myMethod() {\n",
        "        // Method content here\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the Java code from the string into an Abstract Syntax Tree (AST)\n",
        "tree = javalang.parse.parse(java_code)\n",
        "\n",
        "# Define functions to extract method and constructor information\n",
        "def extract_method_or_constructor_info(node):\n",
        "    if isinstance(node, javalang.tree.MethodDeclaration):\n",
        "        return {\n",
        "            'type': 'method',\n",
        "            'name': node.name,\n",
        "            'return_type': str(node.return_type),\n",
        "            'parameters': [str(p.type) for p in node.parameters]\n",
        "        }\n",
        "    elif isinstance(node, javalang.tree.ConstructorDeclaration):\n",
        "        return {\n",
        "            'type': 'constructor',\n",
        "            'name': node.name,\n",
        "            'modifiers': [m for m in node.modifiers],\n",
        "            'parameters': [str(p.type) for p in node.parameters]\n",
        "        }\n",
        "    return None\n",
        "\n",
        "def extract_class_info(node):\n",
        "    if isinstance(node, javalang.tree.ClassDeclaration):\n",
        "        return {\n",
        "            'name': node.name,\n",
        "            'modifiers': [m for m in node.modifiers],\n",
        "            'members': [extract_method_or_constructor_info(member) for member in node.body]\n",
        "        }\n",
        "    return None\n",
        "\n",
        "# Extract class, method, and constructor information\n",
        "class_info = [extract_class_info(node) for path, node in tree if extract_class_info(node)]\n",
        "\n",
        "# Serialize the information to JSON\n",
        "json_data = json.dumps(class_info, indent=2)\n",
        "\n",
        "# Print or save the JSON data as needed\n",
        "print(json_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRCIFnOQEbC3",
        "outputId": "8b03b34b-edb7-4d4b-f7cb-ed2268836424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"name\": \"MyClass\",\n",
            "    \"modifiers\": [\n",
            "      \"public\"\n",
            "    ],\n",
            "    \"members\": [\n",
            "      {\n",
            "        \"type\": \"constructor\",\n",
            "        \"name\": \"MyClass\",\n",
            "        \"modifiers\": [\n",
            "          \"public\"\n",
            "        ],\n",
            "        \"parameters\": []\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"method\",\n",
            "        \"name\": \"news\",\n",
            "        \"modifiers\": [\n",
            "          \"public\"\n",
            "        ],\n",
            "        \"return_type\": \"ReferenceType(arguments=None, dimensions=[], name=string, sub_type=None)\",\n",
            "        \"parameters\": []\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"method\",\n",
            "        \"name\": \"myMethod\",\n",
            "        \"modifiers\": [\n",
            "          \"public\"\n",
            "        ],\n",
            "        \"return_type\": \"None\",\n",
            "        \"parameters\": []\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Method Extractor\n"
      ],
      "metadata": {
        "id": "p8KzdiZDFWeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import javalang\n",
        "\n",
        "# Java code as a string\n",
        "java_code = \"\"\"\n",
        "    class Animal {\n",
        "    // most super class method\n",
        "    public void eat(){\n",
        "        System.out.println(\"Animal eats food\");\n",
        "    }\n",
        "}\n",
        "\n",
        "class Dog extends Animal{\n",
        "    // dynamic method dispatch happens to this method\n",
        "    public void eat() {\n",
        "        System.out.println(\"Dog eats meat\");\n",
        "    }\n",
        "}\n",
        "\n",
        "class Puppy extends Dog{\n",
        "    // dynamic method dispatch happens to this method\n",
        "    public void eat() {\n",
        "        System.out.println(\"Puppy drinks milk\");\n",
        "    }\n",
        "}\n",
        "\n",
        "class Test{\n",
        "    public static void main(String args[]){\n",
        "        // create reference variables\n",
        "        Animal a1, a2, a3;\n",
        "        System.out.println(\"-----No Dynamic method dispatch-----\");\n",
        "        a1 = new Animal();\n",
        "        a1.eat();\n",
        "        System.out.println(\"-----Dynamic method dispatch-----\");\n",
        "        a2 = new Dog();\n",
        "        a3 = new Puppy();\n",
        "\n",
        "        a2.eat();\n",
        "        a3.eat();\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "# Parse the Java code from the string into an Abstract Syntax Tree (AST)\n",
        "tree = javalang.parse.parse(java_code)\n",
        "\n",
        "# Define functions to extract class and method information\n",
        "def extract_method_info(node):\n",
        "    if isinstance(node, javalang.tree.MethodDeclaration):\n",
        "        return node.name\n",
        "    elif isinstance(node, javalang.tree.ConstructorDeclaration):\n",
        "      return node.name\n",
        "    return None\n",
        "def extract_class_info(node):\n",
        "    if isinstance(node, javalang.tree.ClassDeclaration):\n",
        "        return {\n",
        "            'class': node.name,\n",
        "            'methods': [extract_method_info(member)for member in node.body if extract_method_info(member) is not None]\n",
        "        }\n",
        "    return None\n",
        "\n",
        "# Extract class and method information\n",
        "class_info = [extract_class_info(node) for path, node in tree if extract_class_info(node)]\n",
        "\n",
        "# Serialize the information to JSON\n",
        "json_data = json.dumps(class_info, indent=2)\n",
        "\n",
        "# Print or save the JSON data as needed\n",
        "print(json_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jald8lEl-Guw",
        "outputId": "19a7b6f0-97e7-4d20-f726-177861260328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "[\n",
            "  {\n",
            "    \"class\": \"Animal\",\n",
            "    \"methods\": [\n",
            "      \"eat\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"class\": \"Dog\",\n",
            "    \"methods\": [\n",
            "      \"eat\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"class\": \"Puppy\",\n",
            "    \"methods\": [\n",
            "      \"eat\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"class\": \"Test\",\n",
            "    \"methods\": [\n",
            "      \"main\"\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Java Repository to JSON Code"
      ],
      "metadata": {
        "id": "w2T3UJY4LOXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  javalang"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDDWX9FJ1Knw",
        "outputId": "1dfbbc09-3467-4465-fe08-16610b6bad03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting javalang\n",
            "  Downloading javalang-0.13.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from javalang) (1.16.0)\n",
            "Installing collected packages: javalang\n",
            "Successfully installed javalang-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import shutil\n",
        "import ast\n",
        "import json\n",
        "import javalang\n",
        "username = \"SalithaUCSC\"\n",
        "repository = \"Java-OOP\"\n",
        "\n",
        "api_url = f\"https://api.github.com/repos/{username}/{repository}/contents/\"\n",
        "\n",
        "access_token = \"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\"\n",
        "\n",
        "def extract_method_info(node):\n",
        "    if isinstance(node, javalang.tree.MethodDeclaration):\n",
        "        return node.name\n",
        "    elif isinstance(node, javalang.tree.ConstructorDeclaration):\n",
        "      return node.name\n",
        "    return None\n",
        "def extract_class_info(node):\n",
        "    if isinstance(node, javalang.tree.ClassDeclaration):\n",
        "        return {\n",
        "            'class': node.name,\n",
        "            'methods': [extract_method_info(member)for member in node.body if extract_method_info(member) is not None]\n",
        "        }\n",
        "    return None\n",
        "\n",
        "\n",
        "def java_to_json(java_code):\n",
        "    tree = javalang.parse.parse(java_code)\n",
        "    class_info = [extract_class_info(node) for path, node in tree if extract_class_info(node)]\n",
        "    return class_info\n",
        "\n",
        "\n",
        "def java_code_to_json_representation(api_url, destination_directory):\n",
        "    response = requests.get(api_url, headers={\"Authorization\": f\"token {access_token}\"})\n",
        "    print(response)\n",
        "    if response.status_code == 200:\n",
        "        contents = response.json()\n",
        "        for item in contents:\n",
        "          print(item[\"type\"])\n",
        "        for item in contents:\n",
        "            if item[\"type\"] == \"file\":\n",
        "                file_url = item[\"download_url\"]\n",
        "                file_name = item[\"name\"]\n",
        "                base_name, extension = os.path.splitext(file_name)\n",
        "                print(file_name)\n",
        "                if extension == \".java\":\n",
        "                  response = requests.get(file_url)\n",
        "                  if response.status_code == 200:\n",
        "                    content = response.text\n",
        "                    json_content = java_to_json(content)\n",
        "                    new_file_name = base_name + \".json\"\n",
        "                    new_file_path = os.path.join(destination_directory, new_file_name)\n",
        "                    print('[path] -- ', new_file_path)\n",
        "                    print('[json-content] -- ', json_content)\n",
        "                    with open(new_file_path, \"w\") as new_file:\n",
        "                        #new_file.write(json_content)\n",
        "                        json.dump(json_content, new_file, indent=4)\n",
        "            elif item[\"type\"] == \"dir\":\n",
        "                new_dir = os.path.join(destination_directory, item[\"name\"])\n",
        "                os.makedirs(new_dir, exist_ok=True)\n",
        "                java_code_to_json_representation(item[\"url\"], new_dir)\n",
        "\n",
        "os.makedirs(f\"/content/drive/MyDrive/SPL3/WilliamMerry/JSON/{repository}\",exist_ok=True)\n",
        "destination_directory = f\"/content/drive/MyDrive/SPL3/WilliamMerry/JSON/{repository}\"\n",
        "\n",
        "java_code_to_json_representation(api_url, destination_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un_FdH0CLixS",
        "outputId": "334906ec-b8b3-43a1-a050-bfd1854bc9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "file\n",
            "dir\n",
            "<Response [200]>\n",
            "dir\n",
            "file\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "misc.xml\n",
            "modules.xml\n",
            "workspace.xml\n",
            "Abstraction.iml\n",
            "<Response [200]>\n",
            "dir\n",
            "<Response [200]>\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "Animal.class\n",
            "Dog.class\n",
            "Test.class\n",
            "<Response [200]>\n",
            "file\n",
            "Test.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMerry/JSON/Java-OOP/Abstraction/src/Test.json\n",
            "[json-content] --  [{'class': 'Animal', 'methods': ['eat', 'sleep']}, {'class': 'Dog', 'methods': ['eat']}, {'class': 'Test', 'methods': ['main']}]\n",
            "<Response [200]>\n",
            "dir\n",
            "file\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "misc.xml\n",
            "modules.xml\n",
            "workspace.xml\n",
            "CompileTimePolymorphism.iml\n",
            "<Response [200]>\n",
            "dir\n",
            "<Response [200]>\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "AddNumbers.class\n",
            "Mathematics.class\n",
            "<Response [200]>\n",
            "file\n",
            "Mathematics.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMerry/JSON/Java-OOP/CompileTimePolymorphism/src/Mathematics.json\n",
            "[json-content] --  [{'class': 'AddNumbers', 'methods': ['addition', 'addition', 'addition']}, {'class': 'Mathematics', 'methods': ['main']}]\n",
            "<Response [200]>\n",
            "dir\n",
            "file\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "misc.xml\n",
            "modules.xml\n",
            "workspace.xml\n",
            "Encapsulation.iml\n",
            "<Response [200]>\n",
            "dir\n",
            "<Response [200]>\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "Demo.class\n",
            "<Response [200]>\n",
            "file\n",
            "Demo.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMerry/JSON/Java-OOP/Encapsulation/src/Demo.json\n",
            "[json-content] --  [{'class': 'Demo', 'methods': ['main']}]\n",
            "<Response [200]>\n",
            "dir\n",
            "file\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "misc.xml\n",
            "modules.xml\n",
            "workspace.xml\n",
            "Inheritance.iml\n",
            "<Response [200]>\n",
            "dir\n",
            "<Response [200]>\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "Animal.class\n",
            "Dog.class\n",
            "Test.class\n",
            "<Response [200]>\n",
            "file\n",
            "Test.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMerry/JSON/Java-OOP/Inheritance/src/Test.json\n",
            "[json-content] --  [{'class': 'Animal', 'methods': ['eat', 'sleep']}, {'class': 'Dog', 'methods': ['bark']}, {'class': 'Test', 'methods': ['main']}]\n",
            "README.md\n",
            "<Response [200]>\n",
            "dir\n",
            "file\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "misc.xml\n",
            "modules.xml\n",
            "workspace.xml\n",
            "RunTimePolymoraphism.iml\n",
            "<Response [200]>\n",
            "dir\n",
            "<Response [200]>\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "Animal.class\n",
            "Dog.class\n",
            "Puppy.class\n",
            "Test.class\n",
            "<Response [200]>\n",
            "file\n",
            "Test.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMerry/JSON/Java-OOP/RunTimePolymoraphism/src/Test.json\n",
            "[json-content] --  [{'class': 'Animal', 'methods': ['eat']}, {'class': 'Dog', 'methods': ['eat']}, {'class': 'Puppy', 'methods': ['eat']}, {'class': 'Test', 'methods': ['main']}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enum, Interface & Absract Class"
      ],
      "metadata": {
        "id": "pdQhxJhO3CUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import javalang\n",
        "\n",
        "# Java code as a string\n",
        "java_code = \"\"\"\n",
        "public enum Color {\n",
        "    RED, GREEN, BLUE\n",
        "}\n",
        "\n",
        "public enum Day {\n",
        "    MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY\n",
        "}\n",
        "\n",
        "public enum Shape {\n",
        "    CIRCLE, SQUARE, TRIANGLE\n",
        "}\n",
        "\n",
        "public enum Season {\n",
        "    SPRING, SUMMER, AUTUMN, WINTER\n",
        "}\n",
        "\n",
        "public enum Status {\n",
        "    ACTIVE, INACTIVE, PENDING\n",
        "}\n",
        "\n",
        "public interface Drawable {\n",
        "    void draw();\n",
        "}\n",
        "\n",
        "public interface Shape {\n",
        "    double getArea();\n",
        "    double getPerimeter();\n",
        "}\n",
        "\n",
        "public interface Listable {\n",
        "    void add(Object item);\n",
        "    void remove(Object item);\n",
        "    Object get(int index);\n",
        "    int size();\n",
        "}\n",
        "\n",
        "public interface Loggable {\n",
        "    void log(String message);\n",
        "}\n",
        "\n",
        "public interface Printable {\n",
        "    void print();\n",
        "}\n",
        "\n",
        "public interface Computable {\n",
        "    int compute(int a, int b);\n",
        "}\n",
        "\n",
        "public interface Transportable {\n",
        "    void start();\n",
        "    void stop();\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the Java code from the string into an Abstract Syntax Tree (AST)\n",
        "tree = javalang.parse.parse(java_code)\n",
        "\n",
        "# Define functions to extract method, constructor, enum, interface, and abstract class information\n",
        "def extract_method_or_constructor_info(node):\n",
        "    if isinstance(node, javalang.tree.MethodDeclaration):\n",
        "        return {\n",
        "            'type': 'method',\n",
        "            'name': node.name,\n",
        "            'modifiers': [m for m in node.modifiers],\n",
        "            'return_type': str(node.return_type),\n",
        "            'parameters': [str(p.type) for p in node.parameters]\n",
        "        }\n",
        "    elif isinstance(node, javalang.tree.ConstructorDeclaration):\n",
        "        return {\n",
        "            'type': 'constructor',\n",
        "            'name': node.name,\n",
        "            'modifiers': [m for m in node.modifiers],\n",
        "            'parameters': [str(p.type) for p in node.parameters]\n",
        "        }\n",
        "    return None\n",
        "\n",
        "def extract_class_info(node):\n",
        "    if isinstance(node, javalang.tree.EnumDeclaration):\n",
        "        return {\n",
        "            'enum': node.name,\n",
        "            'members': []\n",
        "        }\n",
        "    elif isinstance(node, javalang.tree.InterfaceDeclaration):\n",
        "        return {\n",
        "            'interface': node.name,\n",
        "            'members': []\n",
        "        }\n",
        "    return None\n",
        "\n",
        "# Extract class, method, constructor, enum, interface, and abstract class information\n",
        "class_info = [extract_class_info(node) for path, node in tree if extract_class_info(node)]\n",
        "\n",
        "# Serialize the information to JSON\n",
        "json_data = json.dumps(class_info, indent=2)\n",
        "\n",
        "# Print or save the JSON data as needed\n",
        "print(json_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9bUcF4N3HZQ",
        "outputId": "d939ebdb-75bb-43b2-b2e9-145029f1876c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"enum\": \"Color\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"enum\": \"Day\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"enum\": \"Shape\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"enum\": \"Season\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"enum\": \"Status\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"interface\": \"Drawable\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"interface\": \"Shape\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"interface\": \"Listable\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"interface\": \"Loggable\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"interface\": \"Printable\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"interface\": \"Computable\",\n",
            "    \"members\": []\n",
            "  },\n",
            "  {\n",
            "    \"interface\": \"Transportable\",\n",
            "    \"members\": []\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import javalang\n",
        "\n",
        "# Java code as a string\n",
        "java_code = \"\"\"\n",
        "enum Color {\n",
        "    RED, GREEN, BLUE\n",
        "}\n",
        "\n",
        "enum Day {\n",
        "    MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY\n",
        "}\n",
        "\n",
        "interface Drawable {\n",
        "    void draw();\n",
        "}\n",
        "\n",
        "interface Shape {\n",
        "    double getArea();\n",
        "    double getPerimeter();\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the Java code from the string into an Abstract Syntax Tree (AST)\n",
        "tree = javalang.parse.parse(java_code)\n",
        "\n",
        "# Define dictionaries to store ENUMs and interfaces\n",
        "\n",
        "\n",
        "def extract_method_info(node):\n",
        "    if isinstance(node, javalang.tree.MethodDeclaration):\n",
        "        return node.name\n",
        "    elif isinstance(node, javalang.tree.ConstructorDeclaration):\n",
        "      return node.name\n",
        "    return None\n",
        "\n",
        "def extract_enum_info(node):\n",
        "  if isinstance(node, javalang.tree.EnumDeclaration):\n",
        "\n",
        "        return {\n",
        "            'enum': node.name,\n",
        "            'values': [value.name for value in node.body.constants]\n",
        "        }\n",
        "\n",
        "def extract_interface_info(node):\n",
        "    if isinstance(node, javalang.tree.InterfaceDeclaration):\n",
        "      return {\n",
        "            'interface': node.name,\n",
        "            'methods': [extract_method_info(member) for member in node.body if extract_method_info(member) is not None]\n",
        "        }\n",
        "\n",
        "enum_info = [extract_enum_info(node) for path, node in tree if extract_enum_info(node)]\n",
        "interface_info = [extract_interface_info(node) for path, node in tree if extract_interface_info(node)]\n",
        "\n",
        "java_info = enum_info +  interface_info\n",
        "# Serialize the information to JSON\n",
        "json_data = json.dumps(java_info, indent=2)\n",
        "\n",
        "# Print or save the JSON data as needed\n",
        "print(json_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFVGK5tOOjCE",
        "outputId": "60530a4d-90b8-4b55-ec42-65dd6e4e069e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"interface\": \"Drawable\",\n",
            "    \"methods\": [\n",
            "      \"draw\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"interface\": \"Shape\",\n",
            "    \"methods\": [\n",
            "      \"getArea\",\n",
            "      \"getPerimeter\"\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fix Association"
      ],
      "metadata": {
        "id": "lTEJnSAh7Co1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "class_body = \"\"\"\n",
        "Calculation calculation = new Calculation();\n",
        "Scanner scanner = new Scanner(System.in);\n",
        "Reader read = new Reader();\n",
        "Writer write = new Writer();\n",
        "Logger logger = new Logger();\n",
        "Buffer buffer = new Buffer(array, count, index);\n",
        "\"\"\"\n",
        "\n",
        "associations_pattern = r\"(\\w+)\\s+(\\w+)\\s*=\\s*new\\s+(\\w+)\\((.*)\\);\"\n",
        "\n",
        "associations_matches = re.findall(associations_pattern, class_body)\n",
        "class_relationships = []\n",
        "\n",
        "for field_match in associations_matches:\n",
        "    associated_class, object_name, new_instance, instance_parameters = field_match\n",
        "    class_relationships.append({\n",
        "        \"class\": object_name,\n",
        "        \"relationship_type\": \"Association\",\n",
        "        \"with\": associated_class,\n",
        "    })\n",
        "\n",
        "class_json = json.dumps(class_relationships, indent=2)\n",
        "print(class_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr2vM_nZ7Eno",
        "outputId": "5793f3b3-00c6-40ae-c12d-2991ee0ed361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"class\": \"calculation\",\n",
            "    \"relationship_type\": \"Association\",\n",
            "    \"with\": \"Calculation\"\n",
            "  },\n",
            "  {\n",
            "    \"class\": \"scanner\",\n",
            "    \"relationship_type\": \"Association\",\n",
            "    \"with\": \"Scanner\"\n",
            "  },\n",
            "  {\n",
            "    \"class\": \"read\",\n",
            "    \"relationship_type\": \"Association\",\n",
            "    \"with\": \"Reader\"\n",
            "  },\n",
            "  {\n",
            "    \"class\": \"write\",\n",
            "    \"relationship_type\": \"Association\",\n",
            "    \"with\": \"Writer\"\n",
            "  },\n",
            "  {\n",
            "    \"class\": \"logger\",\n",
            "    \"relationship_type\": \"Association\",\n",
            "    \"with\": \"Logger\"\n",
            "  },\n",
            "  {\n",
            "    \"class\": \"buffer\",\n",
            "    \"relationship_type\": \"Association\",\n",
            "    \"with\": \"Buffer\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle Association"
      ],
      "metadata": {
        "id": "GUV0WpgpmK1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class_body = \"\"\"\n",
        "calculation = new Calculation(number);\n",
        "Reader read = new Reader();\n",
        "Writer write = new Writer();\n",
        "Logger logger = new Logger();\n",
        "Buffer buffer = new Buffer(array, count, index);\n",
        "MyClass myClassObject;\n",
        "AnotherClass anotherClassObject;\n",
        "ThirdClass thirdClassObject;\n",
        "myClassObject = new MyClass(intValue, stringValue);\n",
        "anotherClassObject = new AnotherClass(doubleValue);\n",
        "thirdClassObject = new ThirdClass(booleanValue);\n",
        "\"\"\"\n",
        "\n",
        "associations_pattern = r\"(\\w+)\\s+(\\w+)(?:\\s*=\\s*new\\s+(\\w+)\\((.*)\\);)?\"\n",
        "\n",
        "associations_matches = re.findall(associations_pattern, class_body)\n",
        "class_relationships = []\n",
        "\n",
        "for field_match in associations_matches:\n",
        "    object_type, object_name, new_instance, instance_parameters = field_match\n",
        "    if new_instance:\n",
        "        class_relationships.append({\n",
        "            \"class\": object_type,\n",
        "            \"relationship_type\": \"Association\",\n",
        "            \"with\": new_instance,\n",
        "        })\n",
        "    else:\n",
        "        class_relationships.append({\n",
        "            \"class\": object_type,\n",
        "            \"relationship_type\": \"Declaration\"\n",
        "        })\n",
        "\n",
        "class_json = json.dumps(class_relationships, indent=2)\n",
        "print(class_json)\n",
        "\n"
      ],
      "metadata": {
        "id": "SHIFBhgomNpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complex Association Scenario"
      ],
      "metadata": {
        "id": "EmIOs3lOskNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "class_body = \"\"\"\n",
        "Reader read = new Reader(book, bench);\n",
        "read = new Reader(book, bench);\n",
        "new Reader(book, bench);\n",
        "\"\"\"\n",
        "\n",
        "associations_pattern = r\"(((\\w+)\\s+)?(\\w+)\\s*=\\s*)?new\\s+(\\w+)\\((.*)\\);?\"\n",
        "\n",
        "associations_matches = re.findall(associations_pattern, class_body)\n",
        "class_relationships = []\n",
        "class_name = \"Book\"\n",
        "for association_info in associations_matches:\n",
        "    associated_class = association_info[-2]\n",
        "    class_relationships.append({\n",
        "            \"class\": class_name,\n",
        "            \"relationship_type\": \"Association\",\n",
        "            \"with\": associated_class,\n",
        "        })\n",
        "\n",
        "\n",
        "class_json = json.dumps(class_relationships, indent=2)\n",
        "print(class_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVMn3_02snQM",
        "outputId": "788b86b6-2cb5-42da-916e-ebb21f29429f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"class\": \"Book\",\n",
            "    \"relationship_type\": \"Association\",\n",
            "    \"with\": \"Reader\"\n",
            "  },\n",
            "  {\n",
            "    \"class\": \"Book\",\n",
            "    \"relationship_type\": \"Association\",\n",
            "    \"with\": \"Reader\"\n",
            "  },\n",
            "  {\n",
            "    \"class\": \"Book\",\n",
            "    \"relationship_type\": \"Association\",\n",
            "    \"with\": \"Reader\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Code"
      ],
      "metadata": {
        "id": "psvmObK12ASh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install javalang"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA5UFVfDcKfs",
        "outputId": "589a5ebc-31b7-4f15-90ee-a8f7cc64a020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting javalang\n",
            "  Downloading javalang-0.13.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from javalang) (1.16.0)\n",
            "Installing collected packages: javalang\n",
            "Successfully installed javalang-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "java_code = \"\"\"\n",
        "'''package com.journaldev.design.facade;\n",
        "\n",
        "import java.sql.Connection;\n",
        "\n",
        "public class HelperFacade {\n",
        "\n",
        "\tpublic static void generateReport(DBTypes dbType, ReportTypes reportType, String tableName){\n",
        "\t\tConnection con = null;\n",
        "\t\tswitch (dbType){\n",
        "\t\tcase MYSQL:\n",
        "\t\t\tcon = MySqlHelper.getMySqlDBConnection();\n",
        "\t\t\tMySqlHelper mySqlHelper = new MySqlHelper();\n",
        "\t\t\tswitch(reportType){\n",
        "\t\t\tcase HTML:\n",
        "\t\t\t\tmySqlHelper.generateMySqlHTMLReport(tableName, con);\n",
        "\t\t\t\tbreak;\n",
        "\t\t\tcase PDF:\n",
        "\t\t\t\tmySqlHelper.generateMySqlPDFReport(tableName, con);\n",
        "\t\t\t\tbreak;\n",
        "\t\t\t}\n",
        "\t\t\tbreak;\n",
        "\t\tcase ORACLE:\n",
        "\t\t\tcon = OracleHelper.getOracleDBConnection();\n",
        "\t\t\tOracleHelper oracleHelper = new OracleHelper();\n",
        "\t\t\tswitch(reportType){\n",
        "\t\t\tcase HTML:\n",
        "\t\t\t\toracleHelper.generateOracleHTMLReport(tableName, con);\n",
        "\t\t\t\tbreak;\n",
        "\t\t\tcase PDF:\n",
        "\t\t\t\toracleHelper.generateOraclePDFReport(tableName, con);\n",
        "\t\t\t\tbreak;\n",
        "\t\t\t}\n",
        "\t\t\tbreak;\n",
        "\t\t}\n",
        "\n",
        "\t}\n",
        "\n",
        "\tpublic static enum DBTypes{\n",
        "\t\tMYSQL,ORACLE;\n",
        "\t}\n",
        "\n",
        "\tpublic static enum ReportTypes{\n",
        "\t\tHTML,PDF;\n",
        "\t}\n",
        "}\n",
        "\n",
        "''\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "O-w2aHEN18QN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061cddb9-de0e-4bcb-d8b9-bbe03c170d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: javalang in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from javalang) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Method using Javalang"
      ],
      "metadata": {
        "id": "CZZuHFWK5Zcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def local_variable_declaration(element):\n",
        "  calls=[]\n",
        "  for declarator in element.declarators:\n",
        "      if isinstance(declarator.initializer, javalang.tree.MethodInvocation):\n",
        "          call_method = declarator.initializer.member\n",
        "          calls.append(call_method)\n",
        "  return calls\n",
        "\n",
        "def statement_expression(element):\n",
        "   calls=[]\n",
        "   if isinstance(element.expression, javalang.tree.MethodInvocation):\n",
        "      call_method = element.expression.member\n",
        "      if call_method != 'println':\n",
        "        calls.append(call_method)\n",
        "   elif isinstance(element.expression, javalang.tree.SuperMethodInvocation):\n",
        "      call_method = element.expression.member\n",
        "      calls.append(call_method)\n",
        "   elif isinstance(element.expression, javalang.tree.SuperConstructorInvocation):\n",
        "      call_method = 'super'\n",
        "      calls.append(call_method)\n",
        "   return calls\n",
        "\n",
        "def extract_method_members(node):\n",
        "    members = []\n",
        "\n",
        "    if isinstance(node, tree.MethodInvocation):\n",
        "        members.append(node.member)\n",
        "\n",
        "    for child_name, child_node in node.children:\n",
        "        if isinstance(child_node, tree.Node):\n",
        "            members.extend(extract_method_members(child_node))\n",
        "\n",
        "    return members\n",
        "\n",
        "def if_statement(element):\n",
        "    calls = []\n",
        "    calls.extend(extract_method_members(element))\n",
        "\n",
        "    return calls\n",
        "\n",
        "\n",
        "\n",
        "def convert_to_dict(obj):\n",
        "    if isinstance(obj, tree.Node):\n",
        "        return {k: convert_to_dict(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        print(isinstance(obj, list))\n",
        "        return [convert_to_dict(item) for item in obj]\n",
        "    elif isinstance(obj, set):\n",
        "        print(isinstance(obj, set))\n",
        "        return list(obj)\n",
        "    elif isinstance(obj, tuple):\n",
        "        print(isinstance(obj, tuple))\n",
        "        return tuple(convert_to_dict(item) for item in obj)\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "\n",
        "def find_value_by_name(data, name):\n",
        "    if isinstance(data, list):\n",
        "        for item in data:\n",
        "            result = find_value_by_name(item, name)\n",
        "            if result is not None:\n",
        "                return result\n",
        "    elif isinstance(data, dict):\n",
        "        if \"name\" in data and data[\"name\"] == name:\n",
        "            return data.get(\"value\")\n",
        "        else:\n",
        "            for key, value in data.items():\n",
        "                result = find_value_by_name(value, name)\n",
        "                if result is not None:\n",
        "                    return result\n",
        "    return None\n",
        "\n",
        "    #   if elements is None:\n",
        "    # return calls\n",
        "    #   for element in elements:\n",
        "    #     print(element)\n",
        "    #     if isinstance(element, javalang.tree.LocalVariableDeclaration):\n",
        "    #       calls.extend(local_variable_declaration(element))\n",
        "\n",
        "    #     elif isinstance(element, javalang.tree.StatementExpression):\n",
        "    #       calls.extend(statement_expression(element))\n",
        "\n"
      ],
      "metadata": {
        "id": "Ri70iElriMVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complie File"
      ],
      "metadata": {
        "id": "eN-RTp9d9kc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import requests\n",
        "import os\n",
        "import shutil\n",
        "import ast\n",
        "import json\n",
        "import javalang\n",
        "from javalang import tree\n",
        "\n",
        "\n",
        "def extract_method_calls(elements):\n",
        "  calls = []\n",
        "\n",
        "  for element in elements:\n",
        "    data_str = str(element)\n",
        "    calls_in_method = re.findall(r'MethodInvocation\\(arguments=.*?, member=(\\w+)', data_str)\n",
        "    calls.extend(calls_in_method)\n",
        "    calls_in_method = re.findall(r'SuperMethodInvocation\\(arguments=.*?, member=(\\w+)', data_str)\n",
        "    calls.extend(calls_in_method)\n",
        "    super_invocations = re.findall(r'SuperConstructorInvocation', data_str)\n",
        "    if super_invocations:\n",
        "      calls.append('super')\n",
        "\n",
        "  calls = [call for call in calls if call not in ('print', 'println', 'printf')]\n",
        "\n",
        "  return calls\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def extract_method_details(method):\n",
        "    method_info = {\n",
        "        \"name\": method.name,\n",
        "        \"arguments\": [{\"type\": param.type.name, \"name\": param.name} for param in method.parameters if param.name is not None],\n",
        "         \"calls\": extract_method_calls(method.body)\n",
        "    }\n",
        "    return method_info\n",
        "\n",
        "\n",
        "def extract_method_info(node):\n",
        "    if isinstance(node, javalang.tree.MethodDeclaration):\n",
        "        return extract_method_details(node)\n",
        "    elif isinstance(node, javalang.tree.ConstructorDeclaration):\n",
        "      return extract_method_details(node)\n",
        "    return None\n",
        "\n",
        "def extract_enum_info(node):\n",
        "  if isinstance(node, javalang.tree.EnumDeclaration):\n",
        "        return {\n",
        "            'enum': node.name,\n",
        "            'values': [value.name for value in node.body.constants]\n",
        "        }\n",
        "\n",
        "\n",
        "def extract_abstract_class_info(node):\n",
        "    if isinstance(node, javalang.tree.ClassDeclaration):\n",
        "      if 'abstract' in node.modifiers:\n",
        "        return {\n",
        "            'abstract_class': node.name,\n",
        "            'methods': [info for member in node.body if (info := extract_method_info(member)) is not None]\n",
        "        }\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_interface_info(node):\n",
        "    if isinstance(node, javalang.tree.InterfaceDeclaration):\n",
        "      return {\n",
        "            'interface': node.name,\n",
        "            'methods': [info for member in node.body if (info := extract_method_info(member)) is not None]\n",
        "        }\n",
        "\n",
        "\n",
        "def extract_class_info(node):\n",
        "    if isinstance(node, javalang.tree.ClassDeclaration):\n",
        "        return {\n",
        "            'class': node.name,\n",
        "            'methods': [info for member in node.body if (info := extract_method_info(member)) is not None]\n",
        "        }\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_package_and_imports(java_code):\n",
        "    package_info = []\n",
        "    imports_info = []\n",
        "    class_info = {}\n",
        "    lines = java_code.split(\"\\n\")\n",
        "    is_in_method = False\n",
        "    package_name=\"\"\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip().startswith(\"package \"):\n",
        "            package_name = line.split(\" \")[1][:-1]\n",
        "            package_info.append(package_name)\n",
        "        elif line.strip().startswith(\"import \"):\n",
        "            import_name = line.split(\" \")[1][:-1]\n",
        "            imports_info.append(import_name)\n",
        "\n",
        "    return package_info, imports_info\n",
        "\n",
        "\n",
        "def extract_class_relationships(java_code):\n",
        "    class_relationships = []\n",
        "\n",
        "    class_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s*.*?{([^}]+)}\"\n",
        "    associations_pattern = r\"(((\\w+)\\s+)?(\\w+)\\s*=\\s*)?new\\s+(\\w+)\\((.*)\\);?\"\n",
        "\n",
        "    class_matches = re.findall(class_pattern, java_code, re.DOTALL)\n",
        "    for class_match in class_matches:\n",
        "        access_modifier, class_name, class_body = class_match\n",
        "        associations_matches = re.findall(associations_pattern, class_body)\n",
        "\n",
        "        for association_info in associations_matches:\n",
        "          associated_class = association_info[-2]\n",
        "          class_relationships.append({\n",
        "                        \"class\": class_name,\n",
        "                        \"relationship_type\": \"Association\",\n",
        "                        \"with\": associated_class,\n",
        "                    })\n",
        "\n",
        "    implements_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s+implements\\s+(\\w+)\"\n",
        "    extends_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s+extends\\s+(\\w+)\"\n",
        "\n",
        "    implements_matches = re.findall(implements_pattern, java_code)\n",
        "    for access_modifier, implementing_class, implemented_interface in implements_matches:\n",
        "        class_relationships.append({\n",
        "            \"class\": implementing_class,\n",
        "            \"relationship_type\": \"Realization\",\n",
        "            \"with\": implemented_interface\n",
        "        })\n",
        "\n",
        "    extends_matches = re.findall(extends_pattern, java_code)\n",
        "    for access_modifier, extending_class, extended_class in extends_matches:\n",
        "        class_relationships.append({\n",
        "            \"class\": extending_class,\n",
        "            \"relationship_type\": \"Generalization\",\n",
        "            \"with\": extended_class\n",
        "        })\n",
        "\n",
        "    return class_relationships\n",
        "\n",
        "\n",
        "def extract_info(java_code):\n",
        "    tree = javalang.parse.parse(java_code)\n",
        "    class_info = [info for path, node in tree if (info := extract_class_info(node))]\n",
        "    enum_info =  [info for path, node in tree if (info := extract_enum_info(node))]\n",
        "    interface_info = [info for path, node in tree if (info := extract_interface_info(node))]\n",
        "    abstract_class_info =  [info for path, node in tree if (info := extract_abstract_class_info(node))]\n",
        "    info = class_info + interface_info + abstract_class_info + enum_info\n",
        "    return info\n",
        "\n",
        "\n",
        "def java_to_json(java_code):\n",
        "    try:\n",
        "        class_relationships = extract_class_relationships(java_code)\n",
        "        package_info, imports_info = extract_package_and_imports(java_code)\n",
        "        info = extract_info(java_code)\n",
        "        result = {\n",
        "        \"package\": package_info,\n",
        "        \"imports\": imports_info,\n",
        "        \"info\": info,\n",
        "        \"relationships\": class_relationships,\n",
        "    }\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        error_response = {\"message\": f\"error occur on this file {e}\"}\n",
        "        return error_response\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "java_code = \"\"\"\n",
        "package refactoring_guru.prototype.example;\n",
        "\n",
        "import refactoring_guru.prototype.example.shapes.Circle;\n",
        "import refactoring_guru.prototype.example.shapes.Rectangle;\n",
        "import refactoring_guru.prototype.example.shapes.Shape;\n",
        "\n",
        "import java.util.ArrayList;\n",
        "import java.util.List;\n",
        "\n",
        "public class Demo {\n",
        "    public static void main(String[] args) {\n",
        "        List<Shape> shapes = new ArrayList<>();\n",
        "        List<Shape> shapesCopy = new ArrayList<>();\n",
        "\n",
        "        Circle circle = new Circle();\n",
        "        circle.x = 10;\n",
        "        circle.y = 20;\n",
        "        circle.radius = 15;\n",
        "        circle.color = \"red\";\n",
        "        shapes.add(circle);\n",
        "\n",
        "        Circle anotherCircle = (Circle) circle.clone();\n",
        "        shapes.add(anotherCircle);\n",
        "\n",
        "        Rectangle rectangle = new Rectangle();\n",
        "        rectangle.width = 10;\n",
        "        rectangle.height = 20;\n",
        "        rectangle.color = \"blue\";\n",
        "        shapes.add(rectangle);\n",
        "\n",
        "        cloneAndCompare(shapes, shapesCopy);\n",
        "    }\n",
        "\n",
        "    private static void cloneAndCompare(List<Shape> shapes, List<Shape> shapesCopy) {\n",
        "        for (Shape shape : shapes) {\n",
        "            shapesCopy.add(shape.clone());\n",
        "        }\n",
        "\n",
        "        for (int i = 0; i < shapes.size(); i++) {\n",
        "            if (shapes.get(i) != shapesCopy.get(i)) {\n",
        "                System.out.println(i + \": Shapes are different objects (yay!)\");\n",
        "                if (shapes.get(i).equals(shapesCopy.get(i))) {\n",
        "                    System.out.println(i + \": And they are identical (yay!)\");\n",
        "                } else {\n",
        "                    System.out.println(i + \": But they are not identical (booo!)\");\n",
        "                }\n",
        "            } else {\n",
        "                System.out.println(i + \": Shape objects are the same (booo!)\");\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "result = java_to_json(java_code)\n",
        "json_output = json.dumps(result, indent=2)\n",
        "print(json_output)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWWNDGqX9mza",
        "outputId": "5d814ab5-4c7d-4dad-be07-bbbc9da88ef0"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"package\": [\n",
            "    \"refactoring_guru.prototype.example\"\n",
            "  ],\n",
            "  \"imports\": [\n",
            "    \"refactoring_guru.prototype.example.shapes.Circle\",\n",
            "    \"refactoring_guru.prototype.example.shapes.Rectangle\",\n",
            "    \"refactoring_guru.prototype.example.shapes.Shape\",\n",
            "    \"java.util.ArrayList\",\n",
            "    \"java.util.List\"\n",
            "  ],\n",
            "  \"info\": [\n",
            "    {\n",
            "      \"class\": \"Demo\",\n",
            "      \"methods\": [\n",
            "        {\n",
            "          \"name\": \"main\",\n",
            "          \"arguments\": [\n",
            "            {\n",
            "              \"type\": \"String\",\n",
            "              \"name\": \"args\"\n",
            "            }\n",
            "          ],\n",
            "          \"calls\": [\n",
            "            \"add\",\n",
            "            \"clone\",\n",
            "            \"add\",\n",
            "            \"add\",\n",
            "            \"cloneAndCompare\"\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"cloneAndCompare\",\n",
            "          \"arguments\": [\n",
            "            {\n",
            "              \"type\": \"List\",\n",
            "              \"name\": \"shapes\"\n",
            "            },\n",
            "            {\n",
            "              \"type\": \"List\",\n",
            "              \"name\": \"shapesCopy\"\n",
            "            }\n",
            "          ],\n",
            "          \"calls\": [\n",
            "            \"clone\",\n",
            "            \"get\",\n",
            "            \"get\",\n",
            "            \"get\",\n",
            "            \"get\",\n",
            "            \"size\"\n",
            "          ]\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"relationships\": [\n",
            "    {\n",
            "      \"class\": \"Demo\",\n",
            "      \"relationship_type\": \"Association\",\n",
            "      \"with\": \"Circle\"\n",
            "    },\n",
            "    {\n",
            "      \"class\": \"Demo\",\n",
            "      \"relationship_type\": \"Association\",\n",
            "      \"with\": \"Rectangle\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complie Repository"
      ],
      "metadata": {
        "id": "s5gFWJv-BrLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import requests\n",
        "import os\n",
        "import shutil\n",
        "import ast\n",
        "import json\n",
        "import javalang\n",
        "username = \"rakib3004\"\n",
        "repository = \"SPL3\"\n",
        "\n",
        "api_url = f\"https://api.github.com/repos/{username}/{repository}/contents/\"\n",
        "\n",
        "access_token = \"access-token\"\n",
        "\n",
        "\n",
        "\n",
        "def extract_method_calls(elements):\n",
        "  calls = []\n",
        "  if elements is None:\n",
        "    return calls\n",
        "  for element in elements:\n",
        "    if isinstance(element, javalang.tree.LocalVariableDeclaration):\n",
        "        for declarator in element.declarators:\n",
        "            if isinstance(declarator.initializer, javalang.tree.MethodInvocation):\n",
        "                call_method = declarator.initializer.member\n",
        "                calls.append(call_method)\n",
        "    elif isinstance(element, javalang.tree.StatementExpression):\n",
        "        if isinstance(element.expression, javalang.tree.MethodInvocation):\n",
        "            call_method = element.expression.member\n",
        "            if call_method != 'println':\n",
        "              calls.append(call_method)\n",
        "        elif isinstance(element.expression, javalang.tree.SuperMethodInvocation):\n",
        "            call_method = element.expression.member\n",
        "            calls.append(call_method)\n",
        "        elif isinstance(element.expression, javalang.tree.SuperConstructorInvocation):\n",
        "            call_method = 'super'\n",
        "            calls.append(call_method)\n",
        "    return calls\n",
        "\n",
        "\n",
        "\n",
        "def extract_method_details(method):\n",
        "    method_info = {\n",
        "        \"name\": method.name,\n",
        "        \"arguments\": [{\"type\": param.type.name, \"name\": param.name} for param in method.parameters if param.name is not None],\n",
        "         \"calls\": extract_method_calls(method.body)\n",
        "    }\n",
        "    return method_info\n",
        "\n",
        "\n",
        "def extract_method_info(node):\n",
        "    if isinstance(node, javalang.tree.MethodDeclaration):\n",
        "        return extract_method_details(node)\n",
        "    elif isinstance(node, javalang.tree.ConstructorDeclaration):\n",
        "      return extract_method_details(node)\n",
        "    return None\n",
        "\n",
        "def extract_enum_info(node):\n",
        "  if isinstance(node, javalang.tree.EnumDeclaration):\n",
        "        return {\n",
        "            'enum': node.name,\n",
        "            'values': [value.name for value in node.body.constants]\n",
        "        }\n",
        "\n",
        "\n",
        "def extract_abstract_class_info(node):\n",
        "    if isinstance(node, javalang.tree.ClassDeclaration):\n",
        "      if 'abstract' in node.modifiers:\n",
        "        return {\n",
        "            'abstract_class': node.name,\n",
        "            'methods': [extract_method_info(member)for member in node.body if extract_method_info(member) is not None]\n",
        "        }\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_interface_info(node):\n",
        "    if isinstance(node, javalang.tree.InterfaceDeclaration):\n",
        "      return {\n",
        "            'interface': node.name,\n",
        "            'methods': [extract_method_info(member) for member in node.body if extract_method_info(member) is not None]\n",
        "        }\n",
        "\n",
        "\n",
        "def extract_class_info(node):\n",
        "    if isinstance(node, javalang.tree.ClassDeclaration):\n",
        "        return {\n",
        "            'class': node.name,\n",
        "            'methods': [extract_method_info(member)for member in node.body if extract_method_info(member) is not None]\n",
        "        }\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_package_and_imports(java_code):\n",
        "    package_info = []\n",
        "    imports_info = []\n",
        "    class_info = {}\n",
        "    lines = java_code.split(\"\\n\")\n",
        "    is_in_method = False\n",
        "    package_name=\"\"\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip().startswith(\"package \"):\n",
        "            package_name = line.split(\" \")[1][:-1]\n",
        "            package_info.append(package_name)\n",
        "        elif line.strip().startswith(\"import \"):\n",
        "            import_name = line.split(\" \")[1][:-1]\n",
        "            imports_info.append(import_name)\n",
        "\n",
        "    return package_info, imports_info\n",
        "\n",
        "\n",
        "def extract_class_relationships(java_code):\n",
        "    class_relationships = []\n",
        "\n",
        "    class_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s*.*?{([^}]+)}\"\n",
        "    associations_pattern = r\"(((\\w+)\\s+)?(\\w+)\\s*=\\s*)?new\\s+(\\w+)\\((.*)\\);?\"\n",
        "\n",
        "    class_matches = re.findall(class_pattern, java_code, re.DOTALL)\n",
        "    for class_match in class_matches:\n",
        "        access_modifier, class_name, class_body = class_match\n",
        "        associations_matches = re.findall(associations_pattern, class_body)\n",
        "\n",
        "        for association_info in associations_matches:\n",
        "          associated_class = association_info[-2]\n",
        "          class_relationships.append({\n",
        "                        \"class\": class_name,\n",
        "                        \"relationship_type\": \"Association\",\n",
        "                        \"with\": associated_class,\n",
        "                    })\n",
        "\n",
        "    implements_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s+implements\\s+(\\w+)\"\n",
        "    extends_pattern = r\"(public\\s+)?class\\s+(\\w+)\\s+extends\\s+(\\w+)\"\n",
        "\n",
        "    implements_matches = re.findall(implements_pattern, java_code)\n",
        "    for access_modifier, implementing_class, implemented_interface in implements_matches:\n",
        "        class_relationships.append({\n",
        "            \"class\": implementing_class,\n",
        "            \"relationship_type\": \"Realization\",\n",
        "            \"with\": implemented_interface\n",
        "        })\n",
        "\n",
        "    extends_matches = re.findall(extends_pattern, java_code)\n",
        "    for access_modifier, extending_class, extended_class in extends_matches:\n",
        "        class_relationships.append({\n",
        "            \"class\": extending_class,\n",
        "            \"relationship_type\": \"Generalization\",\n",
        "            \"with\": extended_class\n",
        "        })\n",
        "\n",
        "    return class_relationships\n",
        "\n",
        "\n",
        "def extract_info(java_code):\n",
        "    tree = javalang.parse.parse(java_code)\n",
        "    class_info = [extract_class_info(node) for path, node in tree if extract_class_info(node)]\n",
        "    enum_info = [extract_enum_info(node) for path, node in tree if extract_enum_info(node)]\n",
        "    interface_info = [extract_interface_info(node) for path, node in tree if extract_interface_info(node)]\n",
        "    abstract_class_info =  [extract_abstract_class_info(node) for path, node in tree if extract_abstract_class_info(node)]\n",
        "    info = class_info + interface_info + abstract_class_info + enum_info\n",
        "    return info\n",
        "\n",
        "\n",
        "def java_to_json(java_code):\n",
        "    try:\n",
        "        class_relationships = extract_class_relationships(java_code)\n",
        "        package_info, imports_info = extract_package_and_imports(java_code)\n",
        "        info = extract_info(java_code)\n",
        "        result = {\n",
        "        \"package\": package_info,\n",
        "        \"imports\": imports_info,\n",
        "        \"info\": info,\n",
        "        \"relationships\": class_relationships,\n",
        "    }\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        error_response = {\"message\": f\"error occur on this file {e}\"}\n",
        "        return error_response\n",
        "\n",
        "def java_code_to_json_representation(api_url, destination_directory):\n",
        "    response = requests.get(api_url, headers={\"Authorization\": f\"token {access_token}\"})\n",
        "    print(response)\n",
        "    if response.status_code == 200:\n",
        "        contents = response.json()\n",
        "        for item in contents:\n",
        "          print(item[\"type\"])\n",
        "        for item in contents:\n",
        "            if item[\"type\"] == \"file\":\n",
        "                file_url = item[\"download_url\"]\n",
        "                file_name = item[\"name\"]\n",
        "                base_name, extension = os.path.splitext(file_name)\n",
        "                print(file_name)\n",
        "                if extension == \".java\":\n",
        "                  response = requests.get(file_url)\n",
        "                  if response.status_code == 200:\n",
        "                    content = response.text\n",
        "                    json_content = java_to_json(content)\n",
        "                    new_file_name = base_name + \".json\"\n",
        "                    new_file_path = os.path.join(destination_directory, new_file_name)\n",
        "                    print('[path] -- ', new_file_path)\n",
        "                    print('[content] -- ', json_content)\n",
        "                    with open(new_file_path, \"w\") as new_file:\n",
        "                        json.dump(json_content, new_file, indent=4)\n",
        "            elif item[\"type\"] == \"dir\":\n",
        "                new_dir = os.path.join(destination_directory, item[\"name\"])\n",
        "                os.makedirs(new_dir, exist_ok=True)\n",
        "                java_code_to_json_representation(item[\"url\"], new_dir)\n",
        "\n",
        "os.makedirs(f\"/content/drive/MyDrive/SPL3/WilliamMary/JSON/{repository}\",exist_ok=True)\n",
        "destination_directory = f\"/content/drive/MyDrive/SPL3/WilliamMary/JSON/{repository}\"\n",
        "\n",
        "java_code_to_json_representation(api_url, destination_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45cz-qs5BqxQ",
        "outputId": "afe5a3c7-ec52-4bc3-feb2-f3c2d32b5905"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "file\n",
            "dir\n",
            "file\n",
            "file\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            ".gitignore\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "misc.xml\n",
            "modules.xml\n",
            "uiDesigner.xml\n",
            "vcs.xml\n",
            "workspace.xml\n",
            "JavaToJSON.iml\n",
            "UMLJsonConverterFromCode.ipynb\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "com.fasterxml.jackson.core.jar\n",
            "com.fasterxml.jackson.core.jar.zip\n",
            "com.fasterxml.jackson.databind.jar\n",
            "com.fasterxml.jackson.databind.jar.zip\n",
            "jackson-annotations-2.1.2.jar\n",
            "jackson-annotations-2.1.2.jar.zip\n",
            "<Response [200]>\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "CalculateWeight.java.json\n",
            "Matrix.java.json\n",
            "MedianCalculation.java.json\n",
            "MultipleLinearRegression.java.json\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "BaseClasss.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/json/design/BaseClasss.json\n",
            "[content] --  {'package': [], 'imports': [], 'info': [{'class': 'Animal', 'methods': [{'name': 'Animal', 'arguments': [{'type': 'String', 'name': 'name'}], 'calls': []}, {'name': 'eat', 'arguments': [], 'calls': []}]}, {'class': 'Dolphin', 'methods': [{'name': 'Dolphin', 'arguments': [{'type': 'String', 'name': 'name'}], 'calls': ['super']}, {'name': 'swim', 'arguments': [], 'calls': []}, {'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}, {'interface': 'Swimmer', 'methods': [{'name': 'swim', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'Dolphin', 'relationship_type': 'Generalization', 'with': 'Animal'}]}\n",
            "FizzBuzzPatternMatcher.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/json/design/FizzBuzzPatternMatcher.json\n",
            "[content] --  {'package': ['workshop.FizzBuzzModule'], 'imports': [], 'info': [{'class': 'FizzBuzzPatternMatcher', 'methods': [{'name': 'matches', 'arguments': [{'type': 'int', 'name': 'number'}], 'calls': []}, {'name': 'generateResponse', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'FizzBuzzPatternMatcher', 'relationship_type': 'Realization', 'with': 'PatternMatcher'}]}\n",
            "FizzBuzzPatternMatcher.json\n",
            "exceptional.json\n",
            "expected.json\n",
            "expectedTerms.txt\n",
            "latest.json\n",
            "prompt.json\n",
            "regex.json\n",
            "standard.json\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "LocalContainerLauncher.java.json\n",
            "MapReduceChildJVM.java.json\n",
            "MapTaskAttemptImpl.java.json\n",
            "ReduceTaskAttemptImpl.java.json\n",
            "TaskAttemptListenerImpl.java.json\n",
            "WrappedJvmID.java.json\n",
            "WrappedPeriodicStatsAccumulator.java.json\n",
            "WrappedProgressSplitsBlock.java.json\n",
            "YarnChild.java.json\n",
            "YarnOutputFiles.java.json\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "EducationalGoogleClassRoom.json\n",
            "GoogleClassRoom.json\n",
            "GoogleClassRoomStudents.json\n",
            "GoogleClassStream.json\n",
            "InitDataBase.json\n",
            "Students.json\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "BuzzPatternMatcher.java.json\n",
            "FizzBuzz.java.json\n",
            "FizzBuzzPatternMatcher.java.json\n",
            "FizzPatternMatcher.java.json\n",
            "NullResponse.java.json\n",
            "PatternMatcher.java.json\n",
            "<Response [200]>\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "ATMDispenseChain.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ChainOfResponsibilityPattern/ATMDispenseChain.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ChainOfResponsibilityPattern'], 'imports': ['java.util.Scanner'], 'info': [{'class': 'ATMDispenseChain', 'methods': [{'name': 'ATMDispenseChain', 'arguments': [], 'calls': []}, {'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'ATMDispenseChain', 'relationship_type': 'Association', 'with': 'Dollar50Dispenser'}, {'class': 'ATMDispenseChain', 'relationship_type': 'Association', 'with': 'Dollar20Dispenser'}, {'class': 'ATMDispenseChain', 'relationship_type': 'Association', 'with': 'Dollar10Dispenser'}]}\n",
            "Currency.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ChainOfResponsibilityPattern/Currency.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ChainOfResponsibilityPattern'], 'imports': [], 'info': [{'class': 'Currency', 'methods': [{'name': 'Currency', 'arguments': [{'type': 'int', 'name': 'amt'}], 'calls': []}, {'name': 'getAmount', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "DispenseChain.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ChainOfResponsibilityPattern/DispenseChain.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ChainOfResponsibilityPattern'], 'imports': [], 'info': [{'interface': 'DispenseChain', 'methods': [{'name': 'setNextChain', 'arguments': [{'type': 'DispenseChain', 'name': 'nextChain'}], 'calls': []}, {'name': 'dispense', 'arguments': [{'type': 'Currency', 'name': 'cur'}], 'calls': []}]}], 'relationships': []}\n",
            "Dollar10Dispenser.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ChainOfResponsibilityPattern/Dollar10Dispenser.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ChainOfResponsibilityPattern'], 'imports': [], 'info': [{'class': 'Dollar10Dispenser', 'methods': [{'name': 'setNextChain', 'arguments': [{'type': 'DispenseChain', 'name': 'nextChain'}], 'calls': []}, {'name': 'dispense', 'arguments': [{'type': 'Currency', 'name': 'cur'}], 'calls': []}]}], 'relationships': [{'class': 'Dollar10Dispenser', 'relationship_type': 'Realization', 'with': 'DispenseChain'}]}\n",
            "Dollar20Dispenser.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ChainOfResponsibilityPattern/Dollar20Dispenser.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ChainOfResponsibilityPattern'], 'imports': [], 'info': [{'class': 'Dollar20Dispenser', 'methods': [{'name': 'setNextChain', 'arguments': [{'type': 'DispenseChain', 'name': 'nextChain'}], 'calls': []}, {'name': 'dispense', 'arguments': [{'type': 'Currency', 'name': 'cur'}], 'calls': []}]}], 'relationships': [{'class': 'Dollar20Dispenser', 'relationship_type': 'Realization', 'with': 'DispenseChain'}]}\n",
            "Dollar50Dispenser.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ChainOfResponsibilityPattern/Dollar50Dispenser.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ChainOfResponsibilityPattern'], 'imports': [], 'info': [{'class': 'Dollar50Dispenser', 'methods': [{'name': 'setNextChain', 'arguments': [{'type': 'DispenseChain', 'name': 'nextChain'}], 'calls': []}, {'name': 'dispense', 'arguments': [{'type': 'Currency', 'name': 'cur'}], 'calls': []}]}], 'relationships': [{'class': 'Dollar50Dispenser', 'relationship_type': 'Realization', 'with': 'DispenseChain'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "CloseFileCommand.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/CommandPattern/CloseFileCommand.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.CommandPattern'], 'imports': [], 'info': [{'class': 'CloseFileCommand', 'methods': [{'name': 'CloseFileCommand', 'arguments': [{'type': 'FileSystemReceiver', 'name': 'fs'}], 'calls': []}, {'name': 'execute', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'CloseFileCommand', 'relationship_type': 'Realization', 'with': 'Command'}]}\n",
            "Command.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/CommandPattern/Command.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.CommandPattern'], 'imports': [], 'info': [{'interface': 'Command', 'methods': [{'name': 'execute', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "FileInvoker.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/CommandPattern/FileInvoker.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.CommandPattern'], 'imports': [], 'info': [{'class': 'FileInvoker', 'methods': [{'name': 'FileInvoker', 'arguments': [{'type': 'Command', 'name': 'c'}], 'calls': []}, {'name': 'execute', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "FileSystemClient.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/CommandPattern/FileSystemClient.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.CommandPattern'], 'imports': [], 'info': [{'class': 'FileSystemClient', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': ['getUnderlyingFileSystem']}]}], 'relationships': [{'class': 'FileSystemClient', 'relationship_type': 'Association', 'with': 'OpenFileCommand'}, {'class': 'FileSystemClient', 'relationship_type': 'Association', 'with': 'FileInvoker'}, {'class': 'FileSystemClient', 'relationship_type': 'Association', 'with': 'WriteFileCommand'}, {'class': 'FileSystemClient', 'relationship_type': 'Association', 'with': 'FileInvoker'}, {'class': 'FileSystemClient', 'relationship_type': 'Association', 'with': 'CloseFileCommand'}, {'class': 'FileSystemClient', 'relationship_type': 'Association', 'with': 'FileInvoker'}]}\n",
            "FileSystemReceiver.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/CommandPattern/FileSystemReceiver.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.CommandPattern'], 'imports': [], 'info': [{'interface': 'FileSystemReceiver', 'methods': [{'name': 'openFile', 'arguments': [], 'calls': []}, {'name': 'writeFile', 'arguments': [], 'calls': []}, {'name': 'closeFile', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "FileSystemReceiverUtil.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/CommandPattern/FileSystemReceiverUtil.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.CommandPattern'], 'imports': [], 'info': [{'class': 'FileSystemReceiverUtil', 'methods': [{'name': 'getUnderlyingFileSystem', 'arguments': [], 'calls': ['getProperty']}]}], 'relationships': [{'class': 'FileSystemReceiverUtil', 'relationship_type': 'Association', 'with': 'WindowsFileSystemReceiver'}]}\n",
            "OpenFileCommand.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/CommandPattern/OpenFileCommand.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.CommandPattern'], 'imports': [], 'info': [{'class': 'OpenFileCommand', 'methods': [{'name': 'OpenFileCommand', 'arguments': [{'type': 'FileSystemReceiver', 'name': 'fs'}], 'calls': []}, {'name': 'execute', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'OpenFileCommand', 'relationship_type': 'Realization', 'with': 'Command'}]}\n",
            "UnixFileSystemReceiver.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/CommandPattern/UnixFileSystemReceiver.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.CommandPattern'], 'imports': [], 'info': [{'class': 'UnixFileSystemReceiver', 'methods': [{'name': 'openFile', 'arguments': [], 'calls': []}, {'name': 'writeFile', 'arguments': [], 'calls': []}, {'name': 'closeFile', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'UnixFileSystemReceiver', 'relationship_type': 'Realization', 'with': 'FileSystemReceiver'}]}\n",
            "WindowsFileSystemReceiver.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/CommandPattern/WindowsFileSystemReceiver.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.CommandPattern'], 'imports': [], 'info': [{'class': 'WindowsFileSystemReceiver', 'methods': [{'name': 'openFile', 'arguments': [], 'calls': []}, {'name': 'writeFile', 'arguments': [], 'calls': []}, {'name': 'closeFile', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'WindowsFileSystemReceiver', 'relationship_type': 'Realization', 'with': 'FileSystemReceiver'}]}\n",
            "WriteFileCommand.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/CommandPattern/WriteFileCommand.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.CommandPattern'], 'imports': [], 'info': [{'class': 'WriteFileCommand', 'methods': [{'name': 'WriteFileCommand', 'arguments': [{'type': 'FileSystemReceiver', 'name': 'fs'}], 'calls': []}, {'name': 'execute', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'WriteFileCommand', 'relationship_type': 'Realization', 'with': 'Command'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "Channel.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/IteratorPattern/Channel.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.IteratorPattern'], 'imports': [], 'info': [{'class': 'Channel', 'methods': [{'name': 'Channel', 'arguments': [{'type': 'double', 'name': 'freq'}, {'type': 'ChannelTypeEnum', 'name': 'type'}], 'calls': []}, {'name': 'getFrequency', 'arguments': [], 'calls': []}, {'name': 'getTYPE', 'arguments': [], 'calls': []}, {'name': 'toString', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "ChannelCollection.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/IteratorPattern/ChannelCollection.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.IteratorPattern'], 'imports': [], 'info': [{'interface': 'ChannelCollection', 'methods': [{'name': 'addChannel', 'arguments': [{'type': 'Channel', 'name': 'c'}], 'calls': []}, {'name': 'removeChannel', 'arguments': [{'type': 'Channel', 'name': 'c'}], 'calls': []}, {'name': 'iterator', 'arguments': [{'type': 'ChannelTypeEnum', 'name': 'type'}], 'calls': []}]}], 'relationships': []}\n",
            "ChannelCollectionImpl.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/IteratorPattern/ChannelCollectionImpl.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.IteratorPattern'], 'imports': ['java.util.ArrayList', 'java.util.List'], 'info': [{'class': 'ChannelCollectionImpl', 'methods': [{'name': 'ChannelCollectionImpl', 'arguments': [], 'calls': []}, {'name': 'addChannel', 'arguments': [{'type': 'Channel', 'name': 'c'}], 'calls': []}, {'name': 'removeChannel', 'arguments': [{'type': 'Channel', 'name': 'c'}], 'calls': []}, {'name': 'iterator', 'arguments': [{'type': 'ChannelTypeEnum', 'name': 'type'}], 'calls': []}]}, {'class': 'ChannelIteratorImpl', 'methods': [{'name': 'ChannelIteratorImpl', 'arguments': [{'type': 'ChannelTypeEnum', 'name': 'ty'}, {'type': 'List', 'name': 'channelsList'}], 'calls': []}, {'name': 'hasNext', 'arguments': [], 'calls': []}, {'name': 'next', 'arguments': [], 'calls': ['get']}]}], 'relationships': [{'class': 'ChannelCollectionImpl', 'relationship_type': 'Realization', 'with': 'ChannelCollection'}, {'class': 'ChannelIteratorImpl', 'relationship_type': 'Realization', 'with': 'ChannelIterator'}]}\n",
            "ChannelIterator.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/IteratorPattern/ChannelIterator.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.IteratorPattern'], 'imports': [], 'info': [{'interface': 'ChannelIterator', 'methods': [{'name': 'hasNext', 'arguments': [], 'calls': []}, {'name': 'next', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "ChannelTypeEnum.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/IteratorPattern/ChannelTypeEnum.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.IteratorPattern'], 'imports': [], 'info': [{'enum': 'ChannelTypeEnum', 'values': ['ENGLISH', 'HINDI', 'FRENCH', 'ALL']}], 'relationships': []}\n",
            "IteratorPatternTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/IteratorPattern/IteratorPatternTest.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.IteratorPattern'], 'imports': [], 'info': [{'class': 'IteratorPatternTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': ['populateChannels']}, {'name': 'populateChannels', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "ChatClient.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/MediatorPattern/ChatClient.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.MediatorPattern'], 'imports': [], 'info': [{'class': 'ChatClient', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'ChatClient', 'relationship_type': 'Association', 'with': 'ChatMediatorImpl'}, {'class': 'ChatClient', 'relationship_type': 'Association', 'with': 'UserImpl'}, {'class': 'ChatClient', 'relationship_type': 'Association', 'with': 'UserImpl'}, {'class': 'ChatClient', 'relationship_type': 'Association', 'with': 'UserImpl'}, {'class': 'ChatClient', 'relationship_type': 'Association', 'with': 'UserImpl'}]}\n",
            "ChatMediator.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/MediatorPattern/ChatMediator.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.MediatorPattern'], 'imports': [], 'info': [{'interface': 'ChatMediator', 'methods': [{'name': 'sendMessage', 'arguments': [{'type': 'String', 'name': 'msg'}, {'type': 'User', 'name': 'user'}], 'calls': []}, {'name': 'addUser', 'arguments': [{'type': 'User', 'name': 'user'}], 'calls': []}]}], 'relationships': []}\n",
            "ChatMediatorImpl.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/MediatorPattern/ChatMediatorImpl.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.MediatorPattern'], 'imports': ['java.util.ArrayList', 'java.util.List'], 'info': [{'class': 'ChatMediatorImpl', 'methods': [{'name': 'ChatMediatorImpl', 'arguments': [], 'calls': []}, {'name': 'addUser', 'arguments': [{'type': 'User', 'name': 'user'}], 'calls': []}, {'name': 'sendMessage', 'arguments': [{'type': 'String', 'name': 'msg'}, {'type': 'User', 'name': 'user'}], 'calls': []}]}], 'relationships': [{'class': 'ChatMediatorImpl', 'relationship_type': 'Realization', 'with': 'ChatMediator'}]}\n",
            "User.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/MediatorPattern/User.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.MediatorPattern'], 'imports': [], 'info': [{'class': 'User', 'methods': [{'name': 'User', 'arguments': [{'type': 'ChatMediator', 'name': 'med'}, {'type': 'String', 'name': 'name'}], 'calls': []}, {'name': 'send', 'arguments': [{'type': 'String', 'name': 'msg'}], 'calls': []}, {'name': 'receive', 'arguments': [{'type': 'String', 'name': 'msg'}], 'calls': []}]}, {'abstract_class': 'User', 'methods': [{'name': 'User', 'arguments': [{'type': 'ChatMediator', 'name': 'med'}, {'type': 'String', 'name': 'name'}], 'calls': []}, {'name': 'send', 'arguments': [{'type': 'String', 'name': 'msg'}], 'calls': []}, {'name': 'receive', 'arguments': [{'type': 'String', 'name': 'msg'}], 'calls': []}]}], 'relationships': []}\n",
            "UserImpl.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/MediatorPattern/UserImpl.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.MediatorPattern'], 'imports': [], 'info': [{'class': 'UserImpl', 'methods': [{'name': 'UserImpl', 'arguments': [{'type': 'ChatMediator', 'name': 'med'}, {'type': 'String', 'name': 'name'}], 'calls': ['super']}, {'name': 'send', 'arguments': [{'type': 'String', 'name': 'msg'}], 'calls': []}, {'name': 'receive', 'arguments': [{'type': 'String', 'name': 'msg'}], 'calls': []}]}], 'relationships': [{'class': 'UserImpl', 'relationship_type': 'Generalization', 'with': 'User'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "MyTopic.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ObserverPattern/MyTopic.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ObserverPattern'], 'imports': ['java.util.ArrayList', 'java.util.List'], 'info': [{'class': 'MyTopic', 'methods': [{'name': 'MyTopic', 'arguments': [], 'calls': []}, {'name': 'register', 'arguments': [{'type': 'Observer', 'name': 'obj'}], 'calls': []}, {'name': 'unregister', 'arguments': [{'type': 'Observer', 'name': 'obj'}], 'calls': []}, {'name': 'notifyObservers', 'arguments': [], 'calls': []}, {'name': 'getUpdate', 'arguments': [{'type': 'Observer', 'name': 'obj'}], 'calls': []}, {'name': 'postMessage', 'arguments': [{'type': 'String', 'name': 'msg'}], 'calls': []}]}], 'relationships': [{'class': 'MyTopic', 'relationship_type': 'Association', 'with': 'Object'}, {'class': 'MyTopic', 'relationship_type': 'Realization', 'with': 'Subject'}]}\n",
            "MyTopicSubscriber.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ObserverPattern/MyTopicSubscriber.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ObserverPattern'], 'imports': [], 'info': [{'class': 'MyTopicSubscriber', 'methods': [{'name': 'MyTopicSubscriber', 'arguments': [{'type': 'String', 'name': 'nm'}], 'calls': []}, {'name': 'update', 'arguments': [], 'calls': []}, {'name': 'setSubject', 'arguments': [{'type': 'Subject', 'name': 'sub'}], 'calls': []}]}], 'relationships': [{'class': 'MyTopicSubscriber', 'relationship_type': 'Realization', 'with': 'Observer'}]}\n",
            "Observer.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ObserverPattern/Observer.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ObserverPattern'], 'imports': [], 'info': [{'interface': 'Observer', 'methods': [{'name': 'update', 'arguments': [], 'calls': []}, {'name': 'setSubject', 'arguments': [{'type': 'Subject', 'name': 'sub'}], 'calls': []}]}], 'relationships': []}\n",
            "ObserverPatternTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ObserverPattern/ObserverPatternTest.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ObserverPattern'], 'imports': [], 'info': [{'class': 'ObserverPatternTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'ObserverPatternTest', 'relationship_type': 'Association', 'with': 'MyTopic'}, {'class': 'ObserverPatternTest', 'relationship_type': 'Association', 'with': 'MyTopicSubscriber'}, {'class': 'ObserverPatternTest', 'relationship_type': 'Association', 'with': 'MyTopicSubscriber'}, {'class': 'ObserverPatternTest', 'relationship_type': 'Association', 'with': 'MyTopicSubscriber'}]}\n",
            "Subject.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/ObserverPattern/Subject.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.ObserverPattern'], 'imports': [], 'info': [{'interface': 'Subject', 'methods': [{'name': 'register', 'arguments': [{'type': 'Observer', 'name': 'obj'}], 'calls': []}, {'name': 'unregister', 'arguments': [{'type': 'Observer', 'name': 'obj'}], 'calls': []}, {'name': 'notifyObservers', 'arguments': [], 'calls': []}, {'name': 'getUpdate', 'arguments': [{'type': 'Observer', 'name': 'obj'}], 'calls': []}]}], 'relationships': []}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "State.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StatePattern/State.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StatePattern'], 'imports': [], 'info': [{'interface': 'State', 'methods': [{'name': 'doAction', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "TVContext.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StatePattern/TVContext.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StatePattern'], 'imports': [], 'info': [{'class': 'TVContext', 'methods': [{'name': 'setState', 'arguments': [{'type': 'State', 'name': 'state'}], 'calls': []}, {'name': 'getState', 'arguments': [], 'calls': []}, {'name': 'doAction', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'TVContext', 'relationship_type': 'Realization', 'with': 'State'}]}\n",
            "TVRemote.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StatePattern/TVRemote.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StatePattern'], 'imports': [], 'info': [{'class': 'TVRemote', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'TVRemote', 'relationship_type': 'Association', 'with': 'TVContext'}, {'class': 'TVRemote', 'relationship_type': 'Association', 'with': 'TVStartState'}, {'class': 'TVRemote', 'relationship_type': 'Association', 'with': 'TVStopState'}]}\n",
            "TVRemoteBasic.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StatePattern/TVRemoteBasic.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StatePattern'], 'imports': [], 'info': [{'class': 'TVRemoteBasic', 'methods': [{'name': 'setState', 'arguments': [{'type': 'String', 'name': 'state'}], 'calls': []}, {'name': 'doAction', 'arguments': [], 'calls': []}, {'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': []}\n",
            "TVStartState.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StatePattern/TVStartState.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StatePattern'], 'imports': [], 'info': [{'class': 'TVStartState', 'methods': [{'name': 'doAction', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'TVStartState', 'relationship_type': 'Realization', 'with': 'State'}]}\n",
            "TVStopState.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StatePattern/TVStopState.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StatePattern'], 'imports': [], 'info': [{'class': 'TVStopState', 'methods': [{'name': 'doAction', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'TVStopState', 'relationship_type': 'Realization', 'with': 'State'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "CreditCardStrategy.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StrategyPattern/CreditCardStrategy.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StrategyPattern'], 'imports': [], 'info': [{'class': 'CreditCardStrategy', 'methods': [{'name': 'CreditCardStrategy', 'arguments': [{'type': 'String', 'name': 'nm'}, {'type': 'String', 'name': 'ccNum'}, {'type': 'String', 'name': 'cvv'}, {'type': 'String', 'name': 'expiryDate'}], 'calls': []}, {'name': 'pay', 'arguments': [{'type': 'int', 'name': 'amount'}], 'calls': []}]}], 'relationships': [{'class': 'CreditCardStrategy', 'relationship_type': 'Realization', 'with': 'PaymentStrategy'}]}\n",
            "Item.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StrategyPattern/Item.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StrategyPattern'], 'imports': [], 'info': [{'class': 'Item', 'methods': [{'name': 'Item', 'arguments': [{'type': 'String', 'name': 'upc'}, {'type': 'int', 'name': 'cost'}], 'calls': []}, {'name': 'getUpcCode', 'arguments': [], 'calls': []}, {'name': 'getPrice', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "PaymentStrategy.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StrategyPattern/PaymentStrategy.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StrategyPattern'], 'imports': [], 'info': [{'interface': 'PaymentStrategy', 'methods': [{'name': 'pay', 'arguments': [{'type': 'int', 'name': 'amount'}], 'calls': []}]}], 'relationships': []}\n",
            "PaypalStrategy.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StrategyPattern/PaypalStrategy.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StrategyPattern'], 'imports': [], 'info': [{'class': 'PaypalStrategy', 'methods': [{'name': 'PaypalStrategy', 'arguments': [{'type': 'String', 'name': 'email'}, {'type': 'String', 'name': 'pwd'}], 'calls': []}, {'name': 'pay', 'arguments': [{'type': 'int', 'name': 'amount'}], 'calls': []}]}], 'relationships': [{'class': 'PaypalStrategy', 'relationship_type': 'Realization', 'with': 'PaymentStrategy'}]}\n",
            "ShoppingCart.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StrategyPattern/ShoppingCart.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StrategyPattern'], 'imports': ['java.util.ArrayList', 'java.util.List'], 'info': [{'class': 'ShoppingCart', 'methods': [{'name': 'ShoppingCart', 'arguments': [], 'calls': []}, {'name': 'addItem', 'arguments': [{'type': 'Item', 'name': 'item'}], 'calls': []}, {'name': 'removeItem', 'arguments': [{'type': 'Item', 'name': 'item'}], 'calls': []}, {'name': 'calculateTotal', 'arguments': [], 'calls': []}, {'name': 'pay', 'arguments': [{'type': 'PaymentStrategy', 'name': 'paymentMethod'}], 'calls': ['calculateTotal']}]}], 'relationships': []}\n",
            "ShoppingCartTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/StrategyPattern/ShoppingCartTest.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.StrategyPattern'], 'imports': [], 'info': [{'class': 'ShoppingCartTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'ShoppingCartTest', 'relationship_type': 'Association', 'with': 'ShoppingCart'}, {'class': 'ShoppingCartTest', 'relationship_type': 'Association', 'with': 'Item'}, {'class': 'ShoppingCartTest', 'relationship_type': 'Association', 'with': 'Item'}, {'class': 'ShoppingCartTest', 'relationship_type': 'Association', 'with': 'PaypalStrategy'}, {'class': 'ShoppingCartTest', 'relationship_type': 'Association', 'with': 'CreditCardStrategy'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "GlassHouse.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/TemplatePattern/GlassHouse.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.TemplatePattern'], 'imports': [], 'info': [{'class': 'GlassHouse', 'methods': [{'name': 'buildWalls', 'arguments': [], 'calls': []}, {'name': 'buildPillars', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'GlassHouse', 'relationship_type': 'Generalization', 'with': 'HouseTemplate'}]}\n",
            "HouseTemplate.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/TemplatePattern/HouseTemplate.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.TemplatePattern'], 'imports': [], 'info': [{'class': 'HouseTemplate', 'methods': [{'name': 'buildHouse', 'arguments': [], 'calls': ['buildFoundation']}, {'name': 'buildWindows', 'arguments': [], 'calls': []}, {'name': 'buildWalls', 'arguments': [], 'calls': []}, {'name': 'buildPillars', 'arguments': [], 'calls': []}, {'name': 'buildFoundation', 'arguments': [], 'calls': []}]}, {'abstract_class': 'HouseTemplate', 'methods': [{'name': 'buildHouse', 'arguments': [], 'calls': ['buildFoundation']}, {'name': 'buildWindows', 'arguments': [], 'calls': []}, {'name': 'buildWalls', 'arguments': [], 'calls': []}, {'name': 'buildPillars', 'arguments': [], 'calls': []}, {'name': 'buildFoundation', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "HousingClient.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/TemplatePattern/HousingClient.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.TemplatePattern'], 'imports': [], 'info': [{'class': 'HousingClient', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'HousingClient', 'relationship_type': 'Association', 'with': 'WoodenHouse'}, {'class': 'HousingClient', 'relationship_type': 'Association', 'with': 'GlassHouse'}]}\n",
            "WoodenHouse.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/TemplatePattern/WoodenHouse.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.TemplatePattern'], 'imports': [], 'info': [{'class': 'WoodenHouse', 'methods': [{'name': 'buildWalls', 'arguments': [], 'calls': []}, {'name': 'buildPillars', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'WoodenHouse', 'relationship_type': 'Generalization', 'with': 'HouseTemplate'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "Book.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/VisitorPattern/Book.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.VisitorPattern'], 'imports': [], 'info': [{'class': 'Book', 'methods': [{'name': 'Book', 'arguments': [{'type': 'int', 'name': 'cost'}, {'type': 'String', 'name': 'isbn'}], 'calls': []}, {'name': 'getPrice', 'arguments': [], 'calls': []}, {'name': 'getIsbnNumber', 'arguments': [], 'calls': []}, {'name': 'accept', 'arguments': [{'type': 'ShoppingCartVisitor', 'name': 'visitor'}], 'calls': []}]}], 'relationships': [{'class': 'Book', 'relationship_type': 'Realization', 'with': 'ItemElement'}]}\n",
            "Fruit.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/VisitorPattern/Fruit.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.VisitorPattern'], 'imports': [], 'info': [{'class': 'Fruit', 'methods': [{'name': 'Fruit', 'arguments': [{'type': 'int', 'name': 'priceKg'}, {'type': 'int', 'name': 'wt'}, {'type': 'String', 'name': 'nm'}], 'calls': []}, {'name': 'getPricePerKg', 'arguments': [], 'calls': []}, {'name': 'getWeight', 'arguments': [], 'calls': []}, {'name': 'getName', 'arguments': [], 'calls': []}, {'name': 'accept', 'arguments': [{'type': 'ShoppingCartVisitor', 'name': 'visitor'}], 'calls': []}]}], 'relationships': [{'class': 'Fruit', 'relationship_type': 'Realization', 'with': 'ItemElement'}]}\n",
            "ItemElement.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/VisitorPattern/ItemElement.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.VisitorPattern'], 'imports': [], 'info': [{'interface': 'ItemElement', 'methods': [{'name': 'accept', 'arguments': [{'type': 'ShoppingCartVisitor', 'name': 'visitor'}], 'calls': []}]}], 'relationships': []}\n",
            "ShoppingCartClient.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/VisitorPattern/ShoppingCartClient.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.VisitorPattern'], 'imports': [], 'info': [{'class': 'ShoppingCartClient', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}, {'name': 'calculatePrice', 'arguments': [{'type': 'ItemElement', 'name': 'items'}], 'calls': []}]}], 'relationships': [{'class': 'ShoppingCartClient', 'relationship_type': 'Association', 'with': 'Book'}, {'class': 'ShoppingCartClient', 'relationship_type': 'Association', 'with': 'Fruit'}]}\n",
            "ShoppingCartVisitor.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/VisitorPattern/ShoppingCartVisitor.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.VisitorPattern'], 'imports': [], 'info': [{'interface': 'ShoppingCartVisitor', 'methods': [{'name': 'visit', 'arguments': [{'type': 'Book', 'name': 'book'}], 'calls': []}, {'name': 'visit', 'arguments': [{'type': 'Fruit', 'name': 'fruit'}], 'calls': []}]}], 'relationships': []}\n",
            "ShoppingCartVisitorImpl.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/BehavioralPatterns/VisitorPattern/ShoppingCartVisitorImpl.json\n",
            "[content] --  {'package': ['DesignPatterns.BehavioralPatterns.VisitorPattern'], 'imports': [], 'info': [{'class': 'ShoppingCartVisitorImpl', 'methods': [{'name': 'visit', 'arguments': [{'type': 'Book', 'name': 'book'}], 'calls': []}, {'name': 'visit', 'arguments': [{'type': 'Fruit', 'name': 'fruit'}], 'calls': []}]}], 'relationships': [{'class': 'ShoppingCartVisitorImpl', 'relationship_type': 'Realization', 'with': 'ShoppingCartVisitor'}]}\n",
            "<Response [200]>\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "Computer.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/AbstractFactoryPattern/Computer.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.AbstractFactoryPattern'], 'imports': [], 'info': [{'class': 'Computer', 'methods': [{'name': 'getRAM', 'arguments': [], 'calls': []}, {'name': 'getHDD', 'arguments': [], 'calls': []}, {'name': 'getCPU', 'arguments': [], 'calls': []}, {'name': 'toString', 'arguments': [], 'calls': []}]}, {'abstract_class': 'Computer', 'methods': [{'name': 'getRAM', 'arguments': [], 'calls': []}, {'name': 'getHDD', 'arguments': [], 'calls': []}, {'name': 'getCPU', 'arguments': [], 'calls': []}, {'name': 'toString', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "ComputerAbstractFactory.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/AbstractFactoryPattern/ComputerAbstractFactory.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.AbstractFactoryPattern'], 'imports': [], 'info': [{'interface': 'ComputerAbstractFactory', 'methods': [{'name': 'createComputer', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "ComputerFactory.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/AbstractFactoryPattern/ComputerFactory.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.AbstractFactoryPattern'], 'imports': [], 'info': [{'class': 'ComputerFactory', 'methods': [{'name': 'getComputer', 'arguments': [{'type': 'ComputerAbstractFactory', 'name': 'factory'}], 'calls': []}]}], 'relationships': []}\n",
            "PC.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/AbstractFactoryPattern/PC.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.AbstractFactoryPattern'], 'imports': [], 'info': [{'class': 'PC', 'methods': [{'name': 'PC', 'arguments': [{'type': 'String', 'name': 'ram'}, {'type': 'String', 'name': 'hdd'}, {'type': 'String', 'name': 'cpu'}], 'calls': []}, {'name': 'getRAM', 'arguments': [], 'calls': []}, {'name': 'getHDD', 'arguments': [], 'calls': []}, {'name': 'getCPU', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'PC', 'relationship_type': 'Generalization', 'with': 'Computer'}]}\n",
            "PCFactory.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/AbstractFactoryPattern/PCFactory.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.AbstractFactoryPattern'], 'imports': [], 'info': [{'class': 'PCFactory', 'methods': [{'name': 'PCFactory', 'arguments': [{'type': 'String', 'name': 'ram'}, {'type': 'String', 'name': 'hdd'}, {'type': 'String', 'name': 'cpu'}], 'calls': []}, {'name': 'createComputer', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'PCFactory', 'relationship_type': 'Realization', 'with': 'ComputerAbstractFactory'}]}\n",
            "Server.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/AbstractFactoryPattern/Server.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.AbstractFactoryPattern'], 'imports': [], 'info': [{'class': 'Server', 'methods': [{'name': 'Server', 'arguments': [{'type': 'String', 'name': 'ram'}, {'type': 'String', 'name': 'hdd'}, {'type': 'String', 'name': 'cpu'}], 'calls': []}, {'name': 'getRAM', 'arguments': [], 'calls': []}, {'name': 'getHDD', 'arguments': [], 'calls': []}, {'name': 'getCPU', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'Server', 'relationship_type': 'Generalization', 'with': 'Computer'}]}\n",
            "ServerFactory.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/AbstractFactoryPattern/ServerFactory.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.AbstractFactoryPattern'], 'imports': [], 'info': [{'class': 'ServerFactory', 'methods': [{'name': 'ServerFactory', 'arguments': [{'type': 'String', 'name': 'ram'}, {'type': 'String', 'name': 'hdd'}, {'type': 'String', 'name': 'cpu'}], 'calls': []}, {'name': 'createComputer', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'ServerFactory', 'relationship_type': 'Realization', 'with': 'ComputerAbstractFactory'}]}\n",
            "TestDesignPatterns.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/AbstractFactoryPattern/TestDesignPatterns.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.AbstractFactoryPattern'], 'imports': [], 'info': [{'class': 'TestDesignPatterns', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': ['testAbstractFactory']}, {'name': 'testAbstractFactory', 'arguments': [], 'calls': ['getComputer']}]}], 'relationships': []}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "Computer.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/BuilderPattern/Computer.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.BuilderPattern'], 'imports': [], 'info': [{'class': 'Computer', 'methods': [{'name': 'getHDD', 'arguments': [], 'calls': []}, {'name': 'getRAM', 'arguments': [], 'calls': []}, {'name': 'isGraphicsCardEnabled', 'arguments': [], 'calls': []}, {'name': 'isBluetoothEnabled', 'arguments': [], 'calls': []}, {'name': 'Computer', 'arguments': [{'type': 'ComputerBuilder', 'name': 'builder'}], 'calls': []}]}, {'class': 'ComputerBuilder', 'methods': [{'name': 'ComputerBuilder', 'arguments': [{'type': 'String', 'name': 'hdd'}, {'type': 'String', 'name': 'ram'}], 'calls': []}, {'name': 'setGraphicsCardEnabled', 'arguments': [{'type': 'boolean', 'name': 'isGraphicsCardEnabled'}], 'calls': []}, {'name': 'setBluetoothEnabled', 'arguments': [{'type': 'boolean', 'name': 'isBluetoothEnabled'}], 'calls': []}, {'name': 'build', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "TestBuilderPattern.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/BuilderPattern/TestBuilderPattern.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.BuilderPattern'], 'imports': [], 'info': [{'class': 'TestBuilderPattern', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': []}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "Computer.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/FactoryPattern/Computer.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.FactoryPattern'], 'imports': [], 'info': [{'class': 'Computer', 'methods': [{'name': 'getRAM', 'arguments': [], 'calls': []}, {'name': 'getHDD', 'arguments': [], 'calls': []}, {'name': 'getCPU', 'arguments': [], 'calls': []}, {'name': 'toString', 'arguments': [], 'calls': []}]}, {'abstract_class': 'Computer', 'methods': [{'name': 'getRAM', 'arguments': [], 'calls': []}, {'name': 'getHDD', 'arguments': [], 'calls': []}, {'name': 'getCPU', 'arguments': [], 'calls': []}, {'name': 'toString', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "ComputerFactory.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/FactoryPattern/ComputerFactory.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.FactoryPattern'], 'imports': [], 'info': [{'class': 'ComputerFactory', 'methods': [{'name': 'getComputer', 'arguments': [{'type': 'String', 'name': 'type'}, {'type': 'String', 'name': 'ram'}, {'type': 'String', 'name': 'hdd'}, {'type': 'String', 'name': 'cpu'}], 'calls': []}]}], 'relationships': [{'class': 'ComputerFactory', 'relationship_type': 'Association', 'with': 'PC'}, {'class': 'ComputerFactory', 'relationship_type': 'Association', 'with': 'Server'}]}\n",
            "PC.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/FactoryPattern/PC.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.FactoryPattern'], 'imports': [], 'info': [{'class': 'PC', 'methods': [{'name': 'PC', 'arguments': [{'type': 'String', 'name': 'ram'}, {'type': 'String', 'name': 'hdd'}, {'type': 'String', 'name': 'cpu'}], 'calls': []}, {'name': 'getRAM', 'arguments': [], 'calls': []}, {'name': 'getHDD', 'arguments': [], 'calls': []}, {'name': 'getCPU', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'PC', 'relationship_type': 'Generalization', 'with': 'Computer'}]}\n",
            "Server.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/FactoryPattern/Server.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.FactoryPattern'], 'imports': [], 'info': [{'class': 'Server', 'methods': [{'name': 'Server', 'arguments': [{'type': 'String', 'name': 'ram'}, {'type': 'String', 'name': 'hdd'}, {'type': 'String', 'name': 'cpu'}], 'calls': []}, {'name': 'getRAM', 'arguments': [], 'calls': []}, {'name': 'getHDD', 'arguments': [], 'calls': []}, {'name': 'getCPU', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'Server', 'relationship_type': 'Generalization', 'with': 'Computer'}]}\n",
            "TestFactory.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/FactoryPattern/TestFactory.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.FactoryPattern'], 'imports': [], 'info': [{'class': 'TestFactory', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': ['getComputer']}]}], 'relationships': []}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "Employees.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/PrototypePattern/Employees.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.PrototypePattern'], 'imports': ['java.util.ArrayList', 'java.util.List'], 'info': [{'class': 'Employees', 'methods': [{'name': 'Employees', 'arguments': [], 'calls': []}, {'name': 'Employees', 'arguments': [{'type': 'List', 'name': 'list'}], 'calls': []}, {'name': 'loadData', 'arguments': [], 'calls': ['add']}, {'name': 'getEmpList', 'arguments': [], 'calls': []}, {'name': 'clone', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'Employees', 'relationship_type': 'Realization', 'with': 'Cloneable'}]}\n",
            "PrototypePatternTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/PrototypePattern/PrototypePatternTest.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.PrototypePattern'], 'imports': ['java.util.List'], 'info': [{'class': 'PrototypePatternTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'PrototypePatternTest', 'relationship_type': 'Association', 'with': 'Employees'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "BillPughSingleton.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/SignletonPattern/BillPughSingleton.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.SignletonPattern'], 'imports': [], 'info': [{'class': 'BillPughSingleton', 'methods': [{'name': 'BillPughSingleton', 'arguments': [], 'calls': None}, {'name': 'getInstance', 'arguments': [], 'calls': []}]}, {'class': 'SingletonHelper', 'methods': []}], 'relationships': [{'class': 'SingletonHelper', 'relationship_type': 'Association', 'with': 'BillPughSingleton'}]}\n",
            "EagerInitializedSingleton.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/SignletonPattern/EagerInitializedSingleton.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.SignletonPattern'], 'imports': [], 'info': [{'class': 'EagerInitializedSingleton', 'methods': [{'name': 'EagerInitializedSingleton', 'arguments': [], 'calls': None}, {'name': 'getInstance', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'EagerInitializedSingleton', 'relationship_type': 'Association', 'with': 'EagerInitializedSingleton'}]}\n",
            "EnumSingleton.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/SignletonPattern/EnumSingleton.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.SignletonPattern'], 'imports': [], 'info': [{'enum': 'EnumSingleton', 'values': ['INSTANCE']}], 'relationships': []}\n",
            "LazyInitializedSingleton.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/SignletonPattern/LazyInitializedSingleton.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.SignletonPattern'], 'imports': [], 'info': [{'class': 'LazyInitializedSingleton', 'methods': [{'name': 'LazyInitializedSingleton', 'arguments': [], 'calls': None}, {'name': 'getInstance', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "ReflectionSingletonTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/SignletonPattern/ReflectionSingletonTest.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.SignletonPattern'], 'imports': ['java.lang.reflect.Constructor'], 'info': [{'class': 'ReflectionSingletonTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': ['getInstance']}]}], 'relationships': []}\n",
            "SerializedSingleton.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/SignletonPattern/SerializedSingleton.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.SignletonPattern'], 'imports': ['java.io.Serializable'], 'info': [{'class': 'SerializedSingleton', 'methods': [{'name': 'SerializedSingleton', 'arguments': [], 'calls': None}, {'name': 'getInstance', 'arguments': [], 'calls': []}]}, {'class': 'SingletonHelper', 'methods': []}], 'relationships': [{'class': 'SingletonHelper', 'relationship_type': 'Association', 'with': 'SerializedSingleton'}, {'class': 'SerializedSingleton', 'relationship_type': 'Realization', 'with': 'Serializable'}]}\n",
            "SingletonSerializedTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/SignletonPattern/SingletonSerializedTest.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.SignletonPattern'], 'imports': ['java.io.FileInputStream', 'java.io.FileNotFoundException', 'java.io.FileOutputStream', 'java.io.IOException', 'java.io.ObjectInput', 'java.io.ObjectInputStream', 'java.io.ObjectOutput', 'java.io.ObjectOutputStream'], 'info': [{'class': 'SingletonSerializedTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': ['getInstance']}]}], 'relationships': []}\n",
            "StaticBlockSingleton.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/SignletonPattern/StaticBlockSingleton.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.SignletonPattern'], 'imports': [], 'info': [{'class': 'StaticBlockSingleton', 'methods': [{'name': 'StaticBlockSingleton', 'arguments': [], 'calls': None}, {'name': 'getInstance', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "ThreadSafeSingleton.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/CreationalPatterns/SignletonPattern/ThreadSafeSingleton.json\n",
            "[content] --  {'package': ['DesignPatterns.CreationalPatterns.SignletonPattern'], 'imports': [], 'info': [{'class': 'ThreadSafeSingleton', 'methods': [{'name': 'ThreadSafeSingleton', 'arguments': [], 'calls': None}, {'name': 'getInstance', 'arguments': [], 'calls': []}, {'name': 'getInstanceUsingDoubleLocking', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "<Response [200]>\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "dir\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "AdapterPatternTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/AdapterPattern/AdapterPatternTest.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.AdapterPattern'], 'imports': [], 'info': [{'class': 'AdapterPatternTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': ['testClassAdapter']}, {'name': 'testObjectAdapter', 'arguments': [], 'calls': []}, {'name': 'testClassAdapter', 'arguments': [], 'calls': []}, {'name': 'getVolt', 'arguments': [{'type': 'SocketAdapter', 'name': 'sockAdapter'}, {'type': 'int', 'name': 'i'}], 'calls': []}]}], 'relationships': []}\n",
            "Socket.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/AdapterPattern/Socket.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.AdapterPattern'], 'imports': [], 'info': [{'class': 'Socket', 'methods': [{'name': 'getVolt', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'Socket', 'relationship_type': 'Association', 'with': 'Volt'}]}\n",
            "SocketAdapter.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/AdapterPattern/SocketAdapter.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.AdapterPattern'], 'imports': [], 'info': [{'interface': 'SocketAdapter', 'methods': [{'name': 'get120Volt', 'arguments': [], 'calls': []}, {'name': 'get12Volt', 'arguments': [], 'calls': []}, {'name': 'get3Volt', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "SocketClassAdapterImpl.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/AdapterPattern/SocketClassAdapterImpl.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.AdapterPattern'], 'imports': [], 'info': [{'class': 'SocketClassAdapterImpl', 'methods': [{'name': 'get120Volt', 'arguments': [], 'calls': []}, {'name': 'get12Volt', 'arguments': [], 'calls': ['getVolt']}, {'name': 'get3Volt', 'arguments': [], 'calls': ['getVolt']}, {'name': 'convertVolt', 'arguments': [{'type': 'Volt', 'name': 'v'}, {'type': 'int', 'name': 'i'}], 'calls': []}]}], 'relationships': [{'class': 'SocketClassAdapterImpl', 'relationship_type': 'Generalization', 'with': 'Socket'}]}\n",
            "SocketObjectAdapterImpl.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/AdapterPattern/SocketObjectAdapterImpl.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.AdapterPattern'], 'imports': [], 'info': [{'class': 'SocketObjectAdapterImpl', 'methods': [{'name': 'get120Volt', 'arguments': [], 'calls': []}, {'name': 'get12Volt', 'arguments': [], 'calls': ['getVolt']}, {'name': 'get3Volt', 'arguments': [], 'calls': ['getVolt']}, {'name': 'convertVolt', 'arguments': [{'type': 'Volt', 'name': 'v'}, {'type': 'int', 'name': 'i'}], 'calls': []}]}], 'relationships': [{'class': 'SocketObjectAdapterImpl', 'relationship_type': 'Association', 'with': 'Socket'}, {'class': 'SocketObjectAdapterImpl', 'relationship_type': 'Realization', 'with': 'SocketAdapter'}]}\n",
            "Volt.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/AdapterPattern/Volt.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.AdapterPattern'], 'imports': [], 'info': [{'class': 'Volt', 'methods': [{'name': 'Volt', 'arguments': [{'type': 'int', 'name': 'v'}], 'calls': []}, {'name': 'getVolts', 'arguments': [], 'calls': []}, {'name': 'setVolts', 'arguments': [{'type': 'int', 'name': 'volts'}], 'calls': []}]}], 'relationships': []}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "BridgePatternTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/BridgePattern/BridgePatternTest.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.BridgePattern'], 'imports': [], 'info': [{'class': 'BridgePatternTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'BridgePatternTest', 'relationship_type': 'Association', 'with': 'Triangle'}, {'class': 'BridgePatternTest', 'relationship_type': 'Association', 'with': 'Pentagon'}]}\n",
            "Color.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/BridgePattern/Color.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.BridgePattern'], 'imports': [], 'info': [{'interface': 'Color', 'methods': [{'name': 'applyColor', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "GreenColor.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/BridgePattern/GreenColor.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.BridgePattern'], 'imports': [], 'info': [{'class': 'GreenColor', 'methods': [{'name': 'applyColor', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'GreenColor', 'relationship_type': 'Realization', 'with': 'Color'}]}\n",
            "Pentagon.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/BridgePattern/Pentagon.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.BridgePattern'], 'imports': [], 'info': [{'class': 'Pentagon', 'methods': [{'name': 'Pentagon', 'arguments': [{'type': 'Color', 'name': 'c'}], 'calls': ['super']}, {'name': 'applyColor', 'arguments': [], 'calls': ['print']}]}], 'relationships': [{'class': 'Pentagon', 'relationship_type': 'Generalization', 'with': 'Shape'}]}\n",
            "RedColor.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/BridgePattern/RedColor.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.BridgePattern'], 'imports': [], 'info': [{'class': 'RedColor', 'methods': [{'name': 'applyColor', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'RedColor', 'relationship_type': 'Realization', 'with': 'Color'}]}\n",
            "Shape.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/BridgePattern/Shape.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.BridgePattern'], 'imports': [], 'info': [{'class': 'Shape', 'methods': [{'name': 'Shape', 'arguments': [{'type': 'Color', 'name': 'c'}], 'calls': []}, {'name': 'applyColor', 'arguments': [], 'calls': []}]}, {'abstract_class': 'Shape', 'methods': [{'name': 'Shape', 'arguments': [{'type': 'Color', 'name': 'c'}], 'calls': []}, {'name': 'applyColor', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "Triangle.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/BridgePattern/Triangle.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.BridgePattern'], 'imports': [], 'info': [{'class': 'Triangle', 'methods': [{'name': 'Triangle', 'arguments': [{'type': 'Color', 'name': 'c'}], 'calls': ['super']}, {'name': 'applyColor', 'arguments': [], 'calls': ['print']}]}], 'relationships': [{'class': 'Triangle', 'relationship_type': 'Generalization', 'with': 'Shape'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "Circle.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/CompositePattern/Circle.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.CompositePattern'], 'imports': [], 'info': [{'class': 'Circle', 'methods': [{'name': 'draw', 'arguments': [{'type': 'String', 'name': 'fillColor'}], 'calls': []}]}], 'relationships': [{'class': 'Circle', 'relationship_type': 'Realization', 'with': 'Shape'}]}\n",
            "Drawing.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/CompositePattern/Drawing.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.CompositePattern'], 'imports': ['java.util.ArrayList', 'java.util.List'], 'info': [{'class': 'Drawing', 'methods': [{'name': 'draw', 'arguments': [{'type': 'String', 'name': 'fillColor'}], 'calls': []}, {'name': 'add', 'arguments': [{'type': 'Shape', 'name': 's'}], 'calls': []}, {'name': 'remove', 'arguments': [{'type': 'Shape', 'name': 's'}], 'calls': ['remove']}, {'name': 'clear', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'Drawing', 'relationship_type': 'Realization', 'with': 'Shape'}]}\n",
            "Shape.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/CompositePattern/Shape.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.CompositePattern'], 'imports': [], 'info': [{'interface': 'Shape', 'methods': [{'name': 'draw', 'arguments': [{'type': 'String', 'name': 'fillColor'}], 'calls': []}]}], 'relationships': []}\n",
            "TestCompositePattern.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/CompositePattern/TestCompositePattern.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.CompositePattern'], 'imports': [], 'info': [{'class': 'TestCompositePattern', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'TestCompositePattern', 'relationship_type': 'Association', 'with': 'Triangle'}, {'class': 'TestCompositePattern', 'relationship_type': 'Association', 'with': 'Triangle'}, {'class': 'TestCompositePattern', 'relationship_type': 'Association', 'with': 'Circle'}, {'class': 'TestCompositePattern', 'relationship_type': 'Association', 'with': 'Drawing'}]}\n",
            "Triangle.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/CompositePattern/Triangle.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.CompositePattern'], 'imports': [], 'info': [{'class': 'Triangle', 'methods': [{'name': 'draw', 'arguments': [{'type': 'String', 'name': 'fillColor'}], 'calls': []}]}], 'relationships': [{'class': 'Triangle', 'relationship_type': 'Realization', 'with': 'Shape'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "BasicCar.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/DecoratorPattern/BasicCar.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.DecoratorPattern'], 'imports': [], 'info': [{'class': 'BasicCar', 'methods': [{'name': 'assemble', 'arguments': [], 'calls': ['print']}]}], 'relationships': [{'class': 'BasicCar', 'relationship_type': 'Realization', 'with': 'Car'}]}\n",
            "Car.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/DecoratorPattern/Car.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.DecoratorPattern'], 'imports': [], 'info': [{'interface': 'Car', 'methods': [{'name': 'assemble', 'arguments': [], 'calls': []}]}], 'relationships': []}\n",
            "CarDecorator.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/DecoratorPattern/CarDecorator.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.DecoratorPattern'], 'imports': [], 'info': [{'class': 'CarDecorator', 'methods': [{'name': 'CarDecorator', 'arguments': [{'type': 'Car', 'name': 'c'}], 'calls': []}, {'name': 'assemble', 'arguments': [], 'calls': []}]}], 'relationships': [{'class': 'CarDecorator', 'relationship_type': 'Realization', 'with': 'Car'}]}\n",
            "DecoratorPatternTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/DecoratorPattern/DecoratorPatternTest.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.DecoratorPattern'], 'imports': [], 'info': [{'class': 'DecoratorPatternTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'DecoratorPatternTest', 'relationship_type': 'Association', 'with': 'SportsCar'}, {'class': 'DecoratorPatternTest', 'relationship_type': 'Association', 'with': 'SportsCar'}]}\n",
            "LuxuryCar.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/DecoratorPattern/LuxuryCar.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.DecoratorPattern'], 'imports': [], 'info': [{'class': 'LuxuryCar', 'methods': [{'name': 'LuxuryCar', 'arguments': [{'type': 'Car', 'name': 'c'}], 'calls': ['super']}, {'name': 'assemble', 'arguments': [], 'calls': ['assemble']}]}], 'relationships': [{'class': 'LuxuryCar', 'relationship_type': 'Generalization', 'with': 'CarDecorator'}]}\n",
            "SportsCar.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/DecoratorPattern/SportsCar.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.DecoratorPattern'], 'imports': [], 'info': [{'class': 'SportsCar', 'methods': [{'name': 'SportsCar', 'arguments': [{'type': 'Car', 'name': 'c'}], 'calls': ['super']}, {'name': 'assemble', 'arguments': [], 'calls': ['assemble']}]}], 'relationships': [{'class': 'SportsCar', 'relationship_type': 'Generalization', 'with': 'CarDecorator'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "FacadePatternTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/FacadePattern/FacadePatternTest.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.FacadePattern'], 'imports': ['java.sql.Connection'], 'info': [{'class': 'FacadePatternTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'FacadePatternTest', 'relationship_type': 'Association', 'with': 'MySqlHelper'}, {'class': 'FacadePatternTest', 'relationship_type': 'Association', 'with': 'OracleHelper'}]}\n",
            "HelperFacade.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/FacadePattern/HelperFacade.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.FacadePattern'], 'imports': ['java.sql.Connection'], 'info': [{'class': 'HelperFacade', 'methods': [{'name': 'generateReport', 'arguments': [{'type': 'DBTypes', 'name': 'dbType'}, {'type': 'ReportTypes', 'name': 'reportType'}, {'type': 'String', 'name': 'tableName'}], 'calls': []}]}, {'enum': 'DBTypes', 'values': ['MYSQL', 'ORACLE']}, {'enum': 'ReportTypes', 'values': ['HTML', 'PDF']}], 'relationships': [{'class': 'HelperFacade', 'relationship_type': 'Association', 'with': 'MySqlHelper'}]}\n",
            "MySqlHelper.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/FacadePattern/MySqlHelper.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.FacadePattern'], 'imports': ['java.sql.Connection'], 'info': [{'class': 'MySqlHelper', 'methods': [{'name': 'getMySqlDBConnection', 'arguments': [], 'calls': []}, {'name': 'generateMySqlPDFReport', 'arguments': [{'type': 'String', 'name': 'tableName'}, {'type': 'Connection', 'name': 'con'}], 'calls': None}, {'name': 'generateMySqlHTMLReport', 'arguments': [{'type': 'String', 'name': 'tableName'}, {'type': 'Connection', 'name': 'con'}], 'calls': None}]}], 'relationships': []}\n",
            "OracleHelper.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/FacadePattern/OracleHelper.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.FacadePattern'], 'imports': ['java.sql.Connection'], 'info': [{'class': 'OracleHelper', 'methods': [{'name': 'getOracleDBConnection', 'arguments': [], 'calls': []}, {'name': 'generateOraclePDFReport', 'arguments': [{'type': 'String', 'name': 'tableName'}, {'type': 'Connection', 'name': 'con'}], 'calls': None}, {'name': 'generateOracleHTMLReport', 'arguments': [{'type': 'String', 'name': 'tableName'}, {'type': 'Connection', 'name': 'con'}], 'calls': None}]}], 'relationships': []}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "DrawingClient.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/FlyweightPattern/DrawingClient.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.FlyweightPattern'], 'imports': ['DesignPatterns.StructuralPatterns.FlyweightPattern.ShapeFactory.ShapeType', 'javax.swing.*', 'java.awt.*', 'java.awt.event.ActionEvent', 'java.awt.event.ActionListener'], 'info': [{'class': 'DrawingClient', 'methods': [{'name': 'DrawingClient', 'arguments': [{'type': 'int', 'name': 'width'}, {'type': 'int', 'name': 'height'}], 'calls': []}, {'name': 'getRandomShape', 'arguments': [], 'calls': []}, {'name': 'getRandomX', 'arguments': [], 'calls': []}, {'name': 'getRandomY', 'arguments': [], 'calls': []}, {'name': 'getRandomWidth', 'arguments': [], 'calls': []}, {'name': 'getRandomHeight', 'arguments': [], 'calls': []}, {'name': 'getRandomColor', 'arguments': [], 'calls': []}, {'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'DrawingClient', 'relationship_type': 'Generalization', 'with': 'JFrame'}]}\n",
            "Line.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/FlyweightPattern/Line.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.FlyweightPattern'], 'imports': ['java.awt.Color', 'java.awt.Graphics'], 'info': [{'class': 'Line', 'methods': [{'name': 'Line', 'arguments': [], 'calls': []}, {'name': 'draw', 'arguments': [{'type': 'Graphics', 'name': 'line'}, {'type': 'int', 'name': 'x1'}, {'type': 'int', 'name': 'y1'}, {'type': 'int', 'name': 'x2'}, {'type': 'int', 'name': 'y2'}, {'type': 'Color', 'name': 'color'}], 'calls': ['setColor']}]}], 'relationships': [{'class': 'Line', 'relationship_type': 'Realization', 'with': 'Shape'}]}\n",
            "Oval.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/FlyweightPattern/Oval.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.FlyweightPattern'], 'imports': ['java.awt.Color', 'java.awt.Graphics'], 'info': [{'class': 'Oval', 'methods': [{'name': 'Oval', 'arguments': [{'type': 'boolean', 'name': 'f'}], 'calls': []}, {'name': 'draw', 'arguments': [{'type': 'Graphics', 'name': 'circle'}, {'type': 'int', 'name': 'x'}, {'type': 'int', 'name': 'y'}, {'type': 'int', 'name': 'width'}, {'type': 'int', 'name': 'height'}, {'type': 'Color', 'name': 'color'}], 'calls': ['setColor']}]}], 'relationships': [{'class': 'Oval', 'relationship_type': 'Realization', 'with': 'Shape'}]}\n",
            "Shape.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/FlyweightPattern/Shape.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.FlyweightPattern'], 'imports': ['java.awt.Color', 'java.awt.Graphics'], 'info': [{'interface': 'Shape', 'methods': [{'name': 'draw', 'arguments': [{'type': 'Graphics', 'name': 'g'}, {'type': 'int', 'name': 'x'}, {'type': 'int', 'name': 'y'}, {'type': 'int', 'name': 'width'}, {'type': 'int', 'name': 'height'}, {'type': 'Color', 'name': 'color'}], 'calls': []}]}], 'relationships': []}\n",
            "ShapeFactory.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/FlyweightPattern/ShapeFactory.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.FlyweightPattern'], 'imports': ['java.util.HashMap'], 'info': [{'class': 'ShapeFactory', 'methods': [{'name': 'getShape', 'arguments': [{'type': 'ShapeType', 'name': 'type'}], 'calls': ['get']}]}, {'enum': 'ShapeType', 'values': ['OVAL_FILL', 'OVAL_NOFILL', 'LINE']}], 'relationships': [{'class': 'ShapeFactory', 'relationship_type': 'Association', 'with': 'Oval'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "file\n",
            "CommandExecutor.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/ProxyPattern/CommandExecutor.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.ProxyPattern'], 'imports': [], 'info': [{'interface': 'CommandExecutor', 'methods': [{'name': 'runCommand', 'arguments': [{'type': 'String', 'name': 'cmd'}], 'calls': []}]}], 'relationships': []}\n",
            "CommandExecutorImpl.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/ProxyPattern/CommandExecutorImpl.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.ProxyPattern'], 'imports': ['java.io.IOException'], 'info': [{'class': 'CommandExecutorImpl', 'methods': [{'name': 'runCommand', 'arguments': [{'type': 'String', 'name': 'cmd'}], 'calls': ['getRuntime']}]}], 'relationships': [{'class': 'CommandExecutorImpl', 'relationship_type': 'Realization', 'with': 'CommandExecutor'}]}\n",
            "CommandExecutorProxy.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/ProxyPattern/CommandExecutorProxy.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.ProxyPattern'], 'imports': [], 'info': [{'class': 'CommandExecutorProxy', 'methods': [{'name': 'CommandExecutorProxy', 'arguments': [{'type': 'String', 'name': 'user'}, {'type': 'String', 'name': 'pwd'}], 'calls': []}, {'name': 'runCommand', 'arguments': [{'type': 'String', 'name': 'cmd'}], 'calls': []}]}], 'relationships': [{'class': 'CommandExecutorProxy', 'relationship_type': 'Association', 'with': 'CommandExecutorImpl'}, {'class': 'CommandExecutorProxy', 'relationship_type': 'Realization', 'with': 'CommandExecutor'}]}\n",
            "ProxyPatternTest.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/DesignPatterns/StructuralPatterns/ProxyPattern/ProxyPatternTest.json\n",
            "[content] --  {'package': ['DesignPatterns.StructuralPatterns.ProxyPattern'], 'imports': [], 'info': [{'class': 'ProxyPatternTest', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'ProxyPatternTest', 'relationship_type': 'Association', 'with': 'CommandExecutorProxy'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "file\n",
            "file\n",
            "DataBind.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/JavaToJSON/DataBind.json\n",
            "[content] --  {'package': ['JavaToJSON'], 'imports': ['com.fasterxml.jackson.databind.ObjectMapper', 'java.io.*'], 'info': [{'class': 'DataBind', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}, {'name': 'convertJavaCodeToJson', 'arguments': [{'type': 'String', 'name': 'javaCode'}], 'calls': []}]}], 'relationships': [{'class': 'DataBind', 'relationship_type': 'Association', 'with': 'StringBuilder'}, {'class': 'DataBind', 'relationship_type': 'Association', 'with': 'BufferedReader'}]}\n",
            "JavaToJSONConverter.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/JavaToJSON/JavaToJSONConverter.json\n",
            "[content] --  {'package': ['JavaToJSON'], 'imports': ['com.fasterxml.jackson.databind.ObjectMapper', 'java.io.*'], 'info': [{'class': 'JavaToJSONConverter', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}]}], 'relationships': [{'class': 'JavaToJSONConverter', 'relationship_type': 'Association', 'with': 'ObjectMapper'}, {'class': 'JavaToJSONConverter', 'relationship_type': 'Association', 'with': 'File'}, {'class': 'JavaToJSONConverter', 'relationship_type': 'Association', 'with': 'StringBuilder'}, {'class': 'JavaToJSONConverter', 'relationship_type': 'Association', 'with': 'BufferedReader'}]}\n",
            "Main.java\n",
            "[path] --  /content/drive/MyDrive/SPL3/WilliamMary/JSON/SPL3/src/JavaToJSON/Main.json\n",
            "[content] --  {'package': ['JavaToJSON'], 'imports': ['java.io.BufferedReader', 'java.io.FileReader', 'java.io.IOException'], 'info': [{'class': 'Main', 'methods': [{'name': 'main', 'arguments': [{'type': 'String', 'name': 'args'}], 'calls': []}, {'name': 'escapeJsonString', 'arguments': [{'type': 'String', 'name': 's'}], 'calls': []}]}], 'relationships': [{'class': 'Main', 'relationship_type': 'Association', 'with': 'BufferedReader'}, {'class': 'Main', 'relationship_type': 'Association', 'with': 'StringBuilder'}]}\n",
            "<Response [200]>\n",
            "file\n",
            "primary.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "rME3G1hENeZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(data):\n",
        "    package_name = data.get(\"package\", [0])[0]\n",
        "    imports_count = len(data.get(\"imports\", []))\n",
        "\n",
        "    info = data.get(\"info\", [])\n",
        "    classes_count = sum(1 for item in info if \"class\" in item)\n",
        "    interfaces_count = sum(1 for item in info if \"interface\" in item)\n",
        "    enums_count = sum(1 for item in info if \"enum\" in item)\n",
        "\n",
        "    total_methods_count = sum(len(item.get(\"methods\", [])) for item in info if \"methods\" in item)\n",
        "\n",
        "    methods_in_interfaces = sum(len(item.get(\"methods\", [])) for item in info if \"interface\" in item)\n",
        "    methods_in_classes = sum(len(item.get(\"methods\", [])) for item in info if \"class\" in item)\n",
        "\n",
        "    relationships_count = {\n",
        "        \"Generalization\": 0,\n",
        "        \"Association\": 0,\n",
        "        \"Realization\": 0\n",
        "    }\n",
        "\n",
        "    relationships = data.get(\"relationships\", [])\n",
        "    for relationship in relationships:\n",
        "        relationship_type = relationship.get(\"relationship_type\", \"\")\n",
        "        if relationship_type in relationships_count:\n",
        "            relationships_count[relationship_type] += 1\n",
        "\n",
        "    total_relationships = sum(relationships_count.values())\n",
        "\n",
        "    return [package_name, imports_count, classes_count, interfaces_count, enums_count, methods_in_interfaces, methods_in_classes, total_methods_count, relationships_count[\"Generalization\"], relationships_count[\"Association\"], relationships_count[\"Realization\"], total_relationships]\n",
        "\n",
        "\n",
        "with open('/content/sample_data/data.json', \"r\") as json_file:\n",
        "  json_data = json.load(json_file)\n",
        "\n",
        "json_statistics = calculate_metrics(json_data)\n",
        "print(json_statistics)\n"
      ],
      "metadata": {
        "id": "eRM4bh-hNiIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def calculate_metrics(data):\n",
        "    package_name = data.get(\"package\", \"\")\n",
        "    imports_count = len(data.get(\"imports\", []))\n",
        "    total_classes = len(data.get(\"info\", []))\n",
        "    interfaces_count = len([info for info in data.get(\"info\", []) if \"interface\" in info])\n",
        "    total_enums = len([info for info in data.get(\"info\", []) if \"enum\" in info])\n",
        "\n",
        "    methods_in_interfaces = sum(len(info[\"methods\"]) for info in data.get(\"info\", []) if \"interface\" in info)\n",
        "    methods_in_classes = sum(len(info[\"methods\"]) for info in data.get(\"info\", []) if \"class\" in info)\n",
        "    methods_in_abstract_classes = sum(len(info[\"methods\"]) for info in data.get(\"info\", []) if \"abstract_class\" in info)\n",
        "    total_methods = methods_in_interfaces + methods_in_classes + methods_in_abstract_classes\n",
        "\n",
        "    total_calls = sum(len(method[\"calls\"]) for info in data.get(\"info\", []) for method in info.get(\"methods\", []))\n",
        "    total_arguments = sum(len(method[\"arguments\"]) for info in data.get(\"info\", []) for method in info.get(\"methods\", []))\n",
        "\n",
        "    relationships_count = {\n",
        "        \"Generalization\": 0,\n",
        "        \"Association\": 0,\n",
        "        \"Realization\": 0\n",
        "    }\n",
        "\n",
        "    for relationship in data.get(\"relationships\", []):\n",
        "        relationship_type = relationship.get(\"relationship_type\")\n",
        "        if relationship_type in relationships_count:\n",
        "            relationships_count[relationship_type] += 1\n",
        "\n",
        "    return package_name, imports_count, total_classes, interfaces_count, total_enums, methods_in_classes, methods_in_abstract_classes, methods_in_interfaces, total_methods, total_calls, total_arguments, relationships_count[\"Generalization\"], relationships_count[\"Association\"], relationships_count[\"Realization\"], sum(relationships_count.values())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with open(\"/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Cricket/Match.json\", \"r\") as file:\n",
        "        json_data = json.load(file)\n",
        "\n",
        "    package_name, imports_count, total_classes, interfaces_count, total_enums, methods_in_classes, methods_in_abstract_classes, methods_in_interfaces, total_methods, total_calls, total_arguments, generalization_count, association_count, realization_count, total_relationships = calculate_metrics(json_data)\n",
        "\n",
        "    print(f\"Package Name: {package_name}\")\n",
        "    print(f\"Imports Count: {imports_count}\")\n",
        "    print(f\"Total Classes: {total_classes}\")\n",
        "    print(f\"Interfaces Count: {interfaces_count}\")\n",
        "    print(f\"Total Enums: {total_enums}\")\n",
        "    print(f\"Methods in Classes: {methods_in_classes}\")\n",
        "    print(f\"Methods in Abstact Classes: {methods_in_abstract_classes}\")\n",
        "    print(f\"Methods in Interfaces: {methods_in_interfaces}\")\n",
        "    print(f\"Total Methods: {total_methods}\")\n",
        "    print(f\"Total Calls: {total_calls}\")\n",
        "    print(f\"Total Arguments: {total_arguments}\")\n",
        "    print(f\"Generalization Relationships Count: {generalization_count}\")\n",
        "    print(f\"Association Relationships Count: {association_count}\")\n",
        "    print(f\"Realization Relationships Count: {realization_count}\")\n",
        "    print(f\"Total Relationships: {total_relationships}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjbrNSY-u_Ex",
        "outputId": "24888bfd-71f6-4051-f081-3fc99f1e29c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package Name: ['Cricket']\n",
            "Imports Count: 0\n",
            "Total Classes: 1\n",
            "Interfaces Count: 0\n",
            "Total Enums: 0\n",
            "Methods in Classes: 1\n",
            "Methods in Abstact Classes: 0\n",
            "Methods in Interfaces: 0\n",
            "Total Methods: 1\n",
            "Total Calls: 0\n",
            "Total Arguments: 1\n",
            "Generalization Relationships Count: 0\n",
            "Association Relationships Count: 10\n",
            "Realization Relationships Count: 0\n",
            "Total Relationships: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze JSON Files"
      ],
      "metadata": {
        "id": "to99LvrAhEx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "\n",
        "def calculate_metrics(data):\n",
        "    package_name = data.get(\"package\", \"blank\")\n",
        "    imports_count = len(data.get(\"imports\", []))\n",
        "    total_classes = len([info for info in data.get(\"info\", []) if \"class\" in info])\n",
        "    total_abstract_classes = len([info for info in data.get(\"info\", []) if \"abstract_class\" in info])\n",
        "    total_interfaces = len([info for info in data.get(\"info\", []) if \"interface\" in info])\n",
        "    total_enums = len([info for info in data.get(\"info\", []) if \"enum\" in info])\n",
        "\n",
        "    try:\n",
        "      methods_in_classes = sum(len(info[\"methods\"]) for info in data.get(\"info\", []) if \"class\" in info)\n",
        "    except (KeyError, TypeError):\n",
        "      methods_in_classes = 0\n",
        "\n",
        "    try:\n",
        "      methods_in_abstract_classes = sum(len(info[\"methods\"]) for info in data.get(\"info\", []) if \"abstract_class\" in info)\n",
        "    except (KeyError, TypeError):\n",
        "      methods_in_abstract_classes = 0\n",
        "    try:\n",
        "      methods_in_interfaces = sum(len(info[\"methods\"]) for info in data.get(\"info\", []) if \"interface\" in info)\n",
        "    except (KeyError, TypeError):\n",
        "      methods_in_interfaces = 0\n",
        "\n",
        "    total_methods = methods_in_interfaces + methods_in_classes + methods_in_abstract_classes\n",
        "    try:\n",
        "      total_calls = sum(len(method[\"calls\"]) for info in data.get(\"info\", []) for method in info.get(\"methods\", []))\n",
        "    except (KeyError, TypeError):\n",
        "      total_calls = 0\n",
        "\n",
        "    try:\n",
        "      total_arguments = sum(len(method[\"arguments\"]) for info in data.get(\"info\", []) for method in info.get(\"methods\", []))\n",
        "    except (KeyError, TypeError):\n",
        "      total_arguments = 0\n",
        "\n",
        "\n",
        "    relationships_count = {\n",
        "        \"Generalization\": 0,\n",
        "        \"Association\": 0,\n",
        "        \"Realization\": 0\n",
        "    }\n",
        "\n",
        "    for relationship in data.get(\"relationships\", []):\n",
        "        relationship_type = relationship.get(\"relationship_type\")\n",
        "        if relationship_type in relationships_count:\n",
        "            relationships_count[relationship_type] += 1\n",
        "\n",
        "    return [package_name, imports_count, total_classes, total_abstract_classes, total_interfaces, total_enums, methods_in_classes, methods_in_abstract_classes, methods_in_interfaces, total_methods, total_calls, total_arguments, relationships_count[\"Generalization\"], relationships_count[\"Association\"], relationships_count[\"Realization\"], sum(relationships_count.values())]\n",
        "\n",
        "\n",
        "def process_json_files(directory):\n",
        "    results = []\n",
        "\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".json\"):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with open(file_path, \"r\") as json_file:\n",
        "                        json_data = json.load(json_file)\n",
        "                        print(json_file)\n",
        "                    metrics = calculate_metrics(json_data)\n",
        "                    results.append([file] + metrics)\n",
        "                    print(f\"analyze {file} successfully\")\n",
        "                except (ValueError, KeyError):\n",
        "                    print(f\"Skipping {file}: JSON parsing error\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "dataset_name = \"computer-science\"\n",
        "directory = f\"/content/drive/MyDrive/SPL3/WilliamMary/JSON/{dataset_name}\"\n",
        "\n",
        "results = process_json_files(directory)\n",
        "\n",
        "csv_file = f\"/content/drive/MyDrive/SPL3/WilliamMary/Report/{dataset_name}.csv\"\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File Name\", \"Package Name\", \"Imports\", \"Classes\", \"Abstract Classes\" ,\"Interfaces\", \"Enums\", \"Methods in Classes\", \"Methods in Abstract Classes\", \"Methods in Interfaces\", \"Total Methods\", \"Total Calls\", \"Total Arguments\", \"Generalization Relationships\", \"Association Relationships\", \"Realization Relationships\", \"Total Relationships\"])\n",
        "    writer.writerows(results)\n",
        "#    return [package_name, imports_count, total_classes, interfaces_count, total_enums, methods_in_classes, methods_in_abstract_classes, methods_in_interfaces, total_methods, total_calls, total_arguments, relationships_count[\"Generalization\"], relationships_count[\"Association\"], relationships_count[\"Realization\"], sum(relationships_count.values())]\n",
        "\n",
        "print(f\"Results written to {csv_file}\")\n"
      ],
      "metadata": {
        "id": "akRd0xsyNm87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3759b2-01ae-4415-9a03-5aeff42296e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/AprioriAlgorithm/Apriori.json' mode='r' encoding='UTF-8'>\n",
            "analyze Apriori.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Collections/Sets.json' mode='r' encoding='UTF-8'>\n",
            "analyze Sets.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Cricket/Bowler.json' mode='r' encoding='UTF-8'>\n",
            "analyze Bowler.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Cricket/BowlingAnalysis.json' mode='r' encoding='UTF-8'>\n",
            "analyze BowlingAnalysis.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Cricket/FastBowler.json' mode='r' encoding='UTF-8'>\n",
            "analyze FastBowler.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Cricket/FastMediumBowler.json' mode='r' encoding='UTF-8'>\n",
            "analyze FastMediumBowler.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Cricket/Match.json' mode='r' encoding='UTF-8'>\n",
            "analyze Match.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Cricket/MatchCounterClass.json' mode='r' encoding='UTF-8'>\n",
            "analyze MatchCounterClass.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Cricket/ScoreUpdate.json' mode='r' encoding='UTF-8'>\n",
            "analyze ScoreUpdate.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Cricket/SpinBowler.json' mode='r' encoding='UTF-8'>\n",
            "analyze SpinBowler.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Data/Box.json' mode='r' encoding='UTF-8'>\n",
            "analyze Box.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Data/Person.json' mode='r' encoding='UTF-8'>\n",
            "analyze Person.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/DesignPatternConcepts/BuilderPattern/AdministrationBuilding.json' mode='r' encoding='UTF-8'>\n",
            "analyze AdministrationBuilding.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/DesignPatternConcepts/BuilderPattern/Department.json' mode='r' encoding='UTF-8'>\n",
            "analyze Department.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/DesignPatternConcepts/BuilderPattern/DepartmentBuilder.json' mode='r' encoding='UTF-8'>\n",
            "analyze DepartmentBuilder.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/DesignPatternConcepts/ObserverPattern/EducationalGoogleClassRoom.json' mode='r' encoding='UTF-8'>\n",
            "analyze EducationalGoogleClassRoom.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/DesignPatternConcepts/ObserverPattern/GoogleClassRoom.json' mode='r' encoding='UTF-8'>\n",
            "analyze GoogleClassRoom.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/DesignPatternConcepts/ObserverPattern/GoogleClassRoomStudents.json' mode='r' encoding='UTF-8'>\n",
            "analyze GoogleClassRoomStudents.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/DesignPatternConcepts/ObserverPattern/GoogleClassStream.json' mode='r' encoding='UTF-8'>\n",
            "analyze GoogleClassStream.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/DesignPatternConcepts/ObserverPattern/InitDataBase.json' mode='r' encoding='UTF-8'>\n",
            "analyze InitDataBase.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/DesignPatternConcepts/ObserverPattern/Students.json' mode='r' encoding='UTF-8'>\n",
            "analyze Students.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Hackkerrank/BaseClass.json' mode='r' encoding='UTF-8'>\n",
            "analyze BaseClass.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Hackkerrank/BitPuzzle.json' mode='r' encoding='UTF-8'>\n",
            "analyze BitPuzzle.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Hackkerrank/DataTypeConversion.json' mode='r' encoding='UTF-8'>\n",
            "analyze DataTypeConversion.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Hackkerrank/FloatNumberAddition.json' mode='r' encoding='UTF-8'>\n",
            "analyze FloatNumberAddition.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Hackkerrank/JavaDataTypes.json' mode='r' encoding='UTF-8'>\n",
            "analyze JavaDataTypes.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Hackkerrank/Mutations.json' mode='r' encoding='UTF-8'>\n",
            "analyze Mutations.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Hackkerrank/StandardInputOutput.json' mode='r' encoding='UTF-8'>\n",
            "analyze StandardInputOutput.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/Hackkerrank/TestThread.json' mode='r' encoding='UTF-8'>\n",
            "analyze TestThread.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/InterruptDrivenInputOutputCycle/CPU.json' mode='r' encoding='UTF-8'>\n",
            "analyze CPU.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/InterruptDrivenInputOutputCycle/InputOutputController.json' mode='r' encoding='UTF-8'>\n",
            "analyze InputOutputController.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/ObjectCreator/User.json' mode='r' encoding='UTF-8'>\n",
            "analyze User.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/ObjectOrientedConcepts/Overloading.json' mode='r' encoding='UTF-8'>\n",
            "analyze Overloading.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/ObjectOrientedConcepts/Overriding.json' mode='r' encoding='UTF-8'>\n",
            "analyze Overriding.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/ObjectOrientedConcepts/Polymorphism.json' mode='r' encoding='UTF-8'>\n",
            "analyze Polymorphism.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/OpenSystemsInteractionModel/ApplicationLayer.json' mode='r' encoding='UTF-8'>\n",
            "analyze ApplicationLayer.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/OpenSystemsInteractionModel/DataLinkLayer.json' mode='r' encoding='UTF-8'>\n",
            "analyze DataLinkLayer.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/OpenSystemsInteractionModel/Main.json' mode='r' encoding='UTF-8'>\n",
            "analyze Main.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/OpenSystemsInteractionModel/NetworkLayer.json' mode='r' encoding='UTF-8'>\n",
            "analyze NetworkLayer.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/OpenSystemsInteractionModel/PhysicalLayer.json' mode='r' encoding='UTF-8'>\n",
            "analyze PhysicalLayer.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/OpenSystemsInteractionModel/PresentationLayer.json' mode='r' encoding='UTF-8'>\n",
            "analyze PresentationLayer.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/OpenSystemsInteractionModel/SessionLayer.json' mode='r' encoding='UTF-8'>\n",
            "analyze SessionLayer.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/OpenSystemsInteractionModel/TransportLayer.json' mode='r' encoding='UTF-8'>\n",
            "analyze TransportLayer.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/PetersonSolutionDecompiler/AppScms.json' mode='r' encoding='UTF-8'>\n",
            "analyze AppScms.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/PetersonSolutionDecompiler/CodeUsingJava.json' mode='r' encoding='UTF-8'>\n",
            "analyze CodeUsingJava.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/PetersonSolutionDecompiler/Decompiler.json' mode='r' encoding='UTF-8'>\n",
            "analyze Decompiler.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/PetersonSolutionDecompiler/DecompilersOnline.json' mode='r' encoding='UTF-8'>\n",
            "analyze DecompilersOnline.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/PetersonSolutionDecompiler/JEDC.json' mode='r' encoding='UTF-8'>\n",
            "analyze JEDC.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/PetersonSolutionDecompiler/JavaInUse.json' mode='r' encoding='UTF-8'>\n",
            "analyze JavaInUse.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/PetersonSolutionDecompiler/Main.json' mode='r' encoding='UTF-8'>\n",
            "analyze Main.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/SynchronizationProcess/BoundedBuffer.json' mode='r' encoding='UTF-8'>\n",
            "analyze BoundedBuffer.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/SynchronizationProcess/PetersonSolution.json' mode='r' encoding='UTF-8'>\n",
            "analyze PetersonSolution.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/SynchronizationProcess/ProduceConsumerSynchronization.json' mode='r' encoding='UTF-8'>\n",
            "analyze ProduceConsumerSynchronization.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/SynchronizationProcess/Test_and_Set.json' mode='r' encoding='UTF-8'>\n",
            "analyze Test_and_Set.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/com/company/CalculatePie.json' mode='r' encoding='UTF-8'>\n",
            "analyze CalculatePie.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/com/company/IntToDoubleExample.json' mode='r' encoding='UTF-8'>\n",
            "analyze IntToDoubleExample.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/com/company/Main.json' mode='r' encoding='UTF-8'>\n",
            "analyze Main.json successfully\n",
            "<_io.TextIOWrapper name='/content/drive/MyDrive/SPL3/WilliamMary/JSON/computer-science/src/com/company/Pie.json' mode='r' encoding='UTF-8'>\n",
            "analyze Pie.json successfully\n",
            "Results written to /content/drive/MyDrive/SPL3/WilliamMary/Report/computer-science.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters and calls in each methods"
      ],
      "metadata": {
        "id": "2okaBlGJHEmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import javalang\n",
        "import json\n",
        "\n",
        "def parse_local_variable_declearation(elements):\n",
        "  for element in elements:\n",
        "    if isinstance(element, javalang.tree.LocalVariableDeclaration):\n",
        "        for declarator in element.declarators:\n",
        "            if isinstance(declarator.initializer, javalang.tree.MethodInvocation):\n",
        "                member_value = declarator.initializer.member\n",
        "                return member_value\n",
        "    elif isinstance(element, javalang.tree.StatementExpression):\n",
        "        if isinstance(element.expression, javalang.tree.MethodInvocation):\n",
        "            member_value = element.expression.member\n",
        "            return member_value\n",
        "\n",
        "\n",
        "def parse_method_calls(body):\n",
        "    calls = []\n",
        "    call_method = parse_local_variable_declearation(body)\n",
        "    calls.append(call_method)\n",
        "    return calls\n",
        "\n",
        "def parse_method(method):\n",
        "    method_info = {\n",
        "        \"name\": method.name,\n",
        "        \"arguments\": [ param.name for param in method.parameters],\n",
        "         \"calls\": parse_method_calls(method.body)\n",
        "    }\n",
        "    return method_info\n",
        "\n",
        "def parse_class(clazz):\n",
        "    class_info = {\n",
        "        \"name\": clazz.name,\n",
        "        \"methods\": [parse_method(method) for method in clazz.methods]\n",
        "    }\n",
        "    return class_info\n",
        "\n",
        "def parse_java_code(java_code):\n",
        "    tree = javalang.parse.parse(java_code)\n",
        "    classes = [parse_class(clazz) for _, clazz in tree.filter(javalang.tree.ClassDeclaration)]\n",
        "\n",
        "    return classes\n",
        "\n",
        "def main():\n",
        "    java_code = \"\"\"\n",
        "    public class MyClass {\n",
        "    private int myField;\n",
        "\n",
        "    public MyClass() {\n",
        "        myField = 0;\n",
        "    }\n",
        "\n",
        "    public void setMyField(int value, string name, double price, int count) {\n",
        "       int tool = printMyField();\n",
        "       copyMyField();\n",
        "\n",
        "    }\n",
        "\n",
        "      public void setMyField(string name, double price, int count) {\n",
        "       int text = downloadMyField(file, printer);\n",
        "     int data = deleteMyField(button, text);\n",
        "\n",
        "    }\n",
        "\n",
        "    private void printMyField() {\n",
        "\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    classes_info = parse_java_code(java_code)\n",
        "    json_output = json.dumps(classes_info, indent=4)\n",
        "    print(json_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC9nz6gLHlup",
        "outputId": "ee3b9a30-005b-4122-f9c2-dbd3d13f52f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"name\": \"MyClass\",\n",
            "    \"methods\": [\n",
            "      {\n",
            "        \"name\": \"setMyField\",\n",
            "        \"arguments\": [\n",
            "          \"value\",\n",
            "          \"name\",\n",
            "          \"price\",\n",
            "          \"count\"\n",
            "        ],\n",
            "        \"calls\": [\n",
            "          \"printMyField\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"setMyField\",\n",
            "        \"arguments\": [\n",
            "          \"name\",\n",
            "          \"price\",\n",
            "          \"count\"\n",
            "        ],\n",
            "        \"calls\": [\n",
            "          \"downloadMyField\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"printMyField\",\n",
            "        \"arguments\": [],\n",
            "        \"calls\": [\n",
            "          null\n",
            "        ]\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract Class"
      ],
      "metadata": {
        "id": "sXIkKsmTXP0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import javalang\n",
        "import json\n",
        "\n",
        "def analyze_java_code(java_code):\n",
        "    tree = javalang.parse.parse(java_code)\n",
        "\n",
        "    abstract_classes_info = []\n",
        "    for _, class_declaration in tree.filter(javalang.tree.ClassDeclaration):\n",
        "        if 'abstract' in class_declaration.modifiers:\n",
        "            class_info = {\n",
        "                \"name\": class_declaration.name,\n",
        "                \"methods\": [{\"name\": method.name, \"parameters\": [param.type.name for param in method.parameters]}\n",
        "                            for method in class_declaration.methods]\n",
        "            }\n",
        "            abstract_classes_info.append(class_info)\n",
        "\n",
        "    return abstract_classes_info\n",
        "\n",
        "def main():\n",
        "    java_code = \"\"\"\n",
        "   // Abstract class 1\n",
        "abstract class Shape {\n",
        "    abstract double calculateArea();\n",
        "    abstract double calculatePerimeter();\n",
        "}\n",
        "\n",
        "// Abstract class 2\n",
        "abstract class Animal {\n",
        "    abstract void makeSound();\n",
        "    abstract void eat();\n",
        "}\n",
        "\n",
        "// Abstract class 3\n",
        "abstract class Vehicle {\n",
        "    abstract void start();\n",
        "    abstract void stop();\n",
        "}\n",
        "\n",
        "// Concrete implementation of Shape\n",
        "class Circle extends Shape {\n",
        "    private double radius;\n",
        "\n",
        "    Circle(double radius) {\n",
        "        this.radius = radius;\n",
        "    }\n",
        "\n",
        "    @Override\n",
        "    double calculateArea() {\n",
        "        return Math.PI * radius * radius;\n",
        "    }\n",
        "\n",
        "    @Override\n",
        "    double calculatePerimeter() {\n",
        "        return 2 * Math.PI * radius;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Concrete implementation of Animal\n",
        "class Dog extends Animal {\n",
        "    @Override\n",
        "    void makeSound(int sound) {\n",
        "        System.out.println(\"Woof! Woof!\");\n",
        "    }\n",
        "\n",
        "    @Override\n",
        "    void eat() {\n",
        "        System.out.println(\"The dog is eating.\");\n",
        "    }\n",
        "}\n",
        "\n",
        "// Concrete implementation of Vehicle\n",
        "class Car extends Vehicle {\n",
        "    @Override\n",
        "    void start() {\n",
        "        System.out.println(\"Car is starting.\");\n",
        "    }\n",
        "\n",
        "    @Override\n",
        "    void stop() {\n",
        "        System.out.println(\"Car is stopping.\");\n",
        "    }\n",
        "}\n",
        "\n",
        "public class Main {\n",
        "    public static void main(String[] args) {\n",
        "        // Example usage\n",
        "        Circle circle = new Circle(5.0);\n",
        "        System.out.println(\"Circle Area: \" + circle.calculateArea());\n",
        "        System.out.println(\"Circle Perimeter: \" + circle.calculatePerimeter());\n",
        "\n",
        "        Dog dog = new Dog();\n",
        "        dog.makeSound();\n",
        "        dog.eat();\n",
        "\n",
        "        Car car = new Car();\n",
        "        car.start();\n",
        "        car.stop();\n",
        "    }\n",
        "}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    abstract_classes_info = analyze_java_code(java_code)\n",
        "\n",
        "    json_file = json.dumps(abstract_classes_info, indent=4)\n",
        "    print(json_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnJzs3vcXOY8",
        "outputId": "a7c82f67-82e8-472d-cb2c-e2795b060752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"name\": \"Shape\",\n",
            "        \"methods\": [\n",
            "            {\n",
            "                \"name\": \"calculateArea\",\n",
            "                \"parameters\": []\n",
            "            },\n",
            "            {\n",
            "                \"name\": \"calculatePerimeter\",\n",
            "                \"parameters\": []\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"Animal\",\n",
            "        \"methods\": [\n",
            "            {\n",
            "                \"name\": \"makeSound\",\n",
            "                \"parameters\": []\n",
            "            },\n",
            "            {\n",
            "                \"name\": \"eat\",\n",
            "                \"parameters\": []\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"Vehicle\",\n",
            "        \"methods\": [\n",
            "            {\n",
            "                \"name\": \"start\",\n",
            "                \"parameters\": []\n",
            "            },\n",
            "            {\n",
            "                \"name\": \"stop\",\n",
            "                \"parameters\": []\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    }
  ]
}